{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f349c3d0",
   "metadata": {},
   "source": [
    "# Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3beab3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import re\n",
    "import random\n",
    "from pathlib import Path\n",
    "from typing import Dict, Tuple, Any, Optional, List, Callable, TypedDict, Iterator, DefaultDict\n",
    "from collections import defaultdict\n",
    "from itertools import combinations\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as  lr_scheduler\n",
    "import torchvision.models as models # pyright: ignore[reportMissingTypeStubs]\n",
    "import torchvision.transforms as transforms # pyright: ignore[reportMissingTypeStubs]\n",
    "from torchvision.models import get_model_weights # pyright: ignore[reportUnknownVariableType, reportMissingTypeStubs]\n",
    "from torch.amp.grad_scaler import GradScaler\n",
    "from torch.amp.autocast_mode import autocast\n",
    "from torch.utils.data import Dataset, DataLoader, Sampler\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from sklearn.model_selection import train_test_split # pyright: ignore[reportUnknownVariableType]\n",
    "from sklearn.metrics import roc_curve, roc_auc_score # pyright: ignore[reportUnknownVariableType]\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18227c69",
   "metadata": {},
   "source": [
    "# Seeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2f5cff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed: int = 42) -> None:\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)  # pyright: ignore[reportUnknownMemberType]\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52eacd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_worker(worker_id: int) -> None:\n",
    "    work_seed = 42 + worker_id\n",
    "    np.random.seed(work_seed)\n",
    "    random.seed(work_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc77e170",
   "metadata": {},
   "source": [
    "# Configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50fc54fd",
   "metadata": {},
   "source": [
    "## Defining Custom Types "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e50a163",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SchedulerEntry(TypedDict):\n",
    "    name: str\n",
    "    params: Dict[str, Any]\n",
    "\n",
    "class SchedulerConfig(TypedDict, total=False):\n",
    "    SCHEDULER: str\n",
    "    MILESTONES: List[int]\n",
    "    SCHEDULERS: List[SchedulerEntry]\n",
    "\n",
    "class ModelState(TypedDict):\n",
    "    epoch: int\n",
    "    model_state_dict: Any\n",
    "    optimiser_state_dict: Any\n",
    "    scheduler_state_dict: Any\n",
    "    auc: float\n",
    "    best_loss: float\n",
    "    patience_counter: int"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db194f6b",
   "metadata": {},
   "source": [
    "## Dataset Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38af7d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH: Dict[str, str] = {\n",
    "    \"CEDAR\": \"data\\\\CEDAR\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee066fec",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65332b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_CONFIG: Dict[str, str | int | float] = {\n",
    "    \"BATCH_SIZE\": 32,\n",
    "    \"EPOCH\": 50,\n",
    "    \"LEARNING_RATE\": 1e-3,\n",
    "    \"EARLY_STOPPING_PATIENT\": 10,\n",
    "    \n",
    "    \"DEVICE\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    \n",
    "    \"CHECKPOINT_DIR\": \"checkpoint/exp_01_mod_dummy\",\n",
    "    \"LOG_DIR\": \"runs/exp_01_mod_dummy\"\n",
    "}\n",
    "\n",
    "OPTIMISER_PARAMS: Dict[str, str | float] = {\n",
    "    \"optimiser\": \"AdamW\",\n",
    "    # Prevent overwriting the pretrained weights too aggressively\n",
    "    \"weight_decay\": 1e-3,\n",
    "}\n",
    "\n",
    "# Linear Warmup and Cosine Decay\n",
    "SCHEDULER_PARAMS: SchedulerConfig = {\n",
    "    \"SCHEDULER\": \"SequentialLR\", \n",
    "    \"MILESTONES\": [5],\n",
    "    \"SCHEDULERS\": [\n",
    "        {\n",
    "            \"name\": \"LinearLR\",\n",
    "            \"params\": {\n",
    "                \"start_factor\": 0.1,\n",
    "                \"total_iters\": 5\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"CosineAnnealingLR\",\n",
    "            \"params\": {\n",
    "                \"T_max\": int(LEARNING_CONFIG[\"EPOCH\"])-5, \n",
    "                \"eta_min\": 1e-6\n",
    "            }\n",
    "        }\n",
    "    ],\n",
    "}\n",
    "\n",
    "BACKBONE_CONFIG: Dict[str, Dict[str, Any]] = {\n",
    "    \"efficientnet_v2_s\": {\"builder\": models.efficientnet_v2_s, \"out_channels\": 1280},\n",
    "    \"efficientnet_v2_m\": {\"builder\": models.efficientnet_v2_m, \"out_channels\": 1280},\n",
    "    \"efficientnet_v2_l\": {\"builder\": models.efficientnet_v2_l, \"out_channels\": 1280},\n",
    "}\n",
    "\n",
    "IMAGE_FORMATS: List[str] = [\".png\", \".jpg\", \".jpeg\", \".bmp\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab8d786",
   "metadata": {},
   "source": [
    "# Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4cc4c91",
   "metadata": {},
   "source": [
    "## Model\n",
    "The model uses `efficientnet`\n",
    "```python\n",
    "# use_extra_layers: bool = True,\n",
    "# extra_channels: Optional[List[int]] = None,\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c54fdbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtractionModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        backbone_type: str,\n",
    "        embedding_dim: int = 256,\n",
    "        weights: Optional[str] = None, \n",
    "        dropout_rate: float  = 0.4,\n",
    "    ) -> None:\n",
    "        super().__init__()  # pyright: ignore[reportUnknownMemberType]\n",
    "        self._check_parameters(backbone_type, embedding_dim, dropout_rate)\n",
    "        \n",
    "        FREEZE_UP_TO: int = 4\n",
    "        \n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.backbone_type = backbone_type\n",
    "        self.dropout_rate = dropout_rate  \n",
    "        \n",
    "        self.weights = weights\n",
    "        self.weights_enum = None\n",
    "        \n",
    "        backbone_builder = BACKBONE_CONFIG[self.backbone_type][\"builder\"]\n",
    "        backbone_out_channels = BACKBONE_CONFIG[self.backbone_type][\"out_channels\"]\n",
    "        \n",
    "        self._retrieve_weights(str(self.weights), backbone_builder)\n",
    "        \n",
    "        self.model = backbone_builder(weights = self.weights_enum)\n",
    "        \n",
    "        first_layer = self.model.features[0][0]\n",
    "        self.model.features[0][0] = nn.Conv2d(\n",
    "            in_channels= 1,\n",
    "            out_channels=first_layer.out_channels,\n",
    "            kernel_size=first_layer.kernel_size,\n",
    "            stride=first_layer.stride,\n",
    "            padding=first_layer.padding,\n",
    "            bias=first_layer.bias is not None,\n",
    "        )\n",
    "        \n",
    "        if self.weights is not None:\n",
    "            with torch.no_grad():\n",
    "                self.model.features[0][0].weight.data = (\n",
    "                    first_layer.weight.data.mean(dim=1, keepdim=True)\n",
    "                )\n",
    "        else:\n",
    "            nn.init.kaiming_normal_(\n",
    "                self.model.features[0][0].weight, mode=\"fan_out\", nonlinearity=\"relu\"\n",
    "            )\n",
    "            if self.model.features[0][0].bias is not None:\n",
    "                nn.init.constant_(self.model.features[0][0].bias, 0)\n",
    "\n",
    "        self.backbone = self.model.features\n",
    "\n",
    "        # Zero shot Learning       \n",
    "        # for param in self.backbone.parameters():\n",
    "        #     param.requires_grad = False\n",
    "        \n",
    "        for i, block in enumerate(self.model.features):\n",
    "            if i <= FREEZE_UP_TO:\n",
    "                for param in block.parameters():\n",
    "                    param.requires_grad = False\n",
    "            else:\n",
    "                for param in block.parameters():\n",
    "                    param.requires_grad = True\n",
    "            \n",
    "        self.pool1 = nn.AdaptiveAvgPool2d(1) \n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        self.fc1 = nn.Linear(backbone_out_channels, 512)\n",
    "        self.bn1 = nn.BatchNorm1d(512)\n",
    "        \n",
    "        self.fc2 = nn.Linear(512, self.embedding_dim)\n",
    "        self.bn2 = nn.BatchNorm1d(self.embedding_dim) \n",
    "        \n",
    "        self.dropout = nn.Dropout(self.dropout_rate)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.backbone(x)\n",
    "        \n",
    "        x = self.pool1(x)\n",
    "        x = self.flatten(x)\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        x = self.bn2(x)\n",
    "        # x = self.relu(x)\n",
    "        \n",
    "        x = F.normalize(x, p=2, dim=1)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def _check_parameters(\n",
    "        self,\n",
    "        backbone_type: str,\n",
    "        embedding_dim: int,\n",
    "        dropout_rate: float,\n",
    "    ) -> None:\n",
    "        if embedding_dim <= 0:\n",
    "            raise ValueError(\n",
    "                f\"Embedding dimension must be positive, got {embedding_dim}\"\n",
    "            )\n",
    "        if dropout_rate < 0 or dropout_rate > 1:\n",
    "            raise ValueError(\n",
    "                f\"Dropout rate must be between 0 and 1, got {dropout_rate}\"\n",
    "            )\n",
    "        if backbone_type not in BACKBONE_CONFIG:\n",
    "            raise ValueError(\n",
    "                f\"Unsupported backbone type: {backbone_type}. Choose from {list(BACKBONE_CONFIG.keys())}\"\n",
    "            )\n",
    "    \n",
    "    def _retrieve_weights(\n",
    "        self, \n",
    "        weights: str, \n",
    "        backbone_builder: Any\n",
    "    ) -> None:\n",
    "        try:\n",
    "            weights_enum_type = get_model_weights(backbone_builder)\n",
    "            if hasattr(weights_enum_type, weights):\n",
    "                self.weights_enum = getattr(weights_enum_type, weights)\n",
    "            else:\n",
    "                print(\n",
    "                    f\"Warning: Could not get weights type for backbone '{self.backbone_type}'. Using default random initialisation.\",\n",
    "                    file=sys.stderr,\n",
    "                )\n",
    "                weights = \"\"\n",
    "        except AttributeError:\n",
    "            print(\n",
    "                f\"Warning: Specified weights alias '{weights}' not found for {self.backbone_type}. Check available weights in torchvision documentation. Using default random initialisation.\",\n",
    "                file=sys.stderr,\n",
    "            )\n",
    "            weights = \"\"\n",
    "        except Exception as e:\n",
    "            print(\n",
    "                f\"Warning: An unexpected error occurred looking up weights '{weights}' for {self.backbone_type}: {e}. Using default random initialisation.\",\n",
    "                file=sys.stderr,\n",
    "            )\n",
    "            \n",
    "            weights = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f2c925",
   "metadata": {},
   "source": [
    "## Loss Function\n",
    "```python\n",
    "        \n",
    "pos_dist = torch.linalg.vector_norm(embeddings - positives, ord=self.p, dim=1) # pyright: ignore[reportUnknownVariableType, reportUnknownMemberType]\n",
    "neg_dist = torch.linalg.vector_norm(embeddings - negatives, ord=self.p, dim=1) # pyright: ignore[reportUnknownVariableType, reportUnknownMemberType]\n",
    "\n",
    "triplet_vals = pos_dist - neg_dist + self.margin # pyright: ignore[reportUnknownVariableType]\n",
    "```        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c90a880",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletLoss(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        margin: float = 1.0,\n",
    "        mining_strategy: str = \"batch_semi_hard\",\n",
    "        use_diversity: bool = False,\n",
    "        lambda_diversity: float = 0.1,\n",
    "        p: int = 2,\n",
    "    ) -> None:\n",
    "        super().__init__()  # pyright: ignore[reportUnknownMemberType]\n",
    "        \n",
    "        if margin < 0:\n",
    "            raise ValueError(f\"Margin must be non-negative, got {margin}\")\n",
    "        if mining_strategy not in [\"batch_hard\", \"batch_semi_hard\"]:\n",
    "            raise ValueError(f\"Invalid mining strategy, got {mining_strategy}\")\n",
    "        \n",
    "        self.margin = margin\n",
    "        self.mining_strategy = mining_strategy\n",
    "        \n",
    "        # optional, but it's usually not needed\n",
    "        self.lambda_diversity = lambda_diversity\n",
    "        self.use_diversity = use_diversity\n",
    "        \n",
    "        self.p = p\n",
    "    \n",
    "        # Calculate margin automatically\n",
    "        self.base_loss = nn.TripletMarginLoss(margin=margin, p=p)\n",
    "        \n",
    "    def forward(\n",
    "        self, \n",
    "        embeddings: torch.Tensor, \n",
    "        labels: torch.Tensor\n",
    "    ) -> Tuple[torch.Tensor, Dict[str, Any]]:\n",
    "\n",
    "        # compute pairwise distances\n",
    "        distances = torch.cdist(embeddings, embeddings, p=self.p)\n",
    "        mask_anchor_positive, mask_anchor_negative = self._get_triplet_mask(labels)\n",
    "        \n",
    "        if mask_anchor_positive.sum().item() == 0:\n",
    "            print(\"No positive pairs in batch\")\n",
    "        \n",
    "        if mask_anchor_negative.sum().item() == 0:\n",
    "            print(\"No negative pairs in batch\")\n",
    "\n",
    "        if self.mining_strategy == \"batch_hard\":\n",
    "            pos_idx, neg_idx = self._batch_hard_mining(distances, mask_anchor_positive, mask_anchor_negative)\n",
    "        else:\n",
    "            pos_idx, neg_idx, has_semi = self._batch_semi_hard_mining(distances, mask_anchor_positive, mask_anchor_negative)\n",
    "        \n",
    "            if not has_semi.any(): \n",
    "                print(\"No semi-hard negatives found (fallback to hard negatives)\")\n",
    "\n",
    "        # anchors = embeddings\n",
    "        positives = embeddings[pos_idx]\n",
    "        negatives = embeddings[neg_idx]\n",
    "        \n",
    "        batch_indices = torch.arange(distances.size(0), device=distances.device)\n",
    "        pos_dist = distances[batch_indices, pos_idx]\n",
    "        neg_dist = distances[batch_indices, neg_idx]\n",
    "\n",
    "        triplet_vals = torch.stack([pos_dist, neg_dist], dim = 1)\n",
    "\n",
    "        hn_ratio = (neg_dist < pos_dist).float().mean() if pos_dist.numel() else torch.tensor(0.0)  # pyright: ignore[reportUnknownVariableType, reportUnknownMemberType]\n",
    "        \n",
    "        stats: Dict[str, Any] = {\n",
    "            \"pos\": pos_dist.detach(), \n",
    "            \"neg\": neg_dist.detach(),\n",
    "            \"triplet_vals\": triplet_vals.detach(),\n",
    "            \"hn_ratio\": hn_ratio.item(),\n",
    "            \"pos_idx\": pos_idx.detach(),\n",
    "            \"neg_idx\": neg_idx.detach(),\n",
    "        }\n",
    "        \n",
    "        triplet_loss = self.base_loss(embeddings, positives, negatives)\n",
    "\n",
    "        if self.use_diversity and self.lambda_diversity > 0:\n",
    "            triplet_loss = triplet_loss + self._compute_diversity_regularisation(embeddings)\n",
    "\n",
    "        return triplet_loss, stats\n",
    "\n",
    "    # Gives me 1s and 0s\n",
    "    def _get_triplet_mask(\n",
    "        self, \n",
    "        labels: torch.Tensor\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        labels = labels.unsqueeze(1)\n",
    "        mask_anchor_positive = (labels == labels.T) & ~torch.eye(\n",
    "            labels.size(0), dtype=torch.bool, device=labels.device\n",
    "        )\n",
    "        mask_anchor_negative = labels != labels.T\n",
    "        \n",
    "        return (mask_anchor_positive, mask_anchor_negative)\n",
    "    \n",
    "    def _batch_hard_mining(\n",
    "        self,\n",
    "        distances: torch.Tensor,\n",
    "        mask_anchor_positive: torch.Tensor,\n",
    "        mask_anchor_negative: torch.Tensor,\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \n",
    "        positive_distance = torch.where(\n",
    "            mask_anchor_positive, distances, torch.full_like(distances, -float(\"inf\"))\n",
    "        )\n",
    "        \n",
    "        _max_positive_distance, pos_idx = torch.max(positive_distance, dim=1)\n",
    "        \n",
    "        negative_distance = torch.where(\n",
    "            mask_anchor_negative, distances, torch.full_like(distances, float(\"inf\"))\n",
    "        )\n",
    "        _min_negative_distance, neg_idx = torch.min(negative_distance, dim=1)\n",
    "        \n",
    "        return pos_idx, neg_idx\n",
    "\n",
    "    def _batch_semi_hard_mining(\n",
    "        self,\n",
    "        distances: torch.Tensor,\n",
    "        mask_anchor_positive: torch.Tensor,\n",
    "        mask_anchor_negative: torch.Tensor,\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        positive_distance_filtered = torch.where(\n",
    "            mask_anchor_positive, distances, torch.full_like(distances, -float(\"inf\"))\n",
    "        )\n",
    "        hardest_positive_dist, pos_idx = torch.max(positive_distance_filtered, dim=1)\n",
    "        \n",
    "        valid_negative_distances = torch.where(\n",
    "            mask_anchor_negative, distances, torch.full_like(distances, float(\"inf\"))\n",
    "        )\n",
    "        \n",
    "        is_harder_than_positive = valid_negative_distances > hardest_positive_dist.unsqueeze(1)\n",
    "        \n",
    "        is_easier_than_margin = valid_negative_distances < (\n",
    "            hardest_positive_dist.unsqueeze(1) + self.margin\n",
    "        )\n",
    "        \n",
    "        semi_hard_mask = mask_anchor_negative & is_harder_than_positive & is_easier_than_margin\n",
    "\n",
    "        semi_hard_negatives = torch.where(\n",
    "            semi_hard_mask, distances, torch.full_like(distances, float(\"inf\"))\n",
    "        )\n",
    "        \n",
    "        _easiest_semi_hard, semi_idx = torch.min(semi_hard_negatives, dim=1)\n",
    "        _hardest_overall, hard_idx = torch.min(valid_negative_distances, dim=1)\n",
    "\n",
    "        use_semi = semi_hard_mask.sum(dim=1) > 0\n",
    "        neg_idx = torch.where(use_semi, semi_idx, hard_idx)\n",
    "        \n",
    "        return pos_idx, neg_idx, use_semi\n",
    "    \n",
    "    # This is not really necessary\n",
    "    def _compute_diversity_regularisation(self, embeddings: torch.Tensor) -> torch.Tensor:\n",
    "        sim = embeddings @ embeddings.T\n",
    "        eye = torch.eye(sim.size(0), device=sim.device, dtype=sim.dtype)\n",
    "        diversity = (sim - eye).pow(2).mean()\n",
    "        return self.lambda_diversity * diversity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16860520",
   "metadata": {},
   "source": [
    "### SCT+\n",
    "```python\n",
    "print(f'loss:{loss.item():.3f} hn_rt:{hn_ratio.item():.3f}', end='\\r')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a1aa597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class SCTLoss(nn.Module):\n",
    "#     def __init__(\n",
    "#         self, \n",
    "#         method: str, \n",
    "#         lam: float=1.0, \n",
    "#         margin: float = 1.0,\n",
    "#         positive_pull_weight: float = 0.5,\n",
    "#         verbose: bool = False,\n",
    "#         hard_positive: bool = True,\n",
    "#     ):\n",
    "#         super(SCTLoss, self).__init__() # pyright: ignore[reportUnknownMemberType]\n",
    "#         if method == 'sct':\n",
    "#             self.sct, self.semi = True, False\n",
    "#         elif method == 'hn':\n",
    "#             self.sct, self.semi = False, False\n",
    "#         elif method == 'shn':\n",
    "#             self.sct, self.semi = False, True\n",
    "#         else: raise ValueError('loss type is not supported')\n",
    "        \n",
    "#         self.lam = lam\n",
    "#         self.margin = margin\n",
    "#         self.verbose = verbose\n",
    "#         self.positive_pull_weight = positive_pull_weight\n",
    "#         self.hard_positive = hard_positive\n",
    "\n",
    "#     def forward(\n",
    "#         self,\n",
    "#         fvec: torch.Tensor,\n",
    "#         Lvec: torch.Tensor,\n",
    "#     ) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        \n",
    "#         # Already normalised in the model\n",
    "#         # fvec_norm: torch.Tensor = F.normalize(fvec, p = 2, dim = 1)\n",
    "       \n",
    "#         device = fvec.device\n",
    "#         Same, Diff = self._build_boolean_masks(Lvec.view(-1))\n",
    "#         CosSim = self._calculate_cosine_similarity(fvec, fvec)\n",
    "        \n",
    "#         Pos, I_pos, Mask_pos_valid, _Pos_log = self._select_positives(CosSim, Diff)\n",
    "#         Neg, I_neg, Mask_neg_valid, _Neg_log = self._select_negatives(CosSim, Same, Diff, Pos)\n",
    "\n",
    "#         Triplet_val, Triplet_idx, HardMask, EasyMask, hn_ratio = self._build_triplets(\n",
    "#             Pos, Neg, I_pos, I_neg, Mask_pos_valid, Mask_neg_valid\n",
    "#         )\n",
    "        \n",
    "#         loss = self._compute_loss(Triplet_val, Pos, Neg, HardMask, EasyMask, device)\n",
    "\n",
    "#         if self.verbose:\n",
    "#             hr = float(hn_ratio) if isinstance(hn_ratio, (float, int)) or (hasattr(hn_ratio, \"item\") and not torch.isnan(hn_ratio)) else 0.0\n",
    "#             print(f'loss:{loss.item():.4f} hn_rt:{hr:.4f}', end='\\r')\n",
    "        \n",
    "#         return (\n",
    "#             loss, \n",
    "#             Triplet_val.clone().detach().cpu(), \n",
    "#             Triplet_idx.clone().detach().cpu(), \n",
    "#             hn_ratio if isinstance(hn_ratio, float) else hn_ratio.clone().detach().cpu(),\n",
    "#             Pos.detach().cpu(), \n",
    "#             Neg.detach().cpu()\n",
    "#         )\n",
    "        \n",
    "#     def _select_positives(\n",
    "#         self, \n",
    "#         CosSim: torch.Tensor, \n",
    "#         Diff: torch.Tensor\n",
    "#     ) -> Tuple[\n",
    "#             torch.Tensor, \n",
    "#             torch.Tensor, \n",
    "#             torch.Tensor,\n",
    "#             torch.Tensor,\n",
    "#         ]:\n",
    "        \n",
    "#         # Select Easy Positive\n",
    "#         D_easy = CosSim.clone().detach()\n",
    "#         D_easy[Diff] = -1\n",
    "#         V_easy, I_easy = D_easy.max(1)\n",
    "#         mask_easy = (V_easy > -1) & (V_easy < 1)\n",
    "        \n",
    "#         # Select Hard Positives\n",
    "#         D_hard = CosSim.clone().detach()\n",
    "#         D_hard[Diff] = 2\n",
    "#         V_hard, I_hard = D_hard.min(1)\n",
    "#         mask_hard = (V_hard > -1) & (V_hard < 1)\n",
    "         \n",
    "#         if self.hard_positive and mask_hard.any():\n",
    "#             Pos = CosSim[torch.arange(0, CosSim.size(0)), I_hard]\n",
    "#             return Pos, I_hard, mask_hard, Pos.clone().detach().cpu()\n",
    "        \n",
    "#         Pos = CosSim[torch.arange(0, CosSim.size(0)), I_easy]\n",
    "#         Pos_log = Pos.clone().detach().cpu()\n",
    "    \n",
    "#         return Pos, I_easy, mask_easy, Pos_log\n",
    "    \n",
    "#     def _select_negatives(\n",
    "#         self, \n",
    "#         CosSim: torch.Tensor,\n",
    "#         Same: torch.Tensor,\n",
    "#         Diff: torch.Tensor, \n",
    "#         V_pos: torch.Tensor\n",
    "#     ) -> Tuple[\n",
    "#             torch.Tensor, \n",
    "#             torch.Tensor, \n",
    "#             torch.Tensor,\n",
    "#             torch.Tensor,\n",
    "#         ]:\n",
    "        \n",
    "#         D_neg = CosSim.clone().detach()\n",
    "#         D_neg[Same] = -1\n",
    "        \n",
    "#         # Masking out non-Semi-Hard Negative\n",
    "#         if self.semi:    \n",
    "#             D_neg[(D_neg > V_pos.unsqueeze(1)) & Diff] = -1 \n",
    "#             # D_neg[(D_neg > (V_pos.repeat(CosSim.size(0), 1).t())) & Diff] = -1\n",
    "            \n",
    "#         V_neg, I_neg = D_neg.max(1)\n",
    "#         Mask_neg_valid = (V_neg > -1) & (V_neg < 1)\n",
    "#         Neg = CosSim[torch.arange(0, CosSim.size(0)), I_neg]\n",
    "#         Neg_log = Neg.clone().detach().cpu()\n",
    "        \n",
    "#         return Neg, I_neg, Mask_neg_valid, Neg_log \n",
    "        \n",
    "#     def _build_triplets(\n",
    "#         self, \n",
    "#         Pos: torch.Tensor, \n",
    "#         Neg: torch.Tensor,\n",
    "#         I_pos: torch.Tensor,\n",
    "#         I_neg: torch.Tensor,\n",
    "#         Mask_pos_valid: torch.Tensor,\n",
    "#         Mask_neg_valid: torch.Tensor\n",
    "#     ) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        \n",
    "#         Mask_valid = Mask_pos_valid & Mask_neg_valid\n",
    "#         HardMask = ((Neg > Pos) | (Neg > 0.8)) & Mask_valid\n",
    "#         EasyMask = ((Neg < Pos) & (Neg < 0.8)) & Mask_valid\n",
    "#         hn_ratio = (Neg>Pos)[Mask_valid].clone().float().mean().cpu()\n",
    "        \n",
    "#         Triplet_val = torch.stack([Pos, Neg], 1)\n",
    "#         Triplet_idx = torch.stack([I_pos, I_neg], 1)\n",
    "        \n",
    "#         return Triplet_val, Triplet_idx, HardMask, EasyMask, hn_ratio\n",
    "    \n",
    "#         # Triplet_val_log = Triplet_val.clone().detach().cpu()\n",
    "#         # Triplet_idx_log = Triplet_idx.clone().detach().cpu()\n",
    "        \n",
    "#     def _compute_loss(\n",
    "#         self, \n",
    "#         Triplet_val: torch.Tensor, \n",
    "#         Pos: torch.Tensor, \n",
    "#         Neg: torch.Tensor,\n",
    "#         HardMask: torch.Tensor, \n",
    "#         EasyMask: torch.Tensor,\n",
    "#         device: torch.device,\n",
    "#     ) -> torch.Tensor:\n",
    "#         if self.sct:    \n",
    "#             loss_hard = Neg[HardMask]\n",
    "#             if loss_hard.numel() > 0:\n",
    "#                 loss_hard = loss_hard.sum()\n",
    "#             else:\n",
    "#                 loss_hard = Triplet_val.sum() * 0.0\n",
    "#                 # loss_hard = torch.zeros((), device=device, dtype=Triplet_val.dtype)\n",
    "#                 print('No hard triplets in the batch')\n",
    "            \n",
    "#             easy_valid = Triplet_val[EasyMask, :]\n",
    "#             if easy_valid.numel() > 0:\n",
    "#                 loss_easy = -F.log_softmax(easy_valid / 0.1, dim=1)[:, 0].sum()\n",
    "#             else:\n",
    "#                 loss_easy = Triplet_val.sum() * 0.0\n",
    "#                 # loss_easy = torch.zeros((), device=device, dtype=Triplet_val.dtype)\n",
    "#                 print('No easy triplets in the batch')\n",
    "            \n",
    "#             pos_valid = (Pos > -1) & ( Pos < 1)\n",
    "#             if pos_valid.any():\n",
    "#                 positive_pull_valid = F.relu(self.margin - Pos[pos_valid])\n",
    "#                 positive_pull = positive_pull_valid.mean()\n",
    "#             else:\n",
    "#                 positive_pull = Triplet_val.sum() * 0.0\n",
    "#                 # positive_pull = torch.zeros((), device=device, dtype=Triplet_val.dtype)\n",
    "                \n",
    "#             N_hard = HardMask.float().sum().item()\n",
    "#             N_easy = EasyMask.float().sum().item()\n",
    "#             N_total = max(N_hard + N_easy, 1)\n",
    "            \n",
    "#             sct_loss = (loss_easy + self.lam * loss_hard) / N_total\n",
    "            \n",
    "#             return sct_loss + (self.positive_pull_weight * positive_pull)  \n",
    "#         else:\n",
    "#             return -F.log_softmax(Triplet_val / 0.1, dim=1)[:, 0].mean()\n",
    "\n",
    "#     def _calculate_cosine_similarity(\n",
    "#         self,     \n",
    "#         Mat_A: torch.Tensor, \n",
    "#         Mat_B: torch.Tensor, \n",
    "#         norm:int=1, \n",
    "#     ) -> torch.Tensor: \n",
    "        \n",
    "#         Mat_A = F.normalize(Mat_A, p=2, dim=1)\n",
    "#         Mat_B = F.normalize(Mat_B, p=2, dim=1)\n",
    "#         D = Mat_A.mm(torch.t(Mat_B))\n",
    "    \n",
    "#         # Ignore self-similarity\n",
    "#         D.fill_diagonal_(-norm)\n",
    "#         return D\n",
    "    \n",
    "#     def _build_boolean_masks(\n",
    "#         self, \n",
    "#         Lvec: torch.Tensor\n",
    "#     ) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "#         Same = Lvec.unsqueeze(0) == Lvec.unsqueeze(1)\n",
    "#         return Same.clone().fill_diagonal_(0), ~Same\n",
    "    \n",
    "#         # N = Lvec.size(0)\n",
    "#         # Forms N x N\n",
    "#         # Mask = Lvec.repeat(N,1)\n",
    "        \n",
    "#         # True if labels match\n",
    "#         # Same = Lvec.unsqueeze(0) == Lvec.unsqueeze(1)\n",
    "#         # Same = (Mask == Mask.t())\n",
    "        \n",
    "#         # Same / Different masks\n",
    "#         # return Same.clone().fill_diagonal_(0), ~Same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b27ca70",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SCTLoss(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        method: str, \n",
    "        lam: float=1.0, \n",
    "        margin: float = 1.0,\n",
    "        positive_pull_weight: float = 0.5,\n",
    "        verbose: bool = False,\n",
    "    ):\n",
    "        super(SCTLoss, self).__init__() # pyright: ignore[reportUnknownMemberType]\n",
    "        if method == 'sct':\n",
    "            self.sct, self.semi = True, False\n",
    "        elif method == 'hn':\n",
    "            self.sct, self.semi = False, False\n",
    "        elif method == 'shn':\n",
    "            self.sct, self.semi = False, True\n",
    "        else: raise ValueError('loss type is not supported')\n",
    "        self.lam = lam\n",
    "        self.margin = margin\n",
    "        self.verbose = verbose\n",
    "        self.positive_pull_weight = positive_pull_weight\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        fvec: torch.Tensor,\n",
    "        Lvec: torch.Tensor,\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        \n",
    "        # Already normalised in the model\n",
    "        # fvec_norm: torch.Tensor = F.normalize(fvec, p = 2, dim = 1)\n",
    "       \n",
    "        device = fvec.device\n",
    "        Same, Diff = self._build_boolean_masks(Lvec.view(-1))\n",
    "        CosSim = self._calculate_cosine_similarity(fvec, fvec)\n",
    "        \n",
    "        Pos, I_pos, Mask_pos_valid, _Pos_log = self._select_positives(CosSim, Diff)\n",
    "        Neg, I_neg, Mask_neg_valid, _Neg_log = self._select_negatives(CosSim, Same, Diff, Pos)\n",
    "\n",
    "        Triplet_val, Triplet_idx, HardMask, EasyMask, hn_ratio = self._build_triplets(\n",
    "            Pos, Neg, I_pos, I_neg, Mask_pos_valid, Mask_neg_valid\n",
    "        )\n",
    "        \n",
    "        loss = self._compute_loss(Triplet_val, Pos, Neg, HardMask, EasyMask, device)\n",
    "\n",
    "        if self.verbose:\n",
    "            hr = float(hn_ratio) if isinstance(hn_ratio, (float, int)) or (hasattr(hn_ratio, \"item\") and not torch.isnan(hn_ratio)) else 0.0\n",
    "            print(f'loss:{loss.item():.4f} hn_rt:{hr:.4f}', end='\\r')\n",
    "        \n",
    "        return (\n",
    "            loss, \n",
    "            Triplet_val.clone().detach().cpu(), \n",
    "            Triplet_idx.clone().detach().cpu(), \n",
    "            hn_ratio if isinstance(hn_ratio, float) else hn_ratio.clone().detach().cpu(),\n",
    "            Pos.detach().cpu(), \n",
    "            Neg.detach().cpu()\n",
    "        )\n",
    "        \n",
    "    def _select_positives(\n",
    "        self, \n",
    "        CosSim: torch.Tensor, \n",
    "        Diff: torch.Tensor\n",
    "    ) -> Tuple[\n",
    "            torch.Tensor, \n",
    "            torch.Tensor, \n",
    "            torch.Tensor,\n",
    "            torch.Tensor,\n",
    "        ]:\n",
    "        \n",
    "        D_pos = CosSim.clone().detach()\n",
    "        D_pos[Diff] = -1\n",
    "        V_pos, I_pos = D_pos.max(1)\n",
    "\n",
    "        # Select hard positives\n",
    "        Mask_pos_valid = (V_pos > -1) & (V_pos < 1)        \n",
    "        Pos = CosSim[torch.arange(0, CosSim.size(0)), I_pos]\n",
    "        Pos_log = Pos.clone().detach().cpu()\n",
    "    \n",
    "        return Pos, I_pos, Mask_pos_valid, Pos_log\n",
    "    \n",
    "    def _select_negatives(\n",
    "        self, \n",
    "        CosSim: torch.Tensor,\n",
    "        Same: torch.Tensor,\n",
    "        Diff: torch.Tensor, \n",
    "        V_pos: torch.Tensor\n",
    "    ) -> Tuple[\n",
    "            torch.Tensor, \n",
    "            torch.Tensor, \n",
    "            torch.Tensor,\n",
    "            torch.Tensor,\n",
    "        ]:\n",
    "        \n",
    "        D_neg = CosSim.clone().detach()\n",
    "        D_neg[Same] = -1\n",
    "        \n",
    "        # Masking out non-Semi-Hard Negative\n",
    "        if self.semi:    \n",
    "            D_neg[(D_neg > V_pos.unsqueeze(1)) & Diff] = -1 \n",
    "            # D_neg[(D_neg > (V_pos.repeat(CosSim.size(0), 1).t())) & Diff] = -1\n",
    "            \n",
    "        V_neg, I_neg = D_neg.max(1)\n",
    "        Mask_neg_valid = (V_neg > -1) & (V_neg < 1)\n",
    "        Neg = CosSim[torch.arange(0, CosSim.size(0)), I_neg]\n",
    "        Neg_log = Neg.clone().detach().cpu()\n",
    "        \n",
    "        return Neg, I_neg, Mask_neg_valid, Neg_log \n",
    "        \n",
    "    def _build_triplets(\n",
    "        self, \n",
    "        Pos: torch.Tensor, \n",
    "        Neg: torch.Tensor,\n",
    "        I_pos: torch.Tensor,\n",
    "        I_neg: torch.Tensor,\n",
    "        Mask_pos_valid: torch.Tensor,\n",
    "        Mask_neg_valid: torch.Tensor\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        \n",
    "        Mask_valid = Mask_pos_valid & Mask_neg_valid\n",
    "        HardMask = ((Neg > Pos) | (Neg > 0.8)) & Mask_valid\n",
    "        EasyMask = ((Neg < Pos) & (Neg < 0.8)) & Mask_valid\n",
    "        hn_ratio = (Neg>Pos)[Mask_valid].clone().float().mean().cpu()\n",
    "        \n",
    "        Triplet_val = torch.stack([Pos, Neg], 1)\n",
    "        Triplet_idx = torch.stack([I_pos, I_neg], 1)\n",
    "        \n",
    "        return Triplet_val, Triplet_idx, HardMask, EasyMask, hn_ratio\n",
    "    \n",
    "        # Triplet_val_log = Triplet_val.clone().detach().cpu()\n",
    "        # Triplet_idx_log = Triplet_idx.clone().detach().cpu()\n",
    "        \n",
    "    def _compute_loss(\n",
    "        self, \n",
    "        Triplet_val: torch.Tensor, \n",
    "        Pos: torch.Tensor, \n",
    "        Neg: torch.Tensor,\n",
    "        HardMask: torch.Tensor, \n",
    "        EasyMask: torch.Tensor,\n",
    "        device: torch.device,\n",
    "    ) -> torch.Tensor:\n",
    "        if self.sct:    \n",
    "            loss_hard = Neg[HardMask].sum()\n",
    "            N_hard = HardMask.float().sum().item()\n",
    "            if torch.isnan(loss_hard) or N_hard == 0:\n",
    "                loss_hard, N_hard = torch.tensor(0.0), 0\n",
    "                print('No hard triplets in the batch')\n",
    "                \n",
    "            loss_easy = -F.log_softmax(\n",
    "                Triplet_val[EasyMask, :] / 0.1, dim=1\n",
    "            )[:, 0].sum()\n",
    "            N_easy = EasyMask.float().sum().item()\n",
    "            if torch.isnan(loss_easy) or N_easy == 0:\n",
    "                loss_easy, N_easy = torch.tensor(0.0), 0\n",
    "                print('No easy triplets in the batch')\n",
    "            \n",
    "            pos_valid = (Pos > -1) & ( Pos < 1)\n",
    "            if pos_valid.any():\n",
    "                positive_pull = F.relu(self.margin - Pos[pos_valid]).mean()\n",
    "            else:\n",
    "                positive_pull = torch.tensor(0.0, device=device, requires_grad=True)\n",
    "\n",
    "            N_total = max(N_hard + N_easy, 1)\n",
    "            sct_loss = (loss_easy + self.lam * loss_hard) / N_total\n",
    "            \n",
    "            return sct_loss + (self.positive_pull_weight * positive_pull)  \n",
    "            # return (loss_easy + self.lam * loss_hard) / N_total\n",
    "        else:\n",
    "            return -F.log_softmax(Triplet_val / 0.1, dim=1)[:, 0].mean()\n",
    "\n",
    "            # return -F.log_softmax(\n",
    "            #     Triplet_val[Triplet_val, :] / 0.1, dim=1\n",
    "            # )[:, 0].mean()\n",
    "\n",
    "    def _calculate_cosine_similarity(\n",
    "        self,     \n",
    "        Mat_A: torch.Tensor, \n",
    "        Mat_B: torch.Tensor, \n",
    "        norm:int=1, \n",
    "    ) -> torch.Tensor: \n",
    "        \n",
    "        Mat_A = F.normalize(Mat_A, p=2, dim=1)\n",
    "        Mat_B = F.normalize(Mat_B, p=2, dim=1)\n",
    "        # _N_A = Mat_A.size(0)\n",
    "        # _N_B = Mat_B.size(0)\n",
    "    \n",
    "        D = Mat_A.mm(torch.t(Mat_B))\n",
    "    \n",
    "        # Ignore self-similarity\n",
    "        D.fill_diagonal_(-norm)\n",
    "        return D\n",
    "    \n",
    "    def _build_boolean_masks(\n",
    "        self, \n",
    "        Lvec: torch.Tensor\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        # N = Lvec.size(0)\n",
    "        # Forms N x N\n",
    "        # Mask = Lvec.repeat(N,1)\n",
    "        \n",
    "        # True if labels match\n",
    "        Same = Lvec.unsqueeze(0) == Lvec.unsqueeze(1)\n",
    "        # Same = (Mask == Mask.t())\n",
    "        \n",
    "        # Same / Different masks\n",
    "        return Same.clone().fill_diagonal_(0), ~Same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97f5e093",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SCTLossWrapper(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        method: str = \"sct\", \n",
    "        lam: float = 1.0,\n",
    "        margin: float = 1.0,\n",
    "        positive_pull_weight: float = 0.5,\n",
    "        verbose: bool = False\n",
    "    ) -> None:\n",
    "        super().__init__() # pyright: ignore[reportUnknownMemberType]\n",
    "        self.loss_fn = SCTLoss(method, lam, margin, positive_pull_weight, verbose)\n",
    "\n",
    "    def forward(\n",
    "        self, \n",
    "        fvec: torch.Tensor, \n",
    "        Lvec: torch.Tensor\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        \n",
    "        # SCTLoss returns (loss, Triplet_val.clone().detach().cpu(), Triplet_idx.clone().detach().cpu(), hn_ratio, Pos, Neg)\n",
    "        return self.loss_fn(fvec, Lvec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f07ccb5",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f58e0cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PKSampler(Sampler[List[int]]):\n",
    "    def __init__(\n",
    "        self,\n",
    "        label_to_indices: Dict[str, List[int]],  # now full labels, e.g., \"10_orig\", \"10_forg\"\n",
    "        P: int,  # signers per batch\n",
    "        K: int,  # originals per signer\n",
    "        F: int,  # forgeries per signer\n",
    "        M: int,  # inter-signer negatives per signer\n",
    "        seed: int = 42,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        label_to_indices: Dict[label_string, List[idx]]\n",
    "            e.g., {\"10_orig\": [0,1,2], \"10_forg\": [25,26], \"11_orig\": [...], ...}\n",
    "        \"\"\"\n",
    "        self.P = P\n",
    "        self.K = K\n",
    "        self.F = F\n",
    "        self.M = M\n",
    "        self.label_to_indices = label_to_indices\n",
    "        self.signers = sorted({lbl.split(\"_\")[0] for lbl in label_to_indices.keys()})\n",
    "        self.seed = seed\n",
    "\n",
    "        # Precompute label-wise pools\n",
    "        self._all_indices: List[int] = []\n",
    "        self._indices_by_label: Dict[str, List[int]] = {}\n",
    "        self._indices_by_signer: Dict[str, List[int]] = defaultdict(list)\n",
    "        \n",
    "        for label, idxs in label_to_indices.items():\n",
    "            self._indices_by_label[label] = idxs\n",
    "            signer_id = label.split(\"_\")[0]\n",
    "            self._indices_by_signer[signer_id].extend(idxs)\n",
    "            self._all_indices.extend(idxs)\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return max(1, len(self.signers) // self.P * 10)\n",
    "\n",
    "    def __iter__(self) -> Iterator[List[int]]:\n",
    "        rng = random.Random(self.seed)\n",
    "        num_batches = len(self)\n",
    "        for _ in range(num_batches):\n",
    "            selected_signers = rng.sample(self.signers, self.P)\n",
    "            batch: List[int] = []\n",
    "\n",
    "            for sid in selected_signers:\n",
    "                orig_label = f\"{sid}_orig\"\n",
    "                forg_label = f\"{sid}_forg\"\n",
    "\n",
    "                originals = self._indices_by_label.get(orig_label, [])\n",
    "                forgeries = self._indices_by_label.get(forg_label, [])\n",
    "\n",
    "                # Sample K originals (anchor + positives)\n",
    "                pos = rng.sample(originals, self.K) if len(originals) >= self.K else rng.choices(originals, k=self.K)\n",
    "\n",
    "                # Sample F intra-signer forgeries as hard negatives\n",
    "                neg_hard = rng.sample(forgeries, self.F) if len(forgeries) >= self.F else rng.choices(forgeries, k=self.F)\n",
    "\n",
    "                # Sample M inter-signer negatives (any label from other signers)\n",
    "                global_pool = [idx for idx in self._all_indices if idx not in self._indices_by_signer[sid]]\n",
    "                neg_global = rng.sample(global_pool, self.M) if len(global_pool) >= self.M else rng.choices(global_pool, k=self.M)\n",
    "\n",
    "                batch.extend(pos + neg_hard + neg_global)\n",
    "\n",
    "            yield batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7fc95957",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SignatureDataset(Dataset[Tuple[torch.Tensor, str]]):\n",
    "    def __init__(\n",
    "        self, \n",
    "        data_map: Dict[str, Dict[str, List[str]]],\n",
    "        transform: Optional[Callable[[Image.Image], torch.Tensor]] = None,\n",
    "    ) -> None:\n",
    "        self.data_map = data_map\n",
    "        self.transform = transform\n",
    "        self.signer_ids = sorted(list(data_map.keys()), key=int)\n",
    "        \n",
    "        # signer id, image type, index\n",
    "        self.all_image_references: List[Tuple[str, str, int]] = []\n",
    "        # self.labels: List[int] = []\n",
    "        \n",
    "        for signer_id in self.signer_ids:\n",
    "            for index, _ in enumerate(data_map[signer_id].get(\"original\", [])):\n",
    "                self.all_image_references.append((signer_id, \"original\", index))\n",
    "            \n",
    "            for index, _ in enumerate(data_map[signer_id].get(\"forged\", [])):\n",
    "                self.all_image_references.append((signer_id, \"forged\", index))\n",
    "        \n",
    "        \n",
    "        self.labels = [\n",
    "            f\"{signer_id}_{img_type[:4]}\"  # \"orig\" or \"forg\"\n",
    "            for signer_id, img_type, _ in self.all_image_references\n",
    "        ]\n",
    "        \n",
    "\n",
    "    def __len__(self)->int:\n",
    "        return len(self.all_image_references)\n",
    "    \n",
    "    def __getitem__(self, index: int) -> Tuple[torch.Tensor, str]:\n",
    "        signer_id, image_type, image_index = self.all_image_references[index]\n",
    "                \n",
    "        path: str = self.data_map[signer_id][image_type][image_index]\n",
    "        \n",
    "        image_pil: Image.Image = Image.open(path).convert(\"L\")\n",
    "            \n",
    "        if self.transform is not None:\n",
    "            image_tensor: torch.Tensor = self.transform(image_pil)\n",
    "        else:\n",
    "            image_array: npt.NDArray[np.uint8] = np.array(image_pil, dtype=np.uint8)\n",
    "            image_tensor: torch.Tensor = torch.from_numpy(image_array).unsqueeze(0).float() / 255.0 # type: ignore\n",
    "        \n",
    "        label = f\"{signer_id}_{image_type[:4]}\"\n",
    "        \n",
    "        # signer_label_tensor = torch.tensor(int(signer_id), dtype=torch.long)\n",
    "        \n",
    "        return image_tensor, label\n",
    "        # return image_tensor, signer_label_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c78fad52",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestSignatureDataset(Dataset[Tuple[torch.Tensor, str]]):\n",
    "    \"\"\"\n",
    "    Produces samples in the exact order expected by build_verification_pairs():\n",
    "        sorted signer IDs → originals → forgeries\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_map: Dict[str, Dict[str, List[str]]],\n",
    "        transform: Optional[Callable[[Image.Image], torch.Tensor]] = None,\n",
    "    ) -> None:\n",
    "        self.data_map = data_map\n",
    "        self.transform = transform\n",
    "\n",
    "        # Ensure deterministic ordering\n",
    "        self.signer_ids = sorted(list(data_map.keys()), key=int)\n",
    "\n",
    "        # Build ordered list matching evaluation logic\n",
    "        self.ordered_items: List[Tuple[str, str, str]] = []\n",
    "        # (signer_id, \"original\"/\"forged\", path)\n",
    "\n",
    "        for sid in self.signer_ids:\n",
    "            for path in data_map[sid].get(\"original\", []):\n",
    "                self.ordered_items.append((sid, \"original\", path))\n",
    "\n",
    "            for path in data_map[sid].get(\"forged\", []):\n",
    "                self.ordered_items.append((sid, \"forged\", path))\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.ordered_items)\n",
    "\n",
    "    def __getitem__(self, index: int) -> Tuple[torch.Tensor, str]:\n",
    "        signer_id, _img_type, path = self.ordered_items[index]\n",
    "\n",
    "        image_pil = Image.open(path).convert(\"L\")\n",
    "\n",
    "        if self.transform is not None:\n",
    "            image_tensor: torch.Tensor = self.transform(image_pil)\n",
    "        else:\n",
    "            image_array: npt.NDArray[np.uint8] = np.array(image_pil, dtype=np.uint8)\n",
    "            image_tensor: torch.Tensor = torch.from_numpy(image_array).unsqueeze(0).float() / 255.0 # pyright: ignore[reportUnknownMemberType]\n",
    "        \n",
    "        # IMPORTANT:\n",
    "        # evaluation code expects label to be a *tensor containing string IDs*\n",
    "        # but torch can't store strings → so evaluation uses batching with collate_fn default\n",
    "        # Each label is kept as a Python string.\n",
    "        return image_tensor, signer_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3be25f0",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8267645b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(\n",
    "        self, \n",
    "        model: nn.Module,\n",
    "        loss_function: nn.Module,\n",
    "        learning_config: Dict[str, str | int | float],\n",
    "        optimiser_config: Dict[str, str | float],\n",
    "        scheduler_config: SchedulerConfig,\n",
    "        save_checkpoints: bool = True\n",
    "    ) -> None:\n",
    "        \n",
    "        self.model = model\n",
    "        \n",
    "        # Training loop\n",
    "        self.epoch = int(learning_config[\"EPOCH\"])\n",
    "        self.batch_size = int(learning_config[\"BATCH_SIZE\"])\n",
    "        self.lr = float(learning_config[\"LEARNING_RATE\"])\n",
    "        self.early_stop = int(learning_config[\"EARLY_STOPPING_PATIENT\"])\n",
    "        self.checkpoint_path = Path(str(learning_config[\"CHECKPOINT_DIR\"]))\n",
    "        self.save_checkpoints = bool(save_checkpoints)\n",
    "        self.device = torch.device(str(learning_config[\"DEVICE\"]))\n",
    "        self.device_type = self.device.type\n",
    "        self.global_step = 0\n",
    "        \n",
    "        self.best_val_auc = float(\"inf\")\n",
    "        self.patience_counter = 0\n",
    "        \n",
    "        # Optimiser\n",
    "        self.optimiser = self._build_optimiser(optimiser_config)\n",
    "        \n",
    "        # Scheduler\n",
    "        self.scheduler = self._build_scheduler(scheduler_config)\n",
    "\n",
    "        # Loss function\n",
    "        self.loss_function = loss_function\n",
    "        \n",
    "        # Mixed precision\n",
    "        self.scaler = GradScaler()\n",
    "        \n",
    "        # Moving to GPU\n",
    "        self.model.to(self.device)\n",
    "        \n",
    "        # checkpointing\n",
    "        self.checkpoint_path.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Tensorboard\n",
    "        log_dir = learning_config[\"LOG_DIR\"]\n",
    "        self.writer = SummaryWriter(log_dir)\n",
    "        \n",
    "    def train_epoch(\n",
    "        self, dataloader: DataLoader[Tuple[torch.Tensor, str]]\n",
    "    ) -> float:\n",
    "        self.model.train()\n",
    "        running_loss: float = 0.0\n",
    "        num_batches: int = len(dataloader)\n",
    "        \n",
    "        for batch_index, (images, labels) in enumerate(dataloader):\n",
    "            images = images.to(self.device)\n",
    "            unique_labels = sorted(set(labels))\n",
    "            label_to_int = {label: i for i, label in enumerate(unique_labels)}\n",
    "            label_tensor = torch.tensor([label_to_int[label] for label in labels], dtype=torch.long, device=self.device)\n",
    "        \n",
    "            self.optimiser.zero_grad()\n",
    "            \n",
    "            with autocast(device_type=self.device_type):\n",
    "                outputs = self.model(images)\n",
    "                \n",
    "                # SCTLoss returns (loss, triplet_vals, triplet_idxs, hn_ratio, Pos_log, Neg_log)\n",
    "                loss, triplet_vals, _triplet_idxs, hn_ratio, pos, neg= self.loss_function(outputs, label_tensor)\n",
    "                \n",
    "                # Vanilla Triplet Loss returns (loss, stats)\n",
    "                # loss, stats = self.loss_function(outputs, label_tensor)\n",
    "            \n",
    "            # Gradient clipping is optional\n",
    "            \n",
    "            self.scaler.scale(loss).backward()  # pyright: ignore[reportUnknownMemberType]\n",
    "            self.scaler.step(self.optimiser)\n",
    "            self.scaler.update()\n",
    "            \n",
    "            # OneCycleLR steps for batch, not epoch\n",
    "            if isinstance(self.scheduler, lr_scheduler.OneCycleLR):\n",
    "                self.scheduler.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            self.global_step += 1\n",
    "            \n",
    "            if batch_index % 19 == 0:\n",
    "                # For both SCT and vanilla Triplet Loss\n",
    "                self.writer.add_scalar(f\"Train/BatchLoss\", loss.item(), self.global_step) # pyright: ignore[reportUnknownMemberType]\n",
    "                \n",
    "                # # SCT\n",
    "                self.writer.add_scalar(f\"Train/HN_Ratio\", hn_ratio.item(), self.global_step) # pyright: ignore[reportUnknownMemberType]\n",
    "                self.writer.add_scalar(f\"Train/PosMean\", pos.mean().item(), self.global_step) # pyright: ignore[reportUnknownMemberType]\n",
    "                self.writer.add_scalar(f\"Train/NegMean\", neg.mean().item(), self.global_step) # pyright: ignore[reportUnknownMemberType]\n",
    "                \n",
    "                self.writer.add_histogram(f\"Train/Pos\", triplet_vals[:,0], self.global_step) # pyright: ignore[reportUnknownMemberType]\n",
    "                self.writer.add_histogram(f\"Train/Neg\", triplet_vals[:,1], self.global_step) # pyright: ignore[reportUnknownMemberType]\n",
    "                \n",
    "                # Vanilla Triplet Loss\n",
    "                # self.writer.add_scalar(\"Train/HN_Ratio\", stats[\"hn_ratio\"], self.global_step) # pyright: ignore[reportUnknownMemberType]\n",
    "                # self.writer.add_scalar(\"Train/PosMean\", stats[\"pos\"].mean().item(), self.global_step) # pyright: ignore[reportUnknownMemberType]\n",
    "                # self.writer.add_scalar(\"Train/NegMean\", stats[\"neg\"].mean().item(), self.global_step) # pyright: ignore[reportUnknownMemberType]\n",
    "\n",
    "                # self.writer.add_histogram(\"Train/Pos\", stats[\"triplet_vals\"][:,0], self.global_step) # pyright: ignore[reportUnknownMemberType]\n",
    "                # self.writer.add_histogram(\"Train/Neg\", stats[\"triplet_vals\"][:,1], self.global_step) # pyright: ignore[reportUnknownMemberType]\n",
    "                \n",
    "                total_norm: float = 0.\n",
    "                for p in self.model.parameters():\n",
    "                    if p.grad is not None:\n",
    "                        total_norm += float(p.grad.data.norm(2).item()) # pyright: ignore[reportUnknownArgumentType, reportUnknownMemberType]\n",
    "                        \n",
    "                self.writer.add_scalar(\"Gradients/TotalNorm\", total_norm, self.global_step) # pyright: ignore[reportUnknownMemberType]\n",
    "        \n",
    "        return running_loss / num_batches\n",
    "        \n",
    "    def evaluate(\n",
    "        self,\n",
    "        dataloader: DataLoader[Tuple[torch.Tensor, str]] \n",
    "    ) -> Tuple[\n",
    "            Dict[str, float], \n",
    "            torch.Tensor, \n",
    "            List[str]\n",
    "    ]:\n",
    "        self.model.eval()\n",
    "        all_embeddings_list: List[torch.Tensor] = []\n",
    "        all_labels: List[str] = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels in dataloader:\n",
    "                images = images.to(self.device)\n",
    "                \n",
    "                with autocast(device_type=self.device_type):\n",
    "                    embeddings = self.model(images)\n",
    "                    all_embeddings_list.append(embeddings.cpu())\n",
    "                    all_labels.extend(labels)\n",
    "        \n",
    "        all_embeddings = torch.cat(all_embeddings_list, dim=0)\n",
    "        n = len(all_labels)\n",
    "        \n",
    "        similarity_matrix = F.cosine_similarity(\n",
    "            all_embeddings.unsqueeze(1),\n",
    "            all_embeddings.unsqueeze(0),\n",
    "            dim=2\n",
    "        )\n",
    "        \n",
    "        signer_ids = [label.split(\"_\")[0] for label in all_labels]\n",
    "        intra_mask = torch.zeros((n, n), dtype=torch.bool)\n",
    "        inter_mask = torch.zeros((n, n), dtype=torch.bool)\n",
    "        \n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                if i == j:\n",
    "                    continue\n",
    "                if signer_ids[i] == signer_ids[j]:\n",
    "                    intra_mask[i, j] = True\n",
    "                else:\n",
    "                    inter_mask[i, j] = True\n",
    "\n",
    "        intra_sims: torch.Tensor = similarity_matrix[intra_mask] \n",
    "        inter_sims: torch.Tensor = similarity_matrix[inter_mask]  \n",
    "\n",
    "        intra_sims_np = intra_sims.cpu().numpy() # type: ignore\n",
    "        inter_sims_np = inter_sims.cpu().numpy() # type: ignore\n",
    "\n",
    "        # Metrics\n",
    "        y_true = [1] * len(intra_sims_np) + [0] * len(inter_sims_np) # type: ignore\n",
    "        y_scores = list(intra_sims_np) + list(inter_sims_np) # type: ignore\n",
    "        auc = roc_auc_score(y_true, y_scores)\n",
    "\n",
    "        metrics: Dict[str, float | int] = {\n",
    "            \"AUC\": auc, # type: ignore\n",
    "            \"mean_intra_similarity\": float(intra_sims.mean()),\n",
    "            \"mean_inter_similarity\": float(inter_sims.mean()),\n",
    "            \"num_intra_pairs\": len(intra_sims),\n",
    "            \"num_inter_pairs\": len(inter_sims)\n",
    "        }\n",
    "\n",
    "        return metrics, all_embeddings, all_labels\n",
    "    \n",
    "    def fit(\n",
    "        self, \n",
    "        train_dataloader: DataLoader[Tuple[torch.Tensor, str]],\n",
    "        val_dataloader: DataLoader[Tuple[torch.Tensor, str]]\n",
    "    ) -> None: \n",
    "        for epoch in range(self.epoch):\n",
    "            train_loss = self.train_epoch(train_dataloader)\n",
    "            val_metrics, val_embedding, all_labels = self.evaluate(val_dataloader)\n",
    "            \n",
    "            self.writer.add_embedding( # pyright: ignore[reportUnknownMemberType]\n",
    "                mat = val_embedding,\n",
    "                metadata=all_labels,\n",
    "                global_step=self.global_step\n",
    "            )\n",
    "            \n",
    "            self.writer.add_scalar(\"Loss/train\", train_loss, epoch) # pyright: ignore[reportUnknownMemberType]\n",
    "            self.writer.add_scalar(\"AUC/val\", val_metrics[\"AUC\"], epoch) # pyright: ignore[reportUnknownMemberType]\n",
    "            # I should change this to include loss value from validation too\n",
    "            self.writer.add_scalar(\"Loss/1_minus_auc\", 1.0 - val_metrics[\"AUC\"], epoch) # pyright: ignore[reportUnknownMemberType] \n",
    "            self.writer.add_scalar(\"Learning rate\", self.optimiser.param_groups[0][\"lr\"], epoch) # pyright: ignore[reportUnknownMemberType]\n",
    "            \n",
    "            if self.scheduler is not None and not isinstance(self.scheduler, lr_scheduler.OneCycleLR):\n",
    "                self.scheduler.step()\n",
    "\n",
    "            print(f\"Epoch [{epoch + 1}/{self.epoch}]\"\n",
    "                  f\"| Train loss: {train_loss:.4f}\"\n",
    "                  f\"| AUC: {val_metrics[\"AUC\"]:.4f}\")\n",
    "        \n",
    "            val_auc_for_stop = 1.0 - val_metrics[\"AUC\"]\n",
    "            if val_auc_for_stop < self.best_val_auc:\n",
    "                self.best_val_auc = val_auc_for_stop\n",
    "                self.patience_counter = 0\n",
    "                if self.save_checkpoints:\n",
    "                    self._save_checkpoint(epoch, val_auc_for_stop, self.best_val_auc, self.patience_counter)\n",
    "            else:\n",
    "                self.patience_counter+=1\n",
    "                if self.patience_counter >= self.early_stop:\n",
    "                    print(\"Early stopping\")\n",
    "                    break\n",
    "        \n",
    "        self.writer.close()\n",
    "    \n",
    "    def load_checkpoint(\n",
    "        self, \n",
    "        path: str\n",
    "    ) -> None:\n",
    "        \n",
    "        self._has_path(path)\n",
    "        try:\n",
    "            checkpoint_model: ModelState = torch.load(path, map_location=self.device)\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Error loading checkpoint from {path}: {e}\")\n",
    "        \n",
    "        self.model.load_state_dict(checkpoint_model[\"model_state_dict\"])\n",
    "        self.optimiser.load_state_dict(checkpoint_model[\"optimiser_state_dict\"])\n",
    "        \n",
    "        if self.scheduler and checkpoint_model[\"scheduler_state_dict\"] is not None:\n",
    "            self.scheduler.load_state_dict(checkpoint_model[\"scheduler_state_dict\"])\n",
    "        \n",
    "        self.epoch = checkpoint_model[\"epoch\"]\n",
    "        self.best_val_auc = checkpoint_model[\"best_loss\"]\n",
    "        self.patience_counter = checkpoint_model[\"patience_counter\"]\n",
    "    \n",
    "    def _save_checkpoint(\n",
    "        self, \n",
    "        epoch: int, \n",
    "        auc: float, \n",
    "        best_auc: float, \n",
    "        patience_counter: int,\n",
    "    ) -> None:\n",
    "        model_state: ModelState = {\n",
    "            \"epoch\": epoch,\n",
    "            \"model_state_dict\": self.model.state_dict(),\n",
    "            \"optimiser_state_dict\": self.optimiser.state_dict(),\n",
    "            \"scheduler_state_dict\": self.scheduler.state_dict() if self.scheduler else None,\n",
    "            \"auc\": auc,\n",
    "            \"best_loss\": best_auc,\n",
    "            \"patience_counter\": patience_counter\n",
    "        }\n",
    "        \n",
    "        torch.save(\n",
    "            model_state, self.checkpoint_path / f\"{epoch+1}_auc_{auc:.4f}.pt\"\n",
    "        )\n",
    "    \n",
    "    def _has_path(self, path: str) -> None:\n",
    "        if not Path(path).exists():\n",
    "            raise FileNotFoundError(f\"File not found at {path}\")\n",
    "        print(f\"File is ok!\")\n",
    "                \n",
    "    def _build_optimiser(self, optimiser_config: Dict[str, str | float]) -> optim.Optimizer:\n",
    "        optimiser_name =  str(optimiser_config[\"optimiser\"])\n",
    "        optimiser_class = getattr(optim, optimiser_name)\n",
    "        \n",
    "        optimiser_params = {**optimiser_config}\n",
    "        optimiser_params.pop(\"optimiser\")\n",
    "        optimiser_params[\"lr\"] = self.lr\n",
    "        \n",
    "        return optimiser_class(self.model.parameters(), **optimiser_params)\n",
    "        \n",
    "    def _build_scheduler(\n",
    "        self, \n",
    "        scheduler_config: SchedulerConfig,\n",
    "        ) -> Optional[lr_scheduler.LRScheduler]:\n",
    "        schedulers: List[lr_scheduler.LRScheduler] = []\n",
    "         \n",
    "        for sched_cfg in scheduler_config.get(\"SCHEDULERS\", []):\n",
    "            name = sched_cfg[\"name\"]\n",
    "            params = sched_cfg.get(\"params\", {})\n",
    "            sched_class = getattr(lr_scheduler, name)\n",
    "            schedulers.append(sched_class(self.optimiser, **params))\n",
    "\n",
    "        if scheduler_config.get(\"SCHEDULER\") == \"SequentialLR\":\n",
    "            return lr_scheduler.SequentialLR(\n",
    "                self.optimiser,\n",
    "                schedulers=schedulers,\n",
    "                milestones=scheduler_config.get(\"MILESTONES\", [])\n",
    "            )\n",
    "        \n",
    "        return schedulers[0] if schedulers else None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853218a0",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e234a665",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(\n",
    "    pos_scores: List[float],\n",
    "    neg_scores: List[float]\n",
    ") -> Dict[str, Any]:\n",
    "    \n",
    "    metrics: Dict[str, Any] = {\n",
    "        \"AUC\": float(\"nan\"),\n",
    "        \"EER\": float(\"nan\"),\n",
    "        \"threshold\": float(\"nan\"),\n",
    "        \"fpr\": np.array([]),\n",
    "        \"tpr\": np.array([]),\n",
    "    }\n",
    "    \n",
    "    if len(pos_scores) == 0 or len(neg_scores) == 0:\n",
    "        return metrics\n",
    "    \n",
    "    y_true = [1] * len(pos_scores) + [0] * len(neg_scores)\n",
    "    y_score = pos_scores + neg_scores\n",
    "    \n",
    "    try:\n",
    "        auc = roc_auc_score(y_true, y_score)\n",
    "    except Exception:\n",
    "        metrics[\"AUC\"] = float(\"nan\")\n",
    "        return metrics\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_score) # pyright: ignore[reportUnknownVariableType]\n",
    "\n",
    "    fnr = 1 - tpr # pyright: ignore[reportUnknownVariableType]\n",
    "    abs_diffs = np.abs(fnr - fpr) # pyright: ignore[reportUnusedVariable, reportUnknownArgumentType]\n",
    "    eer_index = int(np.argmin(abs_diffs))\n",
    "    \n",
    "    eer = float((fnr[eer_index] + fpr[eer_index]) / 2.0)\n",
    "    threshold = float(thresholds[eer_index])\n",
    "\n",
    "    metrics.update({\n",
    "        \"AUC\": float(auc),\n",
    "        \"EER\": eer,\n",
    "        \"threshold\": threshold,\n",
    "        \"fpr\": fpr,\n",
    "        \"tpr\": tpr,\n",
    "        \"thresholds\":thresholds\n",
    "    })\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e140e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_scores(\n",
    "    embeddings: torch.Tensor,\n",
    "    pairs: List[Tuple[int, int]]\n",
    ") -> List[float]:\n",
    "    scores: List[float] = []\n",
    "    if len(pairs) == 0:\n",
    "        return scores\n",
    "    \n",
    "    for i, j in pairs:\n",
    "        if i < 0 or j < 0 or i >= embeddings.shape[0] or j >= embeddings.shape[0]:\n",
    "            continue\n",
    "        sim = F.cosine_similarity(\n",
    "            embeddings[i].unsqueeze(0),\n",
    "            embeddings[j].unsqueeze(0),\n",
    "        ).item()\n",
    "        scores.append(float(sim))\n",
    "    return scores    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9fcaebcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_verification_pairs(\n",
    "    embeddings: torch.Tensor,\n",
    "    test_map: Dict[str, Dict[str, List[str]]]\n",
    ") -> Tuple[List[Tuple[int, int]], List[Tuple[int, int]], List[Tuple[int, int]]]: \n",
    "    num_samples = embeddings.shape[0]\n",
    "    \n",
    "    ordered_paths: List[Tuple[str, str, str]] = []\n",
    "    # ordered_types = []\n",
    "    \n",
    "    for signer_id in sorted(test_map.keys(), key=int):\n",
    "        for path in test_map[signer_id].get(\"original\", []):\n",
    "            ordered_paths.append((signer_id, \"original\", path))\n",
    "    \n",
    "        for path in test_map[signer_id].get(\"forged\", []):\n",
    "            ordered_paths.append((signer_id, \"forged\", path))\n",
    "    \n",
    "    assert len(ordered_paths) == num_samples, \\\n",
    "        \"Embedding count does not match number of test images.\"\n",
    "        \n",
    "    # signer_to_indices = {}\n",
    "    orig_indices: Dict[str, List[int]] = {}\n",
    "    forg_indices: Dict[str, List[int]] = {}\n",
    "    \n",
    "    for index, (sid, t, _) in enumerate(ordered_paths):\n",
    "        # signer_to_indices.setdefault(sid, []).append(index)\n",
    "        if t == \"original\":\n",
    "            orig_indices.setdefault(sid, []).append(index)\n",
    "        else: forg_indices.setdefault(sid, []).append(index)\n",
    "    \n",
    "    pos_pairs: List[Tuple[int, int]] = []\n",
    "    for sid, indices in orig_indices.items():\n",
    "        if len(indices) >= 2:\n",
    "            for i, j in combinations(indices, 2):\n",
    "                pos_pairs.append((i, j))\n",
    "    \n",
    "    intra_neg_pairs: List[Tuple[int, int]] = []\n",
    "    for sid in orig_indices.keys():\n",
    "        o_idxs = orig_indices[sid]\n",
    "        f_idxs = forg_indices.get(sid, [])\n",
    "        for i in o_idxs:\n",
    "            for j in f_idxs:\n",
    "                intra_neg_pairs.append((i, j))\n",
    "    \n",
    "    inter_neg_pairs: List[Tuple[int, int]] = []\n",
    "    sids = list(orig_indices.keys())  # original-only ensures consistency\n",
    "\n",
    "    for sid_a, sid_b in combinations(sids, 2):\n",
    "        for i in orig_indices[sid_a]:\n",
    "            for j in orig_indices[sid_b]:\n",
    "                inter_neg_pairs.append((i, j))\n",
    "                \n",
    "    return pos_pairs, intra_neg_pairs, inter_neg_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a61b524b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_all(\n",
    "    model: nn.Module, \n",
    "    dataloader: DataLoader[Tuple[torch.Tensor, str]], \n",
    "    device: torch.device\n",
    ") -> torch.Tensor:\n",
    "    \n",
    "    model.eval()\n",
    "    embeddings_list: List[torch.Tensor] = []\n",
    "    # labels_list: List[str] = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, _signer_ids in dataloader:\n",
    "            images = images.to(device)\n",
    "            embedding = model(images)\n",
    "            embeddings_list.append(embedding.cpu())\n",
    "            # labels_list.append(signer_ids.cpu())\n",
    "            \n",
    "    all_embeddings = torch.cat(embeddings_list)\n",
    "    # labels = torch.cat(labels_list)\n",
    "    \n",
    "    return all_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "83d791f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_operating_point(fpr: Any, tpr: Any, thresholds: Any, chosen_threshold: Any):\n",
    "    # Find the index closest to your chosen threshold\n",
    "    idx = (np.abs(thresholds - chosen_threshold)).argmin()\n",
    "    return {\n",
    "        \"threshold\": thresholds[idx],\n",
    "        \"TPR\": tpr[idx],   # genuine acceptance rate\n",
    "        \"FPR\": fpr[idx],   # forgery acceptance rate\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "61a78242",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(pos_scores: List[float], neg_scores: List[float], threshold: float) -> float:\n",
    "    if len(pos_scores) == 0 and len(neg_scores) == 0:\n",
    "        return float(\"nan\")\n",
    "    \n",
    "    # Genuine pairs should be above threshold\n",
    "    pos_correct = sum([1 for s in pos_scores if s >= threshold])\n",
    "    # Forgery pairs should be below threshold\n",
    "    neg_correct = sum([1 for s in neg_scores if s < threshold])\n",
    "    \n",
    "    total = len(pos_scores) + len(neg_scores)\n",
    "    correct = pos_correct + neg_correct\n",
    "    \n",
    "    return correct / total if total > 0 else float(\"nan\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "accd9703",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(\n",
    "    model: nn.Module, \n",
    "    test_loader: DataLoader[Tuple[torch.Tensor, str]], \n",
    "    test_map:  Dict[str, Dict[str, List[str]]],\n",
    "    device: torch.device\n",
    ") -> Dict[str, Any]:\n",
    "    model.to(device)\n",
    "    \n",
    "    # Applying the model\n",
    "    embeddings = embed_all(model, test_loader, device)\n",
    "\n",
    "    # original, easy, and hard forgery  \n",
    "    pos_pairs, intra_pairs, inter_pairs = build_verification_pairs(embeddings, test_map)\n",
    "\n",
    "    # Intra and Inter\n",
    "    neg_pairs = intra_pairs + inter_pairs\n",
    "    \n",
    "    # Compute similarities\n",
    "    pos_scores = compute_scores(embeddings, pos_pairs)\n",
    "    neg_scores = compute_scores(embeddings, neg_pairs)\n",
    "\n",
    "    # Metrics\n",
    "    metrics = compute_metrics(pos_scores, neg_scores)\n",
    "    op_point = summarize_operating_point(\n",
    "        metrics[\"fpr\"], metrics[\"tpr\"], thresholds=metrics[\"thresholds\"], chosen_threshold=metrics[\"threshold\"]\n",
    "    )\n",
    "    accuracy = compute_accuracy(pos_scores, neg_scores, metrics[\"threshold\"])\n",
    "    metrics[\"accuracy\"] = accuracy\n",
    "\n",
    "    print(f\"At threshold {op_point['threshold']:.3f}:\")\n",
    "    print(f\"  TPR (genuine accepted) = {op_point['TPR']*100:.1f}%\")\n",
    "    print(f\"  FPR (forgeries accepted) = {op_point['FPR']*100:.1f}%\")\n",
    "\n",
    "    return {\n",
    "        # \"embeddings\": embeddings,\n",
    "        \"pos_scores\": sum(pos_scores)/len(pos_scores),\n",
    "        \"neg_scores\": sum(neg_scores)/len(neg_scores),\n",
    "        \"metrics\": metrics,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84818559",
   "metadata": {},
   "source": [
    "# Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "02bc2d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_signer_id(file_name: str) -> str:\n",
    "    match = re.search(r\"(?:original|forgeries|forgery|forged)_(\\d+)_\", file_name)\n",
    "    if match: return match.group(1) \n",
    "    return f\"UNKNOWN_SIGNER\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2685da9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_signature_images(\n",
    "    images_path: Path, \n",
    ") -> List[Tuple[str, str]]:\n",
    "    \n",
    "    signature_images: List[Tuple[str, str]] = []\n",
    "    if not images_path.is_dir():\n",
    "        print(f\"Warning: Directory not found! {images_path}\") \n",
    "        return []\n",
    "    for image_path in images_path.iterdir():\n",
    "        if image_path.is_file() and image_path.suffix.lower() in IMAGE_FORMATS:\n",
    "            signer_id = extract_signer_id(str(image_path))\n",
    "            if signer_id != \"UNKNOWN_SIGNER\":\n",
    "                signature_images.append((signer_id, str(image_path)))\n",
    "            else:\n",
    "                print(\n",
    "                    f\"Warning: Could not extract signer ID from file: {image_path.name}\"\n",
    "                )\n",
    "    return signature_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fe463a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_signature_map(\n",
    "    original_signatures: List[Tuple[str, str]],\n",
    "    forged_signatures: List[Tuple[str, str]],\n",
    ") -> Dict[str, Dict[str, List[str]]]:\n",
    "    \n",
    "    signature_dictionary: defaultdict[str, Dict[str, List[Any]]] = defaultdict(\n",
    "        lambda: {\n",
    "            \"original\": [], \n",
    "            \"forged\": []\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    for category, signatures in [(\"original\", original_signatures),\n",
    "                                 (\"forged\", forged_signatures)]:\n",
    "        for signer_id, image_path in signatures:\n",
    "            signature_dictionary[signer_id][category].append(image_path)\n",
    "            \n",
    "    return signature_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "92684e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_and_testing_split(\n",
    "    signature_dictionary: Dict[str, Dict[str, List[str]]],\n",
    "    test_ratio: float = 0.2,\n",
    "    val_ratio: float = 0.1,\n",
    "    random_state: int = 42,\n",
    ") -> Tuple[\n",
    "        Dict[str, Dict[str, List[str]]], \n",
    "        Dict[str, Dict[str, List[str]]],\n",
    "        Dict[str, Dict[str, List[str]]]\n",
    "    ]:\n",
    "    train_map: Dict[str, Dict[str, List[str]]] = {}\n",
    "    val_map: Dict[str, Dict[str, List[str]]] = {}\n",
    "    test_map: Dict[str, Dict[str, List[str]]] = {} \n",
    "    \n",
    "    signer_ids: List[str] = sorted(list(signature_dictionary.keys()), key=int)\n",
    "    \n",
    "    strat_labels: List[int] = []\n",
    "    for sid in signer_ids:\n",
    "        originals = len(signature_dictionary[sid].get(\"original\", []))\n",
    "        forgeries = len(signature_dictionary[sid].get(\"forged\", []))\n",
    "        strat_labels.append(0 if originals >= forgeries else 1)\n",
    "\n",
    "    train_val_ids, test_ids = train_test_split( # pyright: ignore[reportUnknownVariableType]\n",
    "        signer_ids,\n",
    "        test_size=test_ratio,\n",
    "        random_state=random_state,\n",
    "        stratify=strat_labels,\n",
    "    )\n",
    "\n",
    "    strat_labels_train_val = [\n",
    "        strat_labels[signer_ids.index(sid)] for sid in train_val_ids  # type: ignore\n",
    "    ]\n",
    "    val_size = val_ratio / (1 - test_ratio)\n",
    "    train_ids, val_ids = train_test_split( # pyright: ignore[reportUnknownVariableType]\n",
    "        train_val_ids, # pyright: ignore[reportUnknownArgumentType]\n",
    "        test_size=val_size,\n",
    "        random_state=random_state,\n",
    "        stratify=strat_labels_train_val,\n",
    "    )\n",
    "\n",
    "    train_map = {sid: signature_dictionary[sid] for sid in train_ids} # pyright: ignore[reportUnknownVariableType]\n",
    "    val_map = {sid: signature_dictionary[sid] for sid in val_ids} # pyright: ignore[reportUnknownVariableType]\n",
    "    test_map = {sid: signature_dictionary[sid] for sid in test_ids} # pyright: ignore[reportUnknownVariableType] \n",
    "\n",
    "    return train_map, val_map, test_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6672080c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_label_to_indices(dataset: SignatureDataset) -> dict[str, List[int]]:\n",
    "    label_to_indices: DefaultDict[str, List[int]] = defaultdict(list)\n",
    "    for index in range(len(dataset)):\n",
    "        _, label = dataset[index]\n",
    "        label_to_indices[label].append(index)\n",
    "    \n",
    "    return dict(label_to_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "082097a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_metrics(metrics: Dict[str, Any]) -> None:\n",
    "    print(\"=== Evaluation Metrics ===\")\n",
    "    print(f\"AUC       : {metrics['AUC']:.4f}\")\n",
    "    print(f\"EER       : {metrics['EER']:.4f}\")\n",
    "    print(f\"Threshold : {metrics['threshold']:.4f}\")\n",
    "    \n",
    "    # Summarize ROC curve\n",
    "    fpr = metrics['fpr']\n",
    "    tpr = metrics['tpr']\n",
    "    if len(fpr) > 0:\n",
    "        print(f\"ROC Points: {len(fpr)}\")\n",
    "        print(f\"FPR range : {fpr.min():.4f} → {fpr.max():.4f}\")\n",
    "        print(f\"TPR range : {tpr.min():.4f} → {tpr.max():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea12504",
   "metadata": {},
   "source": [
    "# Driver Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6407b466",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x21fc92e74f0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_everything(42)\n",
    "g = torch.Generator()\n",
    "g.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "95d359c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "        transforms.Resize((384, 384)),\n",
    "        transforms.RandomAffine(\n",
    "            degrees=(-5, 5), \n",
    "            translate=(0.1, 0.1), \n",
    "            scale=(0.95, 1.05), \n",
    "            shear=(-5, 5)\n",
    "        ),\n",
    "\n",
    "        transforms.RandomResizedCrop(\n",
    "            (384, 384), \n",
    "            scale=(0.9, 1.05), \n",
    "            ratio=(0.95, 1.05), \n",
    "            antialias=True\n",
    "        ),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean=[0.5], std=[0.5]\n",
    "    )])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "        transforms.Resize((384, 384)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean=[0.5], std=[0.5]\n",
    "    )])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "435c19cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path: Path = Path(DATASET_PATH[\"CEDAR\"])\n",
    "original_signatures = retrieve_signature_images(dataset_path / \"original\")\n",
    "forged_signatures = retrieve_signature_images(dataset_path / \"forged\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fc35ba6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "signature_map = prepare_signature_map(original_signatures, forged_signatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6964cde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_map, val_map, test_map = training_and_testing_split(\n",
    "    signature_map, test_ratio=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "07f610d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SignatureDataset(train_map, train_transform)\n",
    "val_dataset = SignatureDataset(val_map, test_transform)\n",
    "\n",
    "test_dataset = TestSignatureDataset(test_map, test_transform)\n",
    "train_dataset_for_evaluation = TestSignatureDataset(train_map, test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dad4252e",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_indices = build_label_to_indices(train_dataset)\n",
    "train_sampler = PKSampler(label_to_indices, 8, 2, 2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5d133e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_sampler=train_sampler, \n",
    "    pin_memory=True, \n",
    "    worker_init_fn=seed_worker, \n",
    "    generator=g\n",
    ")\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset, \n",
    "    int(LEARNING_CONFIG[\"BATCH_SIZE\"]), \n",
    "    shuffle=False, \n",
    "    pin_memory=True, \n",
    "    worker_init_fn=seed_worker\n",
    ")\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    int(LEARNING_CONFIG[\"BATCH_SIZE\"]),\n",
    "    shuffle=False\n",
    ")\n",
    "train_dataloader_for_evaluation = DataLoader(\n",
    "    train_dataset_for_evaluation,\n",
    "    int(LEARNING_CONFIG[\"BATCH_SIZE\"]),\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ffd2a9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FeatureExtractionModel(\"efficientnet_v2_m\", 256, \"IMAGENET1K_V1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "91c2dce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_function = TripletLoss(0.5,\"batch_semi_hard\", use_diversity=False)\n",
    "loss_function = SCTLossWrapper(method=\"sct\", lam=1.0, margin=0.5, positive_pull_weight=0.5, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2030c3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_trainer = Trainer(\n",
    "    model,\n",
    "    loss_function,\n",
    "    LEARNING_CONFIG,\n",
    "    OPTIMISER_PARAMS,\n",
    "    SCHEDULER_PARAMS,\n",
    "    True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7dccd1a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No easy triplets in the batch\n",
      "No easy triplets in the batch\n",
      "loss:0.4316 hn_rt:0.9024\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[40]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mmodel_trainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 186\u001b[39m, in \u001b[36mTrainer.fit\u001b[39m\u001b[34m(self, train_dataloader, val_dataloader)\u001b[39m\n\u001b[32m    180\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfit\u001b[39m(\n\u001b[32m    181\u001b[39m     \u001b[38;5;28mself\u001b[39m, \n\u001b[32m    182\u001b[39m     train_dataloader: DataLoader[Tuple[torch.Tensor, \u001b[38;5;28mstr\u001b[39m]],\n\u001b[32m    183\u001b[39m     val_dataloader: DataLoader[Tuple[torch.Tensor, \u001b[38;5;28mstr\u001b[39m]]\n\u001b[32m    184\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m: \n\u001b[32m    185\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m.epoch):\n\u001b[32m--> \u001b[39m\u001b[32m186\u001b[39m         train_loss = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    187\u001b[39m         val_metrics, val_embedding, all_labels = \u001b[38;5;28mself\u001b[39m.evaluate(val_dataloader)\n\u001b[32m    189\u001b[39m         \u001b[38;5;28mself\u001b[39m.writer.add_embedding( \u001b[38;5;66;03m# pyright: ignore[reportUnknownMemberType]\u001b[39;00m\n\u001b[32m    190\u001b[39m             mat = val_embedding,\n\u001b[32m    191\u001b[39m             metadata=all_labels,\n\u001b[32m    192\u001b[39m             global_step=\u001b[38;5;28mself\u001b[39m.global_step\n\u001b[32m    193\u001b[39m         )\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 76\u001b[39m, in \u001b[36mTrainer.train_epoch\u001b[39m\u001b[34m(self, dataloader)\u001b[39m\n\u001b[32m     69\u001b[39m     loss, triplet_vals, _triplet_idxs, hn_ratio, pos, neg= \u001b[38;5;28mself\u001b[39m.loss_function(outputs, label_tensor)\n\u001b[32m     71\u001b[39m     \u001b[38;5;66;03m# Vanilla Triplet Loss returns (loss, stats)\u001b[39;00m\n\u001b[32m     72\u001b[39m     \u001b[38;5;66;03m# loss, stats = self.loss_function(outputs, label_tensor)\u001b[39;00m\n\u001b[32m     73\u001b[39m \n\u001b[32m     74\u001b[39m \u001b[38;5;66;03m# Gradient clipping is optional\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mscaler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscale\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pyright: ignore[reportUnknownMemberType]\u001b[39;00m\n\u001b[32m     77\u001b[39m \u001b[38;5;28mself\u001b[39m.scaler.step(\u001b[38;5;28mself\u001b[39m.optimiser)\n\u001b[32m     78\u001b[39m \u001b[38;5;28mself\u001b[39m.scaler.update()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\projects\\signature_verification\\.venv\\Lib\\site-packages\\torch\\_tensor.py:625\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    615\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    616\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    617\u001b[39m         Tensor.backward,\n\u001b[32m    618\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    623\u001b[39m         inputs=inputs,\n\u001b[32m    624\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m625\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    626\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\projects\\signature_verification\\.venv\\Lib\\site-packages\\torch\\autograd\\__init__.py:354\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    349\u001b[39m     retain_graph = create_graph\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    353\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m354\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\projects\\signature_verification\\.venv\\Lib\\site-packages\\torch\\autograd\\graph.py:841\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    839\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    840\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m841\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    842\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    844\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    845\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "model_trainer.fit(train_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082c94d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File is ok!\n"
     ]
    }
   ],
   "source": [
    "# model_trainer.load_checkpoint(\"checkpoint/exp_01_mod_sct/15_auc_0.0692.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4b9bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At threshold 0.675:\n",
      "  TPR (genuine accepted) = 88.9%\n",
      "  FPR (forgeries accepted) = 11.1%\n",
      "Accuracy: 88.8946%\n",
      "\n",
      "Positive and Negative Scores\n",
      "Positive Score: 0.8401\n",
      "Negative Score: 0.2011\n",
      "\n",
      "=== Evaluation Metrics ===\n",
      "AUC       : 0.9568\n",
      "EER       : 0.1112\n",
      "Threshold : 0.6745\n",
      "ROC Points: 3167\n",
      "FPR range : 0.0000 → 1.0000\n",
      "TPR range : 0.0000 → 1.0000\n"
     ]
    }
   ],
   "source": [
    "result = evaluate(model, test_dataloader, test_map, torch.device(\"cuda\"))\n",
    "print(f\"Accuracy: {(result[\"metrics\"][\"accuracy\"])*100:.4f}%\\n\")\n",
    "print(\"Positive and Negative Scores\")\n",
    "print(f\"Positive Score: {result[\"pos_scores\"]:.4f}\\n\"\n",
    "      f\"Negative Score: {result[\"neg_scores\"]:.4f}\\n\")\n",
    "pretty_metrics(result[\"metrics\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc7737f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At threshold 0.720:\n",
      "  TPR (genuine accepted) = 99.6%\n",
      "  FPR (forgeries accepted) = 0.4%\n",
      "Accuracy: 99.6225%\n",
      "\n",
      "Positive and Negative Scores\n",
      "Positive Score: 0.9748\n",
      "Negative Score: 0.1145\n",
      "\n",
      "=== Evaluation Metrics ===\n",
      "AUC       : 0.9999\n",
      "EER       : 0.0038\n",
      "Threshold : 0.7205\n",
      "ROC Points: 4811\n",
      "FPR range : 0.0000 → 1.0000\n",
      "TPR range : 0.0000 → 1.0000\n"
     ]
    }
   ],
   "source": [
    "result = evaluate(model, train_dataloader_for_evaluation, train_map, torch.device(\"cuda\"))\n",
    "print(f\"Accuracy: {(result[\"metrics\"][\"accuracy\"])*100:.4f}%\\n\")\n",
    "print(\"Positive and Negative Scores\")\n",
    "print(f\"Positive Score: {result[\"pos_scores\"]:.4f}\\n\"\n",
    "      f\"Negative Score: {result[\"neg_scores\"]:.4f}\\n\")\n",
    "pretty_metrics(result[\"metrics\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e646be27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_trainer._save_checkpoint(24, 0.1051, 0.0692, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127eb5ae",
   "metadata": {},
   "source": [
    "# Because I just wanted to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3577d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(\n",
    "    reference_feature_embeddings: torch.Tensor, input_feature_embeddings: torch.Tensor\n",
    ") -> Tuple[float, float, float, float, float]:\n",
    "    similarity = F.cosine_similarity(\n",
    "        reference_feature_embeddings, input_feature_embeddings\n",
    "    ).item()\n",
    "\n",
    "    distance = F.pairwise_distance(\n",
    "        reference_feature_embeddings, input_feature_embeddings\n",
    "    ).item()\n",
    "\n",
    "    normalised_distance = max(0, min(1, distance / 1.3))\n",
    "    distance_score = 1 - normalised_distance\n",
    "\n",
    "    # Greater emphasis is placed on the distance calculated.\n",
    "    confidence_score = 0.8 * similarity + 0.2 * distance_score\n",
    "\n",
    "    return similarity, confidence_score, normalised_distance, distance_score, distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4094d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_threshold(\n",
    "    similarity: float, \n",
    "    distance: float,\n",
    "    confidence_score: float,\n",
    "    result: Dict[str, bool | float | str]\n",
    ") -> None:\n",
    "    pass_thresholds = (\n",
    "        similarity >= 0.5 and \n",
    "        distance <= 1.07\n",
    "    )\n",
    "    \n",
    "    if pass_thresholds:\n",
    "        if confidence_score >= 0.9:\n",
    "            result['prediction_level'] = 'Very High Confidence'\n",
    "            result['is_genuine'] = True\n",
    "        elif confidence_score >= 0.8:\n",
    "            result['prediction_level'] = 'High Confidence'\n",
    "            result['is_genuine'] = True\n",
    "        elif confidence_score >= 0.7:\n",
    "            result['prediction_level'] = 'Medium Confidence'\n",
    "            result['is_genuine'] = True\n",
    "        elif confidence_score >= 0.6:\n",
    "            result['prediction_level'] = 'Low Confidence'\n",
    "        else:\n",
    "            result['prediction_level'] = \"Very Low Confidence\"\n",
    "    else:\n",
    "        result['prediction_level'] = 'Failed Threshold Check'\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478474a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_model(\n",
    "    reference_tensor: torch.Tensor,\n",
    "    forged_same_signer_tensor: torch.Tensor,\n",
    ") -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    \n",
    "    reference_feature_embeddings = torch.Tensor(model(reference_tensor))\n",
    "    forged_same_signer_feature_embeddings = torch.Tensor(model(\n",
    "        forged_same_signer_tensor\n",
    "    ))\n",
    "    return (\n",
    "        reference_feature_embeddings,\n",
    "        forged_same_signer_feature_embeddings,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4414476f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(55):  # signer IDs\n",
    "    for j in range(23):  # pick one original signature\n",
    "        reference_signature_image_path = Path(\n",
    "            f\"data/CEDAR/original/original_{i+1}_{j+1}.png\"\n",
    "        )\n",
    "        reference_image = Image.open(str(reference_signature_image_path)).convert(\"L\")\n",
    "        reference_tensor = test_transform(reference_image).unsqueeze(0).to(\"cuda\") # pyright: ignore[reportUnknownVariableType, reportAttributeAccessIssue, reportUnknownMemberType]\n",
    "\n",
    "        # Now compare this original against *all forgeries* of this signer\n",
    "        for k in range(23):  \n",
    "            forged_input_same_signer = Path(\n",
    "                f\"data/CEDAR/forged/forgeries_{i+1}_{k+1}.png\"\n",
    "            )\n",
    "            forged_same_signer = Image.open(str(forged_input_same_signer)).convert(\"L\")\n",
    "            forged_tensor = test_transform(forged_same_signer).unsqueeze(0).to(\"cuda\") # pyright: ignore[reportUnknownVariableType, reportAttributeAccessIssue, reportUnknownMemberType]\n",
    "\n",
    "            ref_emb, forged_emb = apply_model(reference_tensor, forged_tensor) # pyright: ignore[reportUnknownArgumentType]\n",
    "            similarity, confidence, norm_dist, dist_score, distance = calculate_metrics(ref_emb, forged_emb)\n",
    "\n",
    "            result: Dict[str, Any] = {\n",
    "                \"is_genuine\": False,\n",
    "                \"confidence_score\": confidence,\n",
    "                \"similarity_score\": similarity,\n",
    "                \"euclidean_distance\": norm_dist,\n",
    "                \"distance_score\": dist_score,\n",
    "                \"prediction_level\": \"unknown\",\n",
    "                \"passed_thresholds\": False,\n",
    "            }\n",
    "            apply_threshold(similarity, dist_score, confidence, result)\n",
    "            print(f\"Signer {i+1}, Original {j+1} vs Forgery {k+1} → {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd52b62a",
   "metadata": {},
   "source": [
    "# Temporary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0697a79d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image_directory = \"data/CEDAR/original/\"\n",
    "image_file = random.sample(os.listdir(image_directory), 4)\n",
    "\n",
    "for filename in image_file:\n",
    "    path = os.path.join(image_directory, filename)\n",
    "    image = Image.open(path).convert(\"L\") \n",
    "    aug_img = train_transform(image)\n",
    "    aug_img_np = aug_img.squeeze().numpy()\n",
    "\n",
    "    plt.figure(figsize=(6,3))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.title(\"Original\")\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.title(\"Augmented\")\n",
    "    plt.imshow(aug_img_np, cmap='gray')\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e087817",
   "metadata": {},
   "source": [
    "# Dump"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09da98b0",
   "metadata": {},
   "source": [
    "## Scheduling\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b6097e",
   "metadata": {},
   "source": [
    "### Hardcoding Scheduling (Reference)\n",
    "\n",
    "```python\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, SequentialLR, LinearLR\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
    "\n",
    "warmup = LinearLR(optimizer, start_factor=0.1, total_iters=5)\n",
    "cosine = CosineAnnealingLR(optimizer, T_max=50)\n",
    "\n",
    "scheduler = SequentialLR(optimizer, schedulers=[warmup, cosine], milestones=[5])\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68b9c96",
   "metadata": {},
   "source": [
    "### More Flexible\n",
    "\n",
    "```python\n",
    "if \"WARMUP_SCHEDULER\" in scheduler_config:\n",
    "    warmup_name = str(scheduler_config[\"WARMUP_SCHEDULER\"])\n",
    "    warmup_class = getattr(lr_scheduler, warmup_name)\n",
    "    warmup_scheduler = warmup_class(\n",
    "        self.optimiser, \n",
    "        start_factor=scheduler_config[\"WARMUP_START_FACTOR\"],\n",
    "        total_iters=scheduler_config[\"WARMUP_EPOCHS\"]\n",
    "    )\n",
    "    schedulers.append(warmup_scheduler)\n",
    "\n",
    "if \"MAIN_SCHEDULER\" in scheduler_config:\n",
    "    main_name = str(scheduler_config[\"MAIN_SCHEDULER\"])\n",
    "    main_class = getattr(lr_scheduler, main_name)\n",
    "    main_scheduler = main_class(\n",
    "        self.optimiser,\n",
    "        T_max=scheduler_config[\"T_MAX\"],\n",
    "        eta_min=scheduler_config[\"eta_min\"]\n",
    "    )\n",
    "    schedulers.append(main_scheduler)\n",
    "\n",
    "if scheduler_config[\"SCHEDULER\"] == \"SequentialLR\":\n",
    "    scheduler_class = getattr(lr_scheduler, \"SequentialLR\")\n",
    "    scheduler = scheduler_class(\n",
    "        self.optimiser,\n",
    "        schedulers=schedulers,\n",
    "        milestones=scheduler_config[\"MILESTONES\"]\n",
    "    )\n",
    "    return scheduler\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7968dc2d",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93cdabb2",
   "metadata": {},
   "source": [
    "### Model Related\n",
    "```python \n",
    "\"EMBEDDING_DIM\": 256,\n",
    "        \n",
    "# Optional\n",
    "\"GRAD_CLIP\": 1.0,\n",
    "\"K_FOLD\": 5, \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a3097e",
   "metadata": {},
   "source": [
    "### Scheduling\n",
    "```python\n",
    "\"WARMUP_SCHEDULER\": \"LinearLR\",\n",
    "\"WARMUP_EPOCHS\": 2,\n",
    "\"WARMUP_START_FACTOR\": 0.1,\n",
    "\n",
    "\"MAIN_SCHEDULER\": \"CosineAnnealingLR\",\n",
    "\"T_MAX\": int(LEARNING_CONFIG[\"EPOCH\"]) - 2,\n",
    "\"eta_min\": 1e-6,\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def8a321",
   "metadata": {},
   "source": [
    "### EvalResult\n",
    "```python\n",
    "This needs changing\n",
    "@dataclass\n",
    "class EvalResults:\n",
    "    distances: npt.NDArray[np.float32]\n",
    "    labels: npt.NDArray[np.int64]\n",
    "    embeddings: Dict[str, npt.NDArray[np.float32]]\n",
    "    metrics: Dict[str, npt.NDArray[np.float32]]\n",
    "    curves: Dict[str, npt.NDArray[np.float32]] \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e55ab4",
   "metadata": {},
   "source": [
    "## Sampler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d91802",
   "metadata": {},
   "source": [
    "### PKSampler\n",
    "Still does not different forgeries in originals\n",
    "```python\n",
    "class PKSampler(Sampler[List[int]]):\n",
    "    def __init__(\n",
    "        self,\n",
    "        signer_to_indices: Dict[str, Dict[str, List[int]]], \n",
    "        P: int,          # signers per batch\n",
    "        K: int,          # originals per signer\n",
    "        F: int,          # forgeries per signer\n",
    "        M: int,          # inter-signer global negatives PER signer in batch\n",
    "        seed: int = 42\n",
    "    ):\n",
    "        \"\"\"\n",
    "        signer_to_indices:\n",
    "            {\n",
    "                signer_id: {\n",
    "                    \"original\": [idx,...],\n",
    "                    \"forged\":   [idx,...]\n",
    "                }\n",
    "            }\n",
    "        \"\"\"\n",
    "        self.P = P\n",
    "        self.K = K\n",
    "        self.F = F\n",
    "        self.M = M\n",
    "        \n",
    "        self.signer_to_indices = signer_to_indices\n",
    "        self.signers = list(signer_to_indices.keys())\n",
    "        self.seed = seed\n",
    "\n",
    "        # Precompute global negatives\n",
    "        self._all_indices = []\n",
    "        self._indices_by_signer = {}\n",
    "        for sid, groups in signer_to_indices.items():\n",
    "            all_for_sid = groups[\"original\"] + groups[\"forged\"]\n",
    "            self._indices_by_signer[sid] = set(all_for_sid)\n",
    "            self._all_indices.extend(all_for_sid)\n",
    "\n",
    "    def __len__(self):\n",
    "        return max(1, len(self.signers) // self.P * 10)\n",
    "\n",
    "    def __iter__(self):\n",
    "        rng = random.Random(self.seed)\n",
    "\n",
    "        while True:\n",
    "            selected_signers = rng.sample(self.signers, self.P)\n",
    "            batch = []\n",
    "\n",
    "            for sid in selected_signers:\n",
    "                originals = self.signer_to_indices[sid][\"original\"]\n",
    "                forgeries = self.signer_to_indices[sid][\"forged\"]\n",
    "\n",
    "                # Sample originals\n",
    "                pos = rng.sample(originals, self.K) if len(originals) >= self.K else rng.choices(originals, k=self.K)\n",
    "\n",
    "                # Sample forgeries\n",
    "                neg_hard = rng.sample(forgeries, self.F) if len(forgeries) >= self.F else rng.choices(forgeries, k=self.F)\n",
    "\n",
    "                # Sample inter-signer negatives\n",
    "                # All indices EXCEPT this signer\n",
    "                global_pool = [x for x in self._all_indices if x not in self._indices_by_signer[sid]]\n",
    "                neg_global = rng.sample(global_pool, self.M)\n",
    "\n",
    "                batch.extend(pos + neg_hard + neg_global)\n",
    "\n",
    "            yield batch\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32151d7",
   "metadata": {},
   "source": [
    "### ForgeryAwarePKSampler\n",
    "\n",
    "Still the same issue\n",
    "\n",
    "```python\n",
    "class ForgeryAwarePKSampler(Sampler[List[int]]):\n",
    "    def __init__(\n",
    "        self,\n",
    "        signer_to_indices: Dict[str, Dict[str, List[int]]],\n",
    "        P: int,\n",
    "        K: int,\n",
    "        seed: Optional[int] = 42\n",
    "    )\n",
    "        \"\"\"\n",
    "        signer_to_indices: {\n",
    "            signer_id: {\n",
    "                \"original\": [list of dataset indices],\n",
    "                \"forgery\": [list of dataset indices]\n",
    "            }\n",
    "        }\n",
    "        P: number of signers per batch\n",
    "        K: number of originals per signer\n",
    "        \"\"\"\n",
    "        self.P = P\n",
    "        self.K = K\n",
    "        self.signer_to_indices = signer_to_indices\n",
    "        self.signers = list(signer_to_indices.keys())\n",
    "        self.seed = seed\n",
    "\n",
    "    def __iter__(self):\n",
    "        rng = random.Random(self.seed)\n",
    "        while True:\n",
    "            selected_signers = rng.sample(self.signers, self.P)\n",
    "            batch = []\n",
    "\n",
    "            for signer in selected_signers:\n",
    "                originals = self.signer_to_indices[signer][\"original\"]\n",
    "                forgeries = self.signer_to_indices[signer][\"forged\"]\n",
    "\n",
    "                # Sample K originals (positives)\n",
    "                pos_samples = rng.sample(originals, self.K) if len(originals) >= self.K else rng.choices(originals, k=self.K)\n",
    "                # Sample K forgeries (negatives)\n",
    "                neg_samples = rng.sample(forgeries, self.K) if len(forgeries) >= self.K else rng.choices(forgeries, k=self.K)\n",
    "\n",
    "                batch.extend(pos_samples + neg_samples)\n",
    "\n",
    "            yield batch  # List[int] of indices\n",
    "\n",
    "    def __len__(self):\n",
    "        return max(1, len(self.signers) // self.P * 10)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf94633",
   "metadata": {},
   "source": [
    "### PKSampler\n",
    "This sampler does not differentiate forgeries and originals of the same signer\n",
    "\n",
    "```python\n",
    "class PKSampler(Sampler[List[int]]):\n",
    "    def __init__(\n",
    "        self, \n",
    "        labels: List[int], \n",
    "        P: int, \n",
    "        K: int,\n",
    "    ) -> None:\n",
    "        \n",
    "        self.labels = labels\n",
    "        # Classes per batch\n",
    "        self.P = P\n",
    "        # Samples per class\n",
    "        self.K = K\n",
    "        self.label_to_indices: Dict[int, List[int]] = {}\n",
    "        \n",
    "        for idx, label in enumerate(labels):\n",
    "            self.label_to_indices.setdefault(label, []).append(idx)\n",
    "        \n",
    "        self.labels_set = list(self.label_to_indices.keys())\n",
    "        \n",
    "\n",
    "    def __iter__(self) -> Iterator[List[int]]:\n",
    "        for _ in range(len(self)):\n",
    "            # Randomly select P classes from the available classes. \n",
    "            selected_labels = random.sample(self.labels_set, self.P)\n",
    "            batch: List[int] = []\n",
    "            for label in selected_labels:\n",
    "                indices = self.label_to_indices[label]\n",
    "                # Checks if the class has at least K samples\n",
    "                if len(indices) >= self.K:\n",
    "                    # Samples K indices without replacement\n",
    "                    batch.extend(random.sample(indices, self.K))\n",
    "                else:\n",
    "                    # Samples K indices with replacement\n",
    "                    batch.extend(random.choices(indices, k=self.K)) \n",
    "            yield batch\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        n = len(self.labels)\n",
    "        if n == 0:\n",
    "            return 0\n",
    "        return max(1, n // (self.P * self.K))\n",
    "    \n",
    "        # return len(self.labels) // (self.P * self.K)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075a9eb0",
   "metadata": {},
   "source": [
    "## Test Dataset\n",
    "\n",
    "These two datasets are not well made for evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ee3aae",
   "metadata": {},
   "source": [
    "```python\n",
    "class TestSignatureDataset(Dataset[Tuple[torch.Tensor, torch.Tensor, torch.Tensor, int]]):\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_map: Dict[str, Dict[str, List[str]]],\n",
    "        transform: Optional[transforms.Compose] = None,\n",
    "        mode: str = \"impostor\",\n",
    "    ):\n",
    "        self.data_map = data_map\n",
    "        self.transform = transform\n",
    "        self.mode = mode\n",
    "        \n",
    "        self.signer_ids = [\n",
    "            sid for sid, imgs in data_map.items()\n",
    "            if len(imgs.get(\"original\", [])) + len(imgs.get(\"forged\", [])) >= 2\n",
    "        ]\n",
    "        \n",
    "        self.anchor_candidates = [\n",
    "            (path, sid)\n",
    "            for sid in self.signer_ids\n",
    "            for t in (\"original\", \"forged\")\n",
    "            for path in data_map[sid].get(t, [])\n",
    "        ]\n",
    "        \n",
    "        self.signer_to_imgs = {\n",
    "            sid: data_map[sid].get(\"original\", []) + data_map[sid].get(\"forged\", [])\n",
    "            for sid in self.signer_ids\n",
    "        }\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.anchor_candidates)\n",
    "    \n",
    "    def _load(self, path:str) -> torch.Tensor:\n",
    "        img = Image.open(path).convert(\"L\")\n",
    "        return self.transform(img) if self.transform else transforms.ToTensor()(img) # pyright: ignore[reportUnknownVariableType, reportReturnType]\n",
    "    \n",
    "    def __getitem__(\n",
    "        self, \n",
    "        index: int\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, int]:\n",
    "        \n",
    "        anchor_path, anchor_id = self.anchor_candidates[index]\n",
    "        anchor_id_int = int(anchor_id)\n",
    "        \n",
    "        for _ in range(10):\n",
    "            positive_choices = [p for p in self.signer_to_imgs[anchor_id] if p != anchor_path]\n",
    "            if positive_choices:\n",
    "                break\n",
    "            index = random.randint(0, len(self) - 1)\n",
    "        else:\n",
    "            raise RuntimeError(\"Dataset too malformed to sample positives.\")\n",
    "    \n",
    "        # positive_choices = [p for p in self.signer_to_imgs[anchor_id] if p != anchor_path]\n",
    "        # if not positive_choices:\n",
    "        #     return self.__getitem__(random.randint(0, len(self) - 1))\n",
    "        positive_path = random.choice(positive_choices)\n",
    "        \n",
    "        if self.mode == \"impostor\":\n",
    "            negative_signer = random.choice([sid for sid in self.signer_ids if sid != anchor_id])\n",
    "            negative_choices = self.signer_to_imgs[negative_signer]\n",
    "            negative_path = random.choice(negative_choices)\n",
    "        elif self.mode == \"forgery\":\n",
    "            # for _ in range(10):\n",
    "            #     negative_choices = self.data_map[anchor_id].get(\"forged\", [])\n",
    "            #     if negative_choices:\n",
    "            #         break\n",
    "            #     index = random.randint(0, len(self) - 1)\n",
    "            # else:\n",
    "            #     raise RuntimeError(\"Dataset too malformed to sample negatives.\")\n",
    "            # negative_path = random.choice(negative_choices)\n",
    "            negative_choices = self.data_map[anchor_id].get(\"forged\", [])\n",
    "            if not negative_choices:\n",
    "                return self.__getitem__(random.randint(0, len(self) - 1))\n",
    "            negative_path = random.choice(negative_choices)\n",
    "        else:\n",
    "            raise ValueError(\"mode must be 'impostor' or 'forgery'\")\n",
    "        \n",
    "        return (\n",
    "            self._load(anchor_path),\n",
    "            self._load(positive_path),\n",
    "            self._load(negative_path),\n",
    "            anchor_id_int\n",
    "        )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb6f3c5",
   "metadata": {},
   "source": [
    "```python\n",
    "class TestSignatureDataset(Dataset[Tuple[torch.Tensor, torch.Tensor, torch.Tensor, int]]):\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_map: Dict[str, Dict[str, List[str]]],\n",
    "        transform: Optional[transforms.Compose] = None,\n",
    "    ):\n",
    "        self.data_map = data_map\n",
    "        self.transform = transform\n",
    "\n",
    "        self.signer_ids = [\n",
    "            sid for sid, imgs in data_map.items()\n",
    "            if len(imgs.get(\"original\", [])) + len(imgs.get(\"forged\", [])) >= 2\n",
    "        ]\n",
    "        \n",
    "        # self.signer_ids:List[str] = sorted(\n",
    "        #     [sid for sid, imgs in data_map.items()\n",
    "        #     if len(imgs.get(\"original\", [])) + len(imgs.get(\"forged\", [])) >= 2],\n",
    "        #     key=int\n",
    "        # )\n",
    "        \n",
    "        # if len(self.signer_ids) < 2:\n",
    "        #     raise ValueError(\"Need >= 2 signers with >= 2 images each to form valid triplets.\")\n",
    "        \n",
    "        self.anchor_candidates: List[Tuple[str, str]]= [\n",
    "            (path, sid)\n",
    "            for sid in self.signer_ids\n",
    "            for t in (\"original\", \"forged\")\n",
    "            for path in data_map[sid].get(t, [])\n",
    "        ]\n",
    "        \n",
    "        self.signer_to_imgs = {\n",
    "            sid: data_map[sid].get(\"original\", []) + data_map[sid].get(\"forged\", [])\n",
    "            for sid in self.signer_ids\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.anchor_candidates)\n",
    "    \n",
    "    def _load(self, path:str) -> torch.Tensor:\n",
    "        img = Image.open(path).convert(\"L\")\n",
    "        return torch.Tensor(self.transform(img) if self.transform else transforms.ToTensor()(img))\n",
    "\n",
    "    def __getitem__(  # type: ignore\n",
    "        self, \n",
    "        index: int\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, int]:\n",
    "        \n",
    "        anchor_path, anchor_id = self.anchor_candidates[index]\n",
    "        anchor_id_int = int(anchor_id)\n",
    "        \n",
    "        # all_paths = self.data_map[anchor_id].get(\"original\", []) + self.data_map[anchor_id].get(\"forged\", [])\n",
    "        positive_choices = [p for p in self.signer_to_imgs[anchor_id] if p != anchor_path]\n",
    "        if not positive_choices:\n",
    "            return self.__getitem__(random.randint(0, len(self) - 1))\n",
    "        positive_path = random.choice(positive_choices)\n",
    "\n",
    "\n",
    "        negative_choices = list(self.data_map[anchor_id].get(\"forged\", []))\n",
    "        \n",
    "        for other_id in self.signer_ids:\n",
    "            if other_id == anchor_id:\n",
    "                continue\n",
    "            for category in (\"original\", \"forged\"):\n",
    "                negative_choices.extend(self.data_map[other_id].get(category, []))\n",
    "        \n",
    "        if not negative_choices:\n",
    "            return self.__getitem__(random.randint(0, len(self) - 1))\n",
    "        \n",
    "        negative_path = random.choice(negative_choices)\n",
    "        \n",
    "        return (\n",
    "            self._load(anchor_path),\n",
    "            self._load(positive_path),\n",
    "            self._load(negative_path),\n",
    "            anchor_id_int\n",
    "        )\n",
    "        def load(path: str) -> torch.Tensor:\n",
    "            img: Image.Image = Image.open(path).convert(\"L\")\n",
    "            return self.transform(img) if self.transform else transforms.ToTensor()(img) # pyright: ignore[reportUnknownVariableType, reportReturnType]\n",
    "        \n",
    "        anchor, positive, negative = map(load, [anchor_path, positive_path, negative_path])\n",
    "        return anchor, positive, negative, anchor_id_int\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7beb5988",
   "metadata": {},
   "source": [
    "## Trainer\n",
    "```python\n",
    "class Trainer:\n",
    "    def __init__(\n",
    "        self, \n",
    "        model: nn.Module,\n",
    "        loss_function: nn.Module,\n",
    "        learning_config: Dict[str, str | int | float],\n",
    "        optimiser_config: Dict[str, str | float],\n",
    "        scheduler_config: SchedulerConfig,\n",
    "        save_checkpoints: bool = True\n",
    "    ) -> None:\n",
    "        \n",
    "        self.model = model\n",
    "        \n",
    "        # Training loop\n",
    "        self.epoch = int(learning_config[\"EPOCH\"])\n",
    "        self.batch_size = int(learning_config[\"BATCH_SIZE\"])\n",
    "        self.lr = float(learning_config[\"LEARNING_RATE\"])\n",
    "        self.early_stop = int(learning_config[\"EARLY_STOPPING_PATIENT\"])\n",
    "        self.checkpoint_path = Path(str(learning_config[\"CHECKPOINT_DIR\"]))\n",
    "        self.save_checkpoints = bool(save_checkpoints)\n",
    "        self.device = torch.device(str(learning_config[\"DEVICE\"]))\n",
    "        self.device_type = self.device.type\n",
    "        self.global_step = 0\n",
    "        \n",
    "        self.best_val_loss = float(\"inf\")\n",
    "        self.patience_counter = 0\n",
    "        \n",
    "        # Optimiser\n",
    "        self.optimiser = self._build_optimiser(optimiser_config)\n",
    "        \n",
    "        # Scheduler\n",
    "        self.scheduler = self._build_scheduler(scheduler_config)\n",
    "\n",
    "        # Loss function\n",
    "        self.loss_function = loss_function\n",
    "        \n",
    "        # Mixed precision\n",
    "        self.scaler = GradScaler()\n",
    "        \n",
    "        # Moving to GPU\n",
    "        self.model.to(self.device)\n",
    "        # self.loss_function.to(self.device)\n",
    "        \n",
    "        # checkpointing\n",
    "        self.checkpoint_path.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Tensorboard\n",
    "        log_dir = learning_config[\"LOG_DIR\"]\n",
    "        self.writer = SummaryWriter(log_dir)\n",
    "        \n",
    "    def train_epoch(\n",
    "        self, dataloader: DataLoader[Tuple[torch.Tensor, str]]\n",
    "    ) -> float:\n",
    "        self.model.train()\n",
    "        running_loss: float = 0.0\n",
    "        num_batches: int = len(dataloader)\n",
    "        \n",
    "        for batch_index, (images, label) in enumerate(dataloader):\n",
    "            images = images.to(self.device)\n",
    "            # label = label.to(self.device)\n",
    "        \n",
    "            self.optimiser.zero_grad()\n",
    "            \n",
    "            with autocast(device_type=self.device_type):\n",
    "                outputs = self.model(images)\n",
    "                # SCTLoss returns (loss, triplet_vals, triplet_idxs, hn_ratio, Pos_log, Neg_log)\n",
    "                # loss, triplet_vals, _triplet_idxs, hn_ratio, pos, neg= self.loss_function(outputs, label)\n",
    "                \n",
    "                # Vanilla Triplet Loss returns (loss, stats)\n",
    "                loss, stats = self.loss_function(outputs, label)\n",
    "            \n",
    "            # Gradient clipping is optional\n",
    "            \n",
    "            self.scaler.scale(loss).backward()  # pyright: ignore[reportUnknownMemberType]\n",
    "            self.scaler.step(self.optimiser)\n",
    "            self.scaler.update()\n",
    "            \n",
    "            if isinstance(self.scheduler, lr_scheduler.OneCycleLR):\n",
    "                self.scheduler.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            self.global_step += 1\n",
    "            print(\n",
    "                f\"Training batch {batch_index}/{ num_batches }, \"\n",
    "                f\"Loss: {loss.item():.4f}\"\n",
    "            )\n",
    "            # self._log_triplet_metrics(loss, triplet_vals, triplet_idxs, hn_ratio, \"train\")\n",
    "            \n",
    "            if batch_index % 50 == 0:\n",
    "                # For both SCT and vanilla Triplet Loss\n",
    "                self.writer.add_scalar(f\"Train/BatchLoss\", loss.item(), self.global_step) # pyright: ignore[reportUnknownMemberType]\n",
    "                \n",
    "                # # SCT\n",
    "                # self.writer.add_scalar(f\"Train/HN_Ratio\", hn_ratio.item(), self.global_step) # pyright: ignore[reportUnknownMemberType]\n",
    "                # self.writer.add_scalar(f\"Train/PosMean\", pos.mean().item(), self.global_step) # pyright: ignore[reportUnknownMemberType]\n",
    "                # self.writer.add_scalar(f\"Train/NegMean\", neg.mean().item(), self.global_step) # pyright: ignore[reportUnknownMemberType]\n",
    "                \n",
    "                # self.writer.add_histogram(f\"Train/Pos\", triplet_vals[:,0], self.global_step) # pyright: ignore[reportUnknownMemberType]\n",
    "                # self.writer.add_histogram(f\"Train/Neg\", triplet_vals[:,1], self.global_step) # pyright: ignore[reportUnknownMemberType]\n",
    "                \n",
    "                # Vanilla Triplet Loss\n",
    "                self.writer.add_scalar(\"Train/HN_Ratio\", stats[\"hn_ratio\"], self.global_step) # pyright: ignore[reportUnknownMemberType]\n",
    "                self.writer.add_scalar(\"Train/PosMean\", stats[\"pos\"].mean().item(), self.global_step) # pyright: ignore[reportUnknownMemberType]\n",
    "                self.writer.add_scalar(\"Train/NegMean\", stats[\"neg\"].mean().item(), self.global_step) # pyright: ignore[reportUnknownMemberType]\n",
    "\n",
    "                self.writer.add_histogram(\"Train/Pos\", stats[\"triplet_vals\"][:,0], self.global_step) # pyright: ignore[reportUnknownMemberType]\n",
    "                self.writer.add_histogram(\"Train/Neg\", stats[\"triplet_vals\"][:,1], self.global_step) # pyright: ignore[reportUnknownMemberType]\n",
    "                \n",
    "                total_norm: float = 0.\n",
    "                for p in self.model.parameters():\n",
    "                    if p.grad is not None:\n",
    "                        total_norm += float(p.grad.data.norm(2).item()) # pyright: ignore[reportUnknownArgumentType, reportUnknownMemberType]\n",
    "                        \n",
    "                self.writer.add_scalar(\"Gradients/TotalNorm\", total_norm, self.global_step) # pyright: ignore[reportUnknownMemberType]\n",
    "            \n",
    "        # This is for OneCyclicLR\n",
    "        # self.scheduler.step() # pyright: ignore[reportOptionalMemberAccess] \n",
    "        \n",
    "        return running_loss / num_batches\n",
    "        \n",
    "    def evaluate(\n",
    "        self,\n",
    "        dataloader: DataLoader[Tuple[torch.Tensor, str]] \n",
    "    ) -> Tuple[Dict[str, float], torch.Tensor, List[str]]:\n",
    "        self.model.eval()\n",
    "        all_embeddings_list: List[torch.Tensor] = []\n",
    "        all_labels: List[str] = []\n",
    "        # num_batches: int = len(dataloader)\n",
    "        # running_loss = 0.0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels in dataloader:\n",
    "                images = images.to(self.device)\n",
    "                # labels = labels.to(self.device)\n",
    "                \n",
    "                with autocast(device_type=self.device_type):\n",
    "                    embeddings = self.model(images)\n",
    "                    all_embeddings_list.append(embeddings.cpu())\n",
    "                    all_labels.extend(labels) \n",
    "                    \n",
    "        all_embeddings = torch.cat(all_embeddings_list, dim=0)\n",
    "        n = len(all_labels)\n",
    "        \n",
    "        sim_matrix = F.cosine_similarity(\n",
    "            all_embeddings.unsqueeze(1), \n",
    "            all_embeddings.unsqueeze(0), \n",
    "            dim=2\n",
    "        )\n",
    "        \n",
    "        signer_ids = [label.split(\"_\")[0] for label in all_labels]\n",
    "        intra_mask = torch.zeros((n, n), dtype=torch.bool)\n",
    "        inter_mask = torch.zeros((n, n), dtype=torch.bool)\n",
    "        \n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                if i == j:\n",
    "                    continue\n",
    "                if signer_ids[i] == signer_ids[j]:\n",
    "                    intra_mask[i, j] = True\n",
    "                else:\n",
    "                    inter_mask[i, j] = True\n",
    "\n",
    "        # Convert masked elements to numpy safely\n",
    "        intra_sims: torch.Tensor = sim_matrix[intra_mask] \n",
    "        inter_sims: torch.Tensor = sim_matrix[inter_mask]  \n",
    "\n",
    "        intra_sims_np: np.ndarray = intra_sims.cpu().numpy() # type: ignore\n",
    "        inter_sims_np: np.ndarray = inter_sims.cpu().numpy() # type: ignore\n",
    "\n",
    "        # Metrics\n",
    "        y_true = [1] * len(intra_sims_np) + [0] * len(inter_sims_np) # type: ignore\n",
    "        y_scores = list(intra_sims_np) + list(inter_sims_np) # type: ignore\n",
    "        auc = roc_auc_score(y_true, y_scores)\n",
    "\n",
    "        metrics: Dict[str, float | int] = {\n",
    "            \"AUC\": auc, # type: ignore\n",
    "            \"mean_intra_similarity\": float(intra_sims.mean()),\n",
    "            \"mean_inter_similarity\": float(inter_sims.mean()),\n",
    "            \"num_intra_pairs\": len(intra_sims),\n",
    "            \"num_inter_pairs\": len(inter_sims)\n",
    "        }\n",
    "\n",
    "        return metrics, all_embeddings, all_labels\n",
    "            \n",
    "        # val_embedding = torch.cat(all_embeddings, dim = 0)\n",
    "        # return running_loss / num_batches, val_embedding, all_labels\n",
    "    \n",
    "    def fit(\n",
    "        self, \n",
    "        train_dataloader: DataLoader[Tuple[torch.Tensor, str]],\n",
    "        val_dataloader: DataLoader[Tuple[torch.Tensor, str]]\n",
    "    ) -> None: \n",
    "        for epoch in range(self.epoch):\n",
    "            train_loss = self.train_epoch(train_dataloader)\n",
    "            val_metrics, val_embedding, all_labels = self.evaluate(val_dataloader)\n",
    "            \n",
    "            # if epoch % 5 == 0:\n",
    "            self.writer.add_embedding( # pyright: ignore[reportUnknownMemberType]\n",
    "                mat = val_embedding,\n",
    "                metadata=all_labels,\n",
    "                global_step=self.global_step\n",
    "            )\n",
    "            \n",
    "            self.writer.add_scalar(\"Loss/train\", train_loss, epoch) # pyright: ignore[reportUnknownMemberType]\n",
    "            self.writer.add_scalar(\"AUC/val\", val_metrics[\"AUC\"], epoch) # pyright: ignore[reportUnknownMemberType]\n",
    "            self.writer.add_scalar(\"Loss/val\", 1.0 - val_metrics[\"AUC\"], epoch) # pyright: ignore[reportUnknownMemberType]\n",
    "            self.writer.add_scalar(\"Learning rate\", self.optimiser.param_groups[0][\"lr\"], epoch) # pyright: ignore[reportUnknownMemberType]\n",
    "            \n",
    "            if self.scheduler is not None and not isinstance(self.scheduler, lr_scheduler.OneCycleLR):\n",
    "                self.scheduler.step()\n",
    "\n",
    "            print(f\"Epoch [{epoch+1}/{self.epoch}]\" \n",
    "                  f\"| Train loss: {train_loss:.4f}\" \n",
    "                  f\"| AUC: {val_metrics['AUC']:.4f}\")\n",
    "        \n",
    "            val_loss_for_stop = 1.0 - val_metrics[\"AUC\"]\n",
    "            if val_loss_for_stop < self.best_val_loss:\n",
    "                self.best_val_loss = val_loss_for_stop\n",
    "                self.patience_counter = 0\n",
    "                if self.save_checkpoints:\n",
    "                    self._save_checkpoint(epoch, val_loss_for_stop, self.best_val_loss, self.patience_counter)\n",
    "            else:\n",
    "                self.patience_counter+=1\n",
    "                if self.patience_counter >= self.early_stop:\n",
    "                    print(\"Early stopping\")\n",
    "                    break\n",
    "        \n",
    "        self.writer.close()\n",
    "    \n",
    "    def load_checkpoint(\n",
    "        self, \n",
    "        path: str\n",
    "    ) -> None:\n",
    "        \n",
    "        self._has_path(path)\n",
    "        try:\n",
    "            checkpoint_model: ModelState = torch.load(path, map_location=self.device)\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Error loading checkpoint from {path}: {e}\")\n",
    "        \n",
    "        self.model.load_state_dict(checkpoint_model[\"model_state_dict\"])\n",
    "        self.optimiser.load_state_dict(checkpoint_model[\"optimiser_state_dict\"])\n",
    "        \n",
    "        if self.scheduler and checkpoint_model[\"scheduler_state_dict\"] is not None:\n",
    "            self.scheduler.load_state_dict(checkpoint_model[\"scheduler_state_dict\"])\n",
    "        \n",
    "        self.epoch = checkpoint_model[\"epoch\"]\n",
    "        self.best_val_loss = checkpoint_model[\"best_loss\"]\n",
    "        self.patience_counter = checkpoint_model[\"patience_counter\"]\n",
    "    \n",
    "    def _save_checkpoint(\n",
    "        self, \n",
    "        epoch: int, \n",
    "        loss: float, \n",
    "        best_loss: float, \n",
    "        patience_counter: int,\n",
    "    ) -> None:\n",
    "        model_state: ModelState = {\n",
    "            \"epoch\": epoch,\n",
    "            \"model_state_dict\": self.model.state_dict(),\n",
    "            \"optimiser_state_dict\": self.optimiser.state_dict(),\n",
    "            \"scheduler_state_dict\": self.scheduler.state_dict() if self.scheduler else None,\n",
    "            \"loss\": loss,\n",
    "            \"best_loss\": best_loss,\n",
    "            \"patience_counter\": patience_counter\n",
    "        }\n",
    "        \n",
    "        torch.save(\n",
    "            model_state, self.checkpoint_path / f\"{epoch+1}_loss_{loss:.4f}.pt\"\n",
    "        )\n",
    "    \n",
    "    def _has_path(self, path: str) -> None:\n",
    "        if not Path(path).exists():\n",
    "            raise FileNotFoundError(f\"File not found at {path}\")\n",
    "        print(f\"File is ok!\")\n",
    "                \n",
    "    def _build_optimiser(self, optimiser_config: Dict[str, str | float]) -> optim.Optimizer:\n",
    "        optimiser_name =  str(optimiser_config[\"optimiser\"])\n",
    "        optimiser_class = getattr(optim, optimiser_name)\n",
    "        \n",
    "        optimiser_params = {**optimiser_config}\n",
    "        optimiser_params.pop(\"optimiser\")\n",
    "        optimiser_params[\"lr\"] = self.lr\n",
    "        \n",
    "        return optimiser_class(self.model.parameters(), **optimiser_params)\n",
    "        \n",
    "    def _build_scheduler(\n",
    "        self, \n",
    "        scheduler_config: SchedulerConfig,\n",
    "        ) -> Optional[lr_scheduler.LRScheduler]:\n",
    "        schedulers: List[lr_scheduler.LRScheduler] = []\n",
    "         \n",
    "        for sched_cfg in scheduler_config.get(\"SCHEDULERS\", []):\n",
    "            name = sched_cfg[\"name\"]\n",
    "            params = sched_cfg.get(\"params\", {})\n",
    "            sched_class = getattr(lr_scheduler, name)\n",
    "            schedulers.append(sched_class(self.optimiser, **params))\n",
    "\n",
    "        if scheduler_config.get(\"SCHEDULER\") == \"SequentialLR\":\n",
    "            return lr_scheduler.SequentialLR(\n",
    "                self.optimiser,\n",
    "                schedulers=schedulers,\n",
    "                milestones=scheduler_config.get(\"MILESTONES\", [])\n",
    "            )\n",
    "        \n",
    "        return schedulers[0] if schedulers else None\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67339d4",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afb950c",
   "metadata": {},
   "source": [
    "### Plot Confusion Matrix\n",
    "\n",
    "```python\n",
    "def plot_confusion_matrix(\n",
    "    all_labels_np: npt.NDArray[np.int64],\n",
    "    all_predictions_np: npt.NDArray[np.float32],\n",
    "    best_threshold: float,\n",
    ") -> None:\n",
    "\n",
    "    predictions = [1 if d <= best_threshold else 0 for d in all_predictions_np]\n",
    "    cm = confusion_matrix(all_labels_np, predictions) # type: ignore\n",
    "\n",
    "    plt.figure(figsize=(8, 6)) # type: ignore\n",
    "    sns.heatmap(cm, annot=True, fmt=\"g\", cmap=\"Blues\") # type: ignore\n",
    "    plt.title(\"Confusion Matrix\") # type: ignore\n",
    "    plt.ylabel(\"True Label\") # type: ignore\n",
    "    plt.xlabel(\"Predicted Label\") # type: ignore\n",
    "    plt.savefig(\"confusion_matrix.png\") # type: ignore\n",
    "    plt.show() # type: ignore\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc39a5c0",
   "metadata": {},
   "source": [
    "### Plot AUC ROC\n",
    "```python\n",
    "def plot_auc_roc(fpr: npt.NDArray[np.float32], tpr: npt.NDArray[np.float32], auc_roc: npt.NDArray[np.float32]) -> None:\n",
    "    plt.figure(figsize=(8, 6)) # type: ignore\n",
    "    plt.plot(fpr, tpr, color=\"orange\", label=f\"AUC = {auc_roc}\") # type: ignore\n",
    "    plt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\") # type: ignore\n",
    "    plt.xlabel(\"False Positive Rate\") # type: ignore\n",
    "    plt.ylabel(\"True Positive Rate\") # type: ignore\n",
    "    plt.title(\"ROC Curve\") # type: ignore\n",
    "    plt.legend(loc=\"lower right\") # type: ignore\n",
    "    plt.grid() # type: ignore\n",
    "    plt.show() # type: ignore\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc12c9ba",
   "metadata": {},
   "source": [
    "### Plot Embedding Distances\n",
    "```python\n",
    "def plot_embedding_distances(\n",
    "    anchors: npt.NDArray[np.float32],\n",
    "    positives: npt.NDArray[np.float32],\n",
    "    negatives: npt.NDArray[np.float32],\n",
    ") -> None:\n",
    "    \n",
    "    pca = PCA(n_components=2)\n",
    "    all_embeddings = np.concatenate([anchors, positives, negatives], axis=0)\n",
    "    embeddings_2d = pca.fit_transform(all_embeddings)  # type: ignore\n",
    "\n",
    "    n_samples = len(anchors)\n",
    "    anchors_2d = embeddings_2d[:n_samples] # type: ignore\n",
    "    positives_2d = embeddings_2d[n_samples : 2 * n_samples] # type: ignore\n",
    "    negatives_2d = embeddings_2d[2 * n_samples :] # type: ignore\n",
    "\n",
    "    plt.figure(figsize=(10, 8)) # type: ignore\n",
    "    plt.scatter(anchors_2d[:, 0], anchors_2d[:, 1], c=\"blue\", label=\"Anchors\", alpha=0.6)  # type: ignore\n",
    "    plt.scatter(positives_2d[:, 0], positives_2d[:, 1], c=\"green\", label=\"Positives\", alpha=0.6)  # type: ignore\n",
    "    plt.scatter(negatives_2d[:, 0], negatives_2d[:, 1], c=\"red\", label=\"Negatives\", alpha=0.6)  # type: ignore\n",
    "\n",
    "    for i in range(len(anchors_2d)):  # type: ignore\n",
    "        plt.plot(  # type: ignore\n",
    "            [anchors_2d[i, 0], positives_2d[i, 0]],\n",
    "            [anchors_2d[i, 1], positives_2d[i, 1]],\n",
    "            \"g-\",\n",
    "            alpha=0.1,\n",
    "        )\n",
    "\n",
    "    for i in range(len(anchors_2d)):  # type: ignore\n",
    "        plt.plot(  # type: ignore\n",
    "            [anchors_2d[i, 0], negatives_2d[i, 0]],\n",
    "            [anchors_2d[i, 1], negatives_2d[i, 1]],\n",
    "            \"r-\",\n",
    "            alpha=0.1,\n",
    "        )\n",
    "\n",
    "    plt.title(\"2D Visualization of Embedding Distances\")  # type: ignore\n",
    "    plt.xlabel(\"First Principal Component\")  # type: ignore\n",
    "    plt.ylabel(\"Second Principal Component\")  # type: ignore\n",
    "    plt.legend()  # type: ignore\n",
    "    plt.grid(True)  # type: ignore\n",
    "    plt.savefig(\"embedding_distance.png\")  # type: ignore\n",
    "    plt.show()  # type: ignore\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc2f1f6",
   "metadata": {},
   "source": [
    "### Plot 3D Embeddings Interactive\n",
    "```python\n",
    "def plot_3d_embeddings_interactive(\n",
    "    anchors: npt.NDArray[np.float32],\n",
    "    positives: npt.NDArray[np.float32],\n",
    "    negatives: npt.NDArray[np.float32],\n",
    ") -> None:\n",
    "    pca = PCA(n_components=3)\n",
    "    all_embeddings = np.concatenate([anchors, positives, negatives])\n",
    "    embeddings_3d = pca.fit_transform(all_embeddings)  # type: ignore\n",
    "\n",
    "    n_samples = len(anchors)\n",
    "    anchors_3d = embeddings_3d[:n_samples]  # type: ignore\n",
    "    positives_3d = embeddings_3d[n_samples : 2 * n_samples]  # type: ignore\n",
    "    negatives_3d = embeddings_3d[2 * n_samples :]  # type: ignore\n",
    "\n",
    "    fig = go.Figure()\n",
    "\n",
    "    fig.add_trace(  # type: ignore\n",
    "        go.Scatter3d(\n",
    "            x=anchors_3d[:, 0],\n",
    "            y=anchors_3d[:, 1],\n",
    "            z=anchors_3d[:, 2],\n",
    "            mode=\"markers\",\n",
    "            name=\"Anchors\",\n",
    "            marker=dict(size=5, color=\"blue\", opacity=0.6),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fig.add_trace(  # type: ignore\n",
    "        go.Scatter3d(\n",
    "            x=positives_3d[:, 0],\n",
    "            y=positives_3d[:, 1],\n",
    "            z=positives_3d[:, 2],\n",
    "            mode=\"markers\",\n",
    "            name=\"Positives\",\n",
    "            marker=dict(size=5, color=\"green\", opacity=0.6),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fig.add_trace(  # type: ignore\n",
    "        go.Scatter3d(\n",
    "            x=negatives_3d[:, 0],\n",
    "            y=negatives_3d[:, 1],\n",
    "            z=negatives_3d[:, 2],\n",
    "            mode=\"markers\",\n",
    "            name=\"Negatives\",\n",
    "            marker=dict(size=5, color=\"red\", opacity=0.6),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fig.update_layout(  # type: ignore\n",
    "        title=\"Interactive 3D Visualization of Embedding Distances\",\n",
    "        scene=dict(\n",
    "            xaxis_title=\"First Principal Component\",\n",
    "            yaxis_title=\"Second Principal Component\",\n",
    "            zaxis_title=\"Third Principal Component\",\n",
    "        ),\n",
    "        width=800,\n",
    "        height=800,\n",
    "        margin=dict(l=0, r=0, b=0, t=30),\n",
    "    )\n",
    "\n",
    "    fig.update_layout(  # type: ignore\n",
    "        title=\"Interactive 3D Visualization of Embedding Distances\",\n",
    "        scene=dict(\n",
    "            xaxis_title=\"First Principal Component\",\n",
    "            yaxis_title=\"Second Principal Component\",\n",
    "            zaxis_title=\"Third Principal Component\",\n",
    "            camera=dict(eye=dict(x=1.25, y=1.25, z=1.25)),\n",
    "        ),\n",
    "        width=800,\n",
    "        height=800,\n",
    "        margin=dict(l=0, r=0, b=0, t=30),\n",
    "    )\n",
    "\n",
    "    fig.show()  # type: ignore\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe964d13",
   "metadata": {},
   "source": [
    "### Metrices\n",
    "```python\n",
    "def compute_distance_eval(\n",
    "    anchor: torch.Tensor, \n",
    "    positive: torch.Tensor, \n",
    "    negative: torch.Tensor, \n",
    "    margin: float,\n",
    ") -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "    positive_dist = F.pairwise_distance(anchor, positive)\n",
    "    negative_dist = F.pairwise_distance(anchor, negative)\n",
    "    loss = torch.mean(torch.relu(positive_dist - negative_dist + margin))\n",
    "    return positive_dist, negative_dist, loss\n",
    "\n",
    "def calculate_eer_eer_threshold(\n",
    "    thresholds: npt.NDArray[np.float32],\n",
    "    fpr: npt.NDArray[np.float32],\n",
    "    fnr: npt.NDArray[np.float32],\n",
    ") -> Tuple[float, float]:\n",
    "    absolute_difference = np.abs(fpr - fnr)\n",
    "    index = np.argmin(absolute_difference)\n",
    "    eer = (fpr[index] + fnr[index]) / 2.0\n",
    "    eer_threshold = thresholds[index]\n",
    "    \n",
    "    return eer, eer_threshold\n",
    "\n",
    "def calculate_auc(\n",
    "    all_labels_np: npt.NDArray[np.int64], \n",
    "    all_distances_np: npt.NDArray[np.float32]\n",
    ") -> Tuple[\n",
    "    npt.NDArray[np.float32],\n",
    "    npt.NDArray[np.float32],\n",
    "    npt.NDArray[np.float32],\n",
    "    npt.NDArray[np.float32],\n",
    "    float,\n",
    "    npt.NDArray[np.float32],\n",
    "]:    \n",
    "    scores = -all_distances_np\n",
    "    fpr, tpr, thresholds = roc_curve(all_labels_np, scores) # pyright: ignore[reportUnknownVariableType]\n",
    "    roc_auc = float(auc(fpr, tpr)) # pyright: ignore[reportUnknownArgumentType]\n",
    "\n",
    "    fnr = 1 - tpr  # pyright: ignore[reportUnknownVariableType]\n",
    "\n",
    "    return fpr, tpr, fnr, thresholds, roc_auc, scores # pyright: ignore[reportUnknownVariableType]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ea779e",
   "metadata": {},
   "source": [
    "### Evaluation Function\n",
    "```python\n",
    "def evaluate_model(\n",
    "    model: nn.Module,\n",
    "    test_loader: DataLoader[Tuple[torch.Tensor, torch.Tensor, torch.Tensor, int]],\n",
    "    margin: float = 0.5,\n",
    ") -> EvalResults:\n",
    "    model.eval()\n",
    "    all_labels: List[float] = []\n",
    "    all_distances: List[float] = []\n",
    "    embeddings_list: defaultdict[\n",
    "        str, \n",
    "        List[\n",
    "            npt.NDArray[\n",
    "                np.float32\n",
    "            ]\n",
    "        ]\n",
    "    ] = defaultdict(list)\n",
    "    \n",
    "    total_loss: float = 0.0\n",
    "    num_batches: int = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for anchor, positive, negative, _anchor_id in test_loader:\n",
    "            anchor = anchor.to(LEARNING_CONFIG[\"DEVICE\"])\n",
    "            positive = positive.to(LEARNING_CONFIG[\"DEVICE\"])\n",
    "            negative = negative.to(LEARNING_CONFIG[\"DEVICE\"])\n",
    "             \n",
    "            anchor_embedding = model(anchor)\n",
    "            positive_embedding = model(positive)\n",
    "            negative_embedding = model(negative)\n",
    "            \n",
    "            positive_dist, negative_dist, loss = compute_distance_eval(anchor_embedding, positive_embedding, negative_embedding, margin)\n",
    "            total_loss += loss.item()\n",
    "            num_batches += 1\n",
    "            \n",
    "            for k, v in zip((\"anchor\", \"positive\", \"negative\"), (anchor_embedding, positive_embedding, negative_embedding)):\n",
    "                embeddings_list[k].append(v.cpu().numpy())\n",
    "            \n",
    "            all_distances.extend(positive_dist.cpu().tolist()); all_labels.extend([1]*len(positive_dist)) # pyright: ignore[reportUnknownArgumentType, reportUnknownMemberType]\n",
    "            all_distances.extend(negative_dist.cpu().tolist()); all_labels.extend([0]*len(negative_dist)) # pyright: ignore[reportUnknownArgumentType, reportUnknownMemberType]\n",
    "\n",
    "    final_embeddings: Dict[str, npt.NDArray[np.float32]] = {k: np.concatenate(v, axis=0) for k,v in embeddings_list.items()}\n",
    "    all_distances_np = np.array(all_distances, np.float32).reshape(-1)\n",
    "    all_labels_np = np.array(all_labels, np.int64).reshape(-1)\n",
    "    \n",
    "    fpr, tpr, fnr, thresholds, roc_auc, scores = calculate_auc(all_labels_np, all_distances_np)\n",
    "    eer, eer_threshold = calculate_eer_eer_threshold(thresholds, fpr, fnr)\n",
    "\n",
    "    preds = (scores >= eer_threshold).astype(int)\n",
    "\n",
    "    metrics: Dict[str, Any] = {\n",
    "        \"avg_triplet_loss\": total_loss/num_batches,\n",
    "        \"avg_pos_dist\": float(all_distances_np[all_labels_np==1].mean()),\n",
    "        \"avg_neg_dist\": float(all_distances_np[all_labels_np==0].mean()),\n",
    "        \"auc_roc\": float(roc_auc),\n",
    "        \"eer\": float(eer),\n",
    "        \"eer_threshold\": float(eer_threshold),\n",
    "        \"accuracy\": accuracy_score(all_labels_np, preds),\n",
    "        \"precision\": precision_score(all_labels_np, preds, pos_label=1),\n",
    "        \"recall\": recall_score(all_labels_np, preds, pos_label=1),\n",
    "    }\n",
    "\n",
    "    curves = {\"fpr\": fpr, \"tpr\": tpr, \"fnr\": fnr}\n",
    "    return EvalResults(all_distances_np, all_labels_np, final_embeddings, metrics, curves)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd35b22",
   "metadata": {},
   "source": [
    "## Sanity checks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1664e55b",
   "metadata": {},
   "source": [
    "### Batch indices\n",
    "```python\n",
    "batch_iter = iter(train_sampler)\n",
    "batch_indices = next(batch_iter)\n",
    "\n",
    "print(\"Batch indices:\", batch_indices)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6830ff6d",
   "metadata": {},
   "source": [
    "### Batch Labels\n",
    "```python\n",
    "# Map indices back to labels\n",
    "batch_labels = [train_dataset[i][1] for i in batch_indices]\n",
    "print(\"Batch labels:\", batch_labels)\n",
    "\n",
    "# Optionally, map to signer IDs and type\n",
    "batch_info = [train_dataset.all_image_references[i] for i in batch_indices]\n",
    "print(\"Batch info (signer_id, type, idx):\", batch_info)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759dc4d9",
   "metadata": {},
   "source": [
    "### Signer counts\n",
    "```python\n",
    "from collections import Counter\n",
    "signers = [train_dataset.all_image_references[i][0] for i in batch_indices]\n",
    "print(\"Signer counts in batch:\", Counter(signers))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e8b3b0",
   "metadata": {},
   "source": [
    "### Batch Summary\n",
    "\n",
    "```python\n",
    "from collections import defaultdict\n",
    "\n",
    "def print_batch_summary(dataset, batch_indices):\n",
    "    summary = defaultdict(list)\n",
    "    for idx in batch_indices:\n",
    "        signer, img_type, img_idx = dataset.all_image_references[idx]\n",
    "        summary[signer].append(img_type)\n",
    "    for signer, types in summary.items():\n",
    "        print(f\"Signer {signer}: {types}\")\n",
    "\n",
    "print_batch_summary(train_dataset, batch_indices)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13dbb32",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

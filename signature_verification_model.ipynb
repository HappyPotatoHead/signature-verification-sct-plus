{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f349c3d0",
   "metadata": {},
   "source": [
    "# Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3beab3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import re\n",
    "import random\n",
    "from pathlib import Path\n",
    "from typing import Dict, Tuple, Any, Optional, List, Callable, TypedDict, Iterator, DefaultDict\n",
    "from collections import defaultdict\n",
    "from itertools import combinations\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as  lr_scheduler\n",
    "import torchvision.models as models # pyright: ignore[reportMissingTypeStubs]\n",
    "import torchvision.transforms as transforms # pyright: ignore[reportMissingTypeStubs]\n",
    "from torchvision.models import get_model_weights # pyright: ignore[reportUnknownVariableType, reportMissingTypeStubs]\n",
    "from torch.amp.grad_scaler import GradScaler\n",
    "from torch.amp.autocast_mode import autocast\n",
    "from torch.utils.data import Dataset, DataLoader, Sampler\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from sklearn.model_selection import train_test_split # pyright: ignore[reportUnknownVariableType]\n",
    "from sklearn.metrics import roc_curve, roc_auc_score # pyright: ignore[reportUnknownVariableType]\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18227c69",
   "metadata": {},
   "source": [
    "# Seeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2f5cff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed: int = 42) -> None:\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)  # pyright: ignore[reportUnknownMemberType]\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52eacd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_worker(worker_id: int) -> None:\n",
    "    work_seed = 42 + worker_id\n",
    "    np.random.seed(work_seed)\n",
    "    random.seed(work_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc77e170",
   "metadata": {},
   "source": [
    "# Configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50fc54fd",
   "metadata": {},
   "source": [
    "## Defining Custom Types "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e50a163",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SchedulerEntry(TypedDict):\n",
    "    name: str\n",
    "    params: Dict[str, Any]\n",
    "\n",
    "class SchedulerConfig(TypedDict, total=False):\n",
    "    SCHEDULER: str\n",
    "    MILESTONES: List[int]\n",
    "    SCHEDULERS: List[SchedulerEntry]\n",
    "\n",
    "class ModelState(TypedDict):\n",
    "    epoch: int\n",
    "    model_state_dict: Any\n",
    "    optimiser_state_dict: Any\n",
    "    scheduler_state_dict: Any\n",
    "    auc: float\n",
    "    best_loss: float\n",
    "    patience_counter: int"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db194f6b",
   "metadata": {},
   "source": [
    "## Dataset Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38af7d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH: Dict[str, str] = {\n",
    "    \"CEDAR\": \"data\\\\CEDAR\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee066fec",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65332b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_CONFIG: Dict[str, str | int | float] = {\n",
    "    \"BATCH_SIZE\": 32,\n",
    "    \"EPOCH\": 50,\n",
    "    \"LEARNING_RATE\": 1e-3,\n",
    "    \"EARLY_STOPPING_PATIENT\": 10,\n",
    "    \n",
    "    \"DEVICE\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    \n",
    "    \"CHECKPOINT_DIR\": \"checkpoint/exp_01_mod_sct\",\n",
    "    \"LOG_DIR\": \"runs/exp_01_mod_sct\"\n",
    "}\n",
    "\n",
    "OPTIMISER_PARAMS: Dict[str, str | float] = {\n",
    "    \"optimiser\": \"AdamW\",\n",
    "    # Prevent overwriting the pretrained weights too aggressively\n",
    "    \"weight_decay\": 1e-3,\n",
    "}\n",
    "\n",
    "# Linear Warmup and Cosine Decay\n",
    "SCHEDULER_PARAMS: SchedulerConfig = {\n",
    "    \"SCHEDULER\": \"SequentialLR\", \n",
    "    \"MILESTONES\": [5],\n",
    "    \"SCHEDULERS\": [\n",
    "        {\n",
    "            \"name\": \"LinearLR\",\n",
    "            \"params\": {\n",
    "                \"start_factor\": 0.1,\n",
    "                \"total_iters\": 5\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"CosineAnnealingLR\",\n",
    "            \"params\": {\n",
    "                \"T_max\": int(LEARNING_CONFIG[\"EPOCH\"])-5, \n",
    "                \"eta_min\": 1e-6\n",
    "            }\n",
    "        }\n",
    "    ],\n",
    "}\n",
    "\n",
    "BACKBONE_CONFIG: Dict[str, Dict[str, Any]] = {\n",
    "    \"efficientnet_v2_s\": {\"builder\": models.efficientnet_v2_s, \"out_channels\": 1280},\n",
    "    \"efficientnet_v2_m\": {\"builder\": models.efficientnet_v2_m, \"out_channels\": 1280},\n",
    "    \"efficientnet_v2_l\": {\"builder\": models.efficientnet_v2_l, \"out_channels\": 1280},\n",
    "}\n",
    "\n",
    "IMAGE_FORMATS: List[str] = [\".png\", \".jpg\", \".jpeg\", \".bmp\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab8d786",
   "metadata": {},
   "source": [
    "# Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4cc4c91",
   "metadata": {},
   "source": [
    "## Model\n",
    "The model uses `efficientnet`\n",
    "```python\n",
    "# use_extra_layers: bool = True,\n",
    "# extra_channels: Optional[List[int]] = None,\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c54fdbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtractionModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        backbone_type: str,\n",
    "        embedding_dim: int = 256,\n",
    "        weights: Optional[str] = None, \n",
    "        dropout_rate: float  = 0.4,\n",
    "    ) -> None:\n",
    "        super().__init__()  # pyright: ignore[reportUnknownMemberType]\n",
    "        self._check_parameters(backbone_type, embedding_dim, dropout_rate)\n",
    "        \n",
    "        FREEZE_UP_TO: int = 4\n",
    "        \n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.backbone_type = backbone_type\n",
    "        self.dropout_rate = dropout_rate  \n",
    "        \n",
    "        self.weights = weights\n",
    "        self.weights_enum = None\n",
    "        \n",
    "        backbone_builder = BACKBONE_CONFIG[self.backbone_type][\"builder\"]\n",
    "        backbone_out_channels = BACKBONE_CONFIG[self.backbone_type][\"out_channels\"]\n",
    "        \n",
    "        self._retrieve_weights(str(self.weights), backbone_builder)\n",
    "        \n",
    "        self.model = backbone_builder(weights = self.weights_enum)\n",
    "        \n",
    "        first_layer = self.model.features[0][0]\n",
    "        self.model.features[0][0] = nn.Conv2d(\n",
    "            in_channels= 1,\n",
    "            out_channels=first_layer.out_channels,\n",
    "            kernel_size=first_layer.kernel_size,\n",
    "            stride=first_layer.stride,\n",
    "            padding=first_layer.padding,\n",
    "            bias=first_layer.bias is not None,\n",
    "        )\n",
    "        \n",
    "        if self.weights is not None:\n",
    "            with torch.no_grad():\n",
    "                self.model.features[0][0].weight.data = (\n",
    "                    first_layer.weight.data.mean(dim=1, keepdim=True)\n",
    "                )\n",
    "        else:\n",
    "            nn.init.kaiming_normal_(\n",
    "                self.model.features[0][0].weight, mode=\"fan_out\", nonlinearity=\"relu\"\n",
    "            )\n",
    "            if self.model.features[0][0].bias is not None:\n",
    "                nn.init.constant_(self.model.features[0][0].bias, 0)\n",
    "\n",
    "        self.backbone = self.model.features\n",
    "\n",
    "        # Zero shot Learning       \n",
    "        # for param in self.backbone.parameters():\n",
    "        #     param.requires_grad = False\n",
    "        \n",
    "        for i, block in enumerate(self.model.features):\n",
    "            if i <= FREEZE_UP_TO:\n",
    "                for param in block.parameters():\n",
    "                    param.requires_grad = False\n",
    "            else:\n",
    "                for param in block.parameters():\n",
    "                    param.requires_grad = True\n",
    "            \n",
    "        self.pool1 = nn.AdaptiveAvgPool2d(1) \n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        self.fc1 = nn.Linear(backbone_out_channels, 512)\n",
    "        self.bn1 = nn.BatchNorm1d(512)\n",
    "        \n",
    "        self.fc2 = nn.Linear(512, self.embedding_dim)\n",
    "        self.bn2 = nn.BatchNorm1d(self.embedding_dim) \n",
    "        \n",
    "        self.dropout = nn.Dropout(self.dropout_rate)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.backbone(x)\n",
    "        \n",
    "        x = self.pool1(x)\n",
    "        x = self.flatten(x)\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        x = self.bn2(x)\n",
    "        # x = self.relu(x)\n",
    "        \n",
    "        x = F.normalize(x, p=2, dim=1)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def _check_parameters(\n",
    "        self,\n",
    "        backbone_type: str,\n",
    "        embedding_dim: int,\n",
    "        dropout_rate: float,\n",
    "    ) -> None:\n",
    "        if embedding_dim <= 0:\n",
    "            raise ValueError(\n",
    "                f\"Embedding dimension must be positive, got {embedding_dim}\"\n",
    "            )\n",
    "        if dropout_rate < 0 or dropout_rate > 1:\n",
    "            raise ValueError(\n",
    "                f\"Dropout rate must be between 0 and 1, got {dropout_rate}\"\n",
    "            )\n",
    "        if backbone_type not in BACKBONE_CONFIG:\n",
    "            raise ValueError(\n",
    "                f\"Unsupported backbone type: {backbone_type}. Choose from {list(BACKBONE_CONFIG.keys())}\"\n",
    "            )\n",
    "    \n",
    "    def _retrieve_weights(\n",
    "        self, \n",
    "        weights: str, \n",
    "        backbone_builder: Any\n",
    "    ) -> None:\n",
    "        try:\n",
    "            weights_enum_type = get_model_weights(backbone_builder)\n",
    "            if hasattr(weights_enum_type, weights):\n",
    "                self.weights_enum = getattr(weights_enum_type, weights)\n",
    "            else:\n",
    "                print(\n",
    "                    f\"Warning: Could not get weights type for backbone '{self.backbone_type}'. Using default random initialisation.\",\n",
    "                    file=sys.stderr,\n",
    "                )\n",
    "                weights = \"\"\n",
    "        except AttributeError:\n",
    "            print(\n",
    "                f\"Warning: Specified weights alias '{weights}' not found for {self.backbone_type}. Check available weights in torchvision documentation. Using default random initialisation.\",\n",
    "                file=sys.stderr,\n",
    "            )\n",
    "            weights = \"\"\n",
    "        except Exception as e:\n",
    "            print(\n",
    "                f\"Warning: An unexpected error occurred looking up weights '{weights}' for {self.backbone_type}: {e}. Using default random initialisation.\",\n",
    "                file=sys.stderr,\n",
    "            )\n",
    "            \n",
    "            weights = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f2c925",
   "metadata": {},
   "source": [
    "## Loss Function\n",
    "```python\n",
    "        \n",
    "pos_dist = torch.linalg.vector_norm(embeddings - positives, ord=self.p, dim=1) # pyright: ignore[reportUnknownVariableType, reportUnknownMemberType]\n",
    "neg_dist = torch.linalg.vector_norm(embeddings - negatives, ord=self.p, dim=1) # pyright: ignore[reportUnknownVariableType, reportUnknownMemberType]\n",
    "\n",
    "triplet_vals = pos_dist - neg_dist + self.margin # pyright: ignore[reportUnknownVariableType]\n",
    "```        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c90a880",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletLoss(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        margin: float = 1.0,\n",
    "        mining_strategy: str = \"batch_semi_hard\",\n",
    "        use_diversity: bool = False,\n",
    "        lambda_diversity: float = 0.1,\n",
    "        p: int = 2,\n",
    "    ) -> None:\n",
    "        super().__init__()  # pyright: ignore[reportUnknownMemberType]\n",
    "        \n",
    "        if margin < 0:\n",
    "            raise ValueError(f\"Margin must be non-negative, got {margin}\")\n",
    "        if mining_strategy not in [\"batch_hard\", \"batch_semi_hard\"]:\n",
    "            raise ValueError(f\"Invalid mining strategy, got {mining_strategy}\")\n",
    "        \n",
    "        self.margin = margin\n",
    "        self.mining_strategy = mining_strategy\n",
    "        \n",
    "        # optional, but it's usually not needed\n",
    "        self.lambda_diversity = lambda_diversity\n",
    "        self.use_diversity = use_diversity\n",
    "        \n",
    "        self.p = p\n",
    "    \n",
    "        # Calculate margin automatically\n",
    "        self.base_loss = nn.TripletMarginLoss(margin=margin, p=p)\n",
    "        \n",
    "    def forward(\n",
    "        self, \n",
    "        embeddings: torch.Tensor, \n",
    "        labels: torch.Tensor\n",
    "    ) -> Tuple[torch.Tensor, Dict[str, Any]]:\n",
    "\n",
    "        # compute pairwise distances\n",
    "        distances = torch.cdist(embeddings, embeddings, p=self.p)\n",
    "        mask_anchor_positive, mask_anchor_negative = self._get_triplet_mask(labels)\n",
    "        \n",
    "        if mask_anchor_positive.sum().item() == 0:\n",
    "            print(\"No positive pairs in batch\")\n",
    "        \n",
    "        if mask_anchor_negative.sum().item() == 0:\n",
    "            print(\"No negative pairs in batch\")\n",
    "\n",
    "        if self.mining_strategy == \"batch_hard\":\n",
    "            pos_idx, neg_idx = self._batch_hard_mining(distances, mask_anchor_positive, mask_anchor_negative)\n",
    "        else:\n",
    "            pos_idx, neg_idx, has_semi = self._batch_semi_hard_mining(distances, mask_anchor_positive, mask_anchor_negative)\n",
    "        \n",
    "            if not has_semi.any(): \n",
    "                print(\"No semi-hard negatives found (fallback to hard negatives)\")\n",
    "\n",
    "        # anchors = embeddings\n",
    "        positives = embeddings[pos_idx]\n",
    "        negatives = embeddings[neg_idx]\n",
    "        \n",
    "        batch_indices = torch.arange(distances.size(0), device=distances.device)\n",
    "        pos_dist = distances[batch_indices, pos_idx]\n",
    "        neg_dist = distances[batch_indices, neg_idx]\n",
    "\n",
    "        triplet_vals = torch.stack([pos_dist, neg_dist], dim = 1)\n",
    "\n",
    "        hn_ratio = (neg_dist < pos_dist).float().mean() if pos_dist.numel() else torch.tensor(0.0)  # pyright: ignore[reportUnknownVariableType, reportUnknownMemberType]\n",
    "        \n",
    "        stats: Dict[str, Any] = {\n",
    "            \"pos\": pos_dist.detach(), \n",
    "            \"neg\": neg_dist.detach(),\n",
    "            \"triplet_vals\": triplet_vals.detach(),\n",
    "            \"hn_ratio\": hn_ratio.item(),\n",
    "            \"pos_idx\": pos_idx.detach(),\n",
    "            \"neg_idx\": neg_idx.detach(),\n",
    "        }\n",
    "        \n",
    "        triplet_loss = self.base_loss(embeddings, positives, negatives)\n",
    "\n",
    "        if self.use_diversity and self.lambda_diversity > 0:\n",
    "            triplet_loss = triplet_loss + self._compute_diversity_regularisation(embeddings)\n",
    "\n",
    "        return triplet_loss, stats\n",
    "\n",
    "    # Gives me 1s and 0s\n",
    "    def _get_triplet_mask(\n",
    "        self, \n",
    "        labels: torch.Tensor\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        labels = labels.unsqueeze(1)\n",
    "        mask_anchor_positive = (labels == labels.T) & ~torch.eye(\n",
    "            labels.size(0), dtype=torch.bool, device=labels.device\n",
    "        )\n",
    "        mask_anchor_negative = labels != labels.T\n",
    "        \n",
    "        return (mask_anchor_positive, mask_anchor_negative)\n",
    "    \n",
    "    def _batch_hard_mining(\n",
    "        self,\n",
    "        distances: torch.Tensor,\n",
    "        mask_anchor_positive: torch.Tensor,\n",
    "        mask_anchor_negative: torch.Tensor,\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \n",
    "        positive_distance = torch.where(\n",
    "            mask_anchor_positive, distances, torch.full_like(distances, -float(\"inf\"))\n",
    "        )\n",
    "        \n",
    "        _max_positive_distance, pos_idx = torch.max(positive_distance, dim=1)\n",
    "        \n",
    "        negative_distance = torch.where(\n",
    "            mask_anchor_negative, distances, torch.full_like(distances, float(\"inf\"))\n",
    "        )\n",
    "        _min_negative_distance, neg_idx = torch.min(negative_distance, dim=1)\n",
    "        \n",
    "        return pos_idx, neg_idx\n",
    "\n",
    "    def _batch_semi_hard_mining(\n",
    "        self,\n",
    "        distances: torch.Tensor,\n",
    "        mask_anchor_positive: torch.Tensor,\n",
    "        mask_anchor_negative: torch.Tensor,\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        positive_distance_filtered = torch.where(\n",
    "            mask_anchor_positive, distances, torch.full_like(distances, -float(\"inf\"))\n",
    "        )\n",
    "        hardest_positive_dist, pos_idx = torch.max(positive_distance_filtered, dim=1)\n",
    "        \n",
    "        valid_negative_distances = torch.where(\n",
    "            mask_anchor_negative, distances, torch.full_like(distances, float(\"inf\"))\n",
    "        )\n",
    "        \n",
    "        is_harder_than_positive = valid_negative_distances > hardest_positive_dist.unsqueeze(1)\n",
    "        \n",
    "        is_easier_than_margin = valid_negative_distances < (\n",
    "            hardest_positive_dist.unsqueeze(1) + self.margin\n",
    "        )\n",
    "        \n",
    "        semi_hard_mask = mask_anchor_negative & is_harder_than_positive & is_easier_than_margin\n",
    "\n",
    "        semi_hard_negatives = torch.where(\n",
    "            semi_hard_mask, distances, torch.full_like(distances, float(\"inf\"))\n",
    "        )\n",
    "        \n",
    "        _easiest_semi_hard, semi_idx = torch.min(semi_hard_negatives, dim=1)\n",
    "        _hardest_overall, hard_idx = torch.min(valid_negative_distances, dim=1)\n",
    "\n",
    "        use_semi = semi_hard_mask.sum(dim=1) > 0\n",
    "        neg_idx = torch.where(use_semi, semi_idx, hard_idx)\n",
    "        \n",
    "        return pos_idx, neg_idx, use_semi\n",
    "    \n",
    "    # This is not really necessary\n",
    "    def _compute_diversity_regularisation(self, embeddings: torch.Tensor) -> torch.Tensor:\n",
    "        sim = embeddings @ embeddings.T\n",
    "        eye = torch.eye(sim.size(0), device=sim.device, dtype=sim.dtype)\n",
    "        diversity = (sim - eye).pow(2).mean()\n",
    "        return self.lambda_diversity * diversity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16860520",
   "metadata": {},
   "source": [
    "### SCTLoss(nn.Module)\n",
    "```python\n",
    "print(f'loss:{loss.item():.3f} hn_rt:{hn_ratio.item():.3f}', end='\\r')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b27ca70",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SCTLoss(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        method: str, \n",
    "        lam: float=1.0, \n",
    "        margin: float = 1.0,\n",
    "        verbose: bool = False,\n",
    "    ):\n",
    "        super(SCTLoss, self).__init__() # pyright: ignore[reportUnknownMemberType]\n",
    "        if method == 'sct':\n",
    "            self.sct, self.semi = True, False\n",
    "        elif method == 'hn':\n",
    "            self.sct, self.semi = False, False\n",
    "        elif method == 'shn':\n",
    "            self.sct, self.semi = False, True\n",
    "        else: raise ValueError('loss type is not supported')\n",
    "        self.lam = lam\n",
    "        self.margin = margin\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        fvec: torch.Tensor,\n",
    "        Lvec: torch.Tensor,\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        \n",
    "        # Already normalised in the model\n",
    "        # fvec_norm: torch.Tensor = F.normalize(fvec, p = 2, dim = 1)\n",
    "       \n",
    "        device = fvec.device\n",
    "        Same, Diff = self._build_boolean_masks(Lvec.view(-1))\n",
    "        CosSim = self._calculate_cosine_similarity(fvec, fvec)\n",
    "        \n",
    "        Pos, I_pos, Mask_pos_valid, _Pos_log = self._select_positives(CosSim, Diff)\n",
    "        Neg, I_neg, Mask_neg_valid, _Neg_log = self._select_negatives(CosSim, Same, Diff, Pos)\n",
    "\n",
    "        Triplet_val, Triplet_idx, HardMask, EasyMask, hn_ratio = self._build_triplets(\n",
    "            Pos, Neg, I_pos, I_neg, Mask_pos_valid, Mask_neg_valid\n",
    "        )\n",
    "        \n",
    "        loss = self._compute_loss(Triplet_val, Pos, Neg, HardMask, EasyMask, device)\n",
    "\n",
    "        if self.verbose:\n",
    "            hr = float(hn_ratio) if isinstance(hn_ratio, (float, int)) or (hasattr(hn_ratio, \"item\") and not torch.isnan(hn_ratio)) else 0.0\n",
    "            print(f'loss:{loss.item():.4f} hn_rt:{hr:.4f}', end='\\r')\n",
    "        \n",
    "        return (\n",
    "            loss, \n",
    "            Triplet_val.clone().detach().cpu(), \n",
    "            Triplet_idx.clone().detach().cpu(), \n",
    "            hn_ratio if isinstance(hn_ratio, float) else hn_ratio.clone().detach().cpu(),\n",
    "            Pos.detach().cpu(), \n",
    "            Neg.detach().cpu()\n",
    "        )\n",
    "        \n",
    "    def _select_positives(\n",
    "        self, \n",
    "        CosSim: torch.Tensor, \n",
    "        Diff: torch.Tensor\n",
    "    ) -> Tuple[\n",
    "            torch.Tensor, \n",
    "            torch.Tensor, \n",
    "            torch.Tensor,\n",
    "            torch.Tensor,\n",
    "        ]:\n",
    "        \n",
    "        D_pos = CosSim.clone().detach()\n",
    "        D_pos[Diff] = -1\n",
    "        # D_pos[D_pos>0.9999] = -1\n",
    "        V_pos, I_pos = D_pos.max(1)\n",
    " \n",
    "        Mask_pos_valid = (V_pos > -1) & (V_pos < 1)\n",
    "        Pos = CosSim[torch.arange(0, CosSim.size(0)), I_pos]\n",
    "        Pos_log = Pos.clone().detach().cpu()\n",
    "    \n",
    "        return Pos, I_pos, Mask_pos_valid, Pos_log\n",
    "    \n",
    "    def _select_negatives(\n",
    "        self, \n",
    "        CosSim: torch.Tensor,\n",
    "        Same: torch.Tensor,\n",
    "        Diff: torch.Tensor, \n",
    "        V_pos: torch.Tensor\n",
    "    ) -> Tuple[\n",
    "            torch.Tensor, \n",
    "            torch.Tensor, \n",
    "            torch.Tensor,\n",
    "            torch.Tensor,\n",
    "        ]:\n",
    "        \n",
    "        D_neg = CosSim.clone().detach()\n",
    "        D_neg[Same] = -1\n",
    "        \n",
    "        # Masking out non-Semi-Hard Negative\n",
    "        if self.semi:    \n",
    "            D_neg[(D_neg > V_pos.unsqueeze(1)) & Diff] = -1 \n",
    "            # D_neg[(D_neg > (V_pos.repeat(CosSim.size(0), 1).t())) & Diff] = -1\n",
    "            \n",
    "        V_neg, I_neg = D_neg.max(1)\n",
    "        Mask_neg_valid = (V_neg > -1) & (V_neg < 1)\n",
    "        Neg = CosSim[torch.arange(0, CosSim.size(0)), I_neg]\n",
    "        Neg_log = Neg.clone().detach().cpu()\n",
    "        \n",
    "        return Neg, I_neg, Mask_neg_valid, Neg_log \n",
    "        \n",
    "    def _build_triplets(\n",
    "        self, \n",
    "        Pos: torch.Tensor, \n",
    "        Neg: torch.Tensor,\n",
    "        I_pos: torch.Tensor,\n",
    "        I_neg: torch.Tensor,\n",
    "        Mask_pos_valid: torch.Tensor,\n",
    "        Mask_neg_valid: torch.Tensor\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        \n",
    "        Mask_valid = Mask_pos_valid & Mask_neg_valid\n",
    "        HardMask = ((Neg > Pos) | (Neg > 0.8)) & Mask_valid\n",
    "        EasyMask = ((Neg < Pos) & (Neg < 0.8)) & Mask_valid\n",
    "        hn_ratio = (Neg>Pos)[Mask_valid].clone().float().mean().cpu()\n",
    "        \n",
    "        Triplet_val = torch.stack([Pos, Neg], 1)\n",
    "        Triplet_idx = torch.stack([I_pos, I_neg], 1)\n",
    "        \n",
    "        return Triplet_val, Triplet_idx, HardMask, EasyMask, hn_ratio\n",
    "    \n",
    "        # Triplet_val_log = Triplet_val.clone().detach().cpu()\n",
    "        # Triplet_idx_log = Triplet_idx.clone().detach().cpu()\n",
    "        \n",
    "    def _compute_loss(\n",
    "        self, \n",
    "        Triplet_val: torch.Tensor, \n",
    "        Pos: torch.Tensor, \n",
    "        Neg: torch.Tensor,\n",
    "        HardMask: torch.Tensor, \n",
    "        EasyMask: torch.Tensor,\n",
    "        device: torch.device,\n",
    "    ) -> torch.Tensor:\n",
    "        if self.sct:    \n",
    "            loss_hard = Neg[HardMask].sum()\n",
    "            N_hard = HardMask.float().sum().item()\n",
    "            if torch.isnan(loss_hard) or N_hard == 0:\n",
    "                loss_hard, N_hard = torch.tensor(0.0), 0\n",
    "                print('No hard triplets in the batch')\n",
    "                \n",
    "            loss_easy = -F.log_softmax(\n",
    "                Triplet_val[EasyMask, :] / 0.1, dim=1\n",
    "            )[:, 0].sum()\n",
    "            N_easy = EasyMask.float().sum().item()\n",
    "            if torch.isnan(loss_easy) or N_easy == 0:\n",
    "                loss_easy, N_easy = torch.tensor(0.0), 0\n",
    "                print('No easy triplets in the batch')\n",
    "            \n",
    "            pos_valid = (Pos > -1) & ( Pos < 1)\n",
    "            N_pos = int(pos_valid.float().sum().item())\n",
    "            if N_pos > 0:\n",
    "                positive_pull = F.relu(self.margin - Pos[pos_valid]).sum()\n",
    "            else:\n",
    "                positive_pull = torch.Tensor(0.0, device=device)\n",
    "            \n",
    "            N_total = max(N_hard + N_easy, 1)\n",
    "            return (loss_easy + self.lam * loss_hard + 0.5 * positive_pull) / N_total\n",
    "            # return (loss_easy + self.lam * loss_hard) / N_total\n",
    "        else:\n",
    "            return -F.log_softmax(Triplet_val / 0.1, dim=1)[:, 0].mean()\n",
    "\n",
    "            # return -F.log_softmax(\n",
    "            #     Triplet_val[Triplet_val, :] / 0.1, dim=1\n",
    "            # )[:, 0].mean()\n",
    "\n",
    "    def _calculate_cosine_similarity(\n",
    "        self,     \n",
    "        Mat_A: torch.Tensor, \n",
    "        Mat_B: torch.Tensor, \n",
    "        norm:int=1, \n",
    "    ) -> torch.Tensor: \n",
    "        \n",
    "        Mat_A = F.normalize(Mat_A, p=2, dim=1)\n",
    "        Mat_B = F.normalize(Mat_B, p=2, dim=1)\n",
    "        # _N_A = Mat_A.size(0)\n",
    "        # _N_B = Mat_B.size(0)\n",
    "    \n",
    "        D = Mat_A.mm(torch.t(Mat_B))\n",
    "    \n",
    "        # Ignore self-similarity\n",
    "        D.fill_diagonal_(-norm)\n",
    "        return D\n",
    "    \n",
    "    def _build_boolean_masks(\n",
    "        self, \n",
    "        Lvec: torch.Tensor\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        # N = Lvec.size(0)\n",
    "        # Forms N x N\n",
    "        # Mask = Lvec.repeat(N,1)\n",
    "        \n",
    "        # True if labels match\n",
    "        Same = Lvec.unsqueeze(0) == Lvec.unsqueeze(1)\n",
    "        # Same = (Mask == Mask.t())\n",
    "        \n",
    "        # Same / Different masks\n",
    "        return Same.clone().fill_diagonal_(0), ~Same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97f5e093",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SCTLossWrapper(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        method: str = \"sct\", \n",
    "        lam: float = 1.0,\n",
    "        margin: float = 1.0,\n",
    "        verbose: bool = False\n",
    "    ) -> None:\n",
    "        super().__init__() # pyright: ignore[reportUnknownMemberType]\n",
    "        self.loss_fn = SCTLoss(method, lam, margin, verbose)\n",
    "\n",
    "    def forward(\n",
    "        self, \n",
    "        fvec: torch.Tensor, \n",
    "        Lvec: torch.Tensor\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        \n",
    "        # SCTLoss returns (loss, Triplet_val.clone().detach().cpu(), Triplet_idx.clone().detach().cpu(), hn_ratio, Pos, Neg)\n",
    "        return self.loss_fn(fvec, Lvec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f07ccb5",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f58e0cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PKSampler(Sampler[List[int]]):\n",
    "    def __init__(\n",
    "        self,\n",
    "        label_to_indices: Dict[str, List[int]],  # now full labels, e.g., \"10_orig\", \"10_forg\"\n",
    "        P: int,  # signers per batch\n",
    "        K: int,  # originals per signer\n",
    "        F: int,  # forgeries per signer\n",
    "        M: int,  # inter-signer negatives per signer\n",
    "        seed: int = 42,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        label_to_indices: Dict[label_string, List[idx]]\n",
    "            e.g., {\"10_orig\": [0,1,2], \"10_forg\": [25,26], \"11_orig\": [...], ...}\n",
    "        \"\"\"\n",
    "        self.P = P\n",
    "        self.K = K\n",
    "        self.F = F\n",
    "        self.M = M\n",
    "        self.label_to_indices = label_to_indices\n",
    "        self.signers = sorted({lbl.split(\"_\")[0] for lbl in label_to_indices.keys()})\n",
    "        self.seed = seed\n",
    "\n",
    "        # Precompute label-wise pools\n",
    "        self._all_indices: List[int] = []\n",
    "        self._indices_by_label: Dict[str, List[int]] = {}\n",
    "        self._indices_by_signer: Dict[str, List[int]] = defaultdict(list)\n",
    "        \n",
    "        for label, idxs in label_to_indices.items():\n",
    "            self._indices_by_label[label] = idxs\n",
    "            signer_id = label.split(\"_\")[0]\n",
    "            self._indices_by_signer[signer_id].extend(idxs)\n",
    "            self._all_indices.extend(idxs)\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return max(1, len(self.signers) // self.P * 10)\n",
    "\n",
    "    def __iter__(self) -> Iterator[List[int]]:\n",
    "        rng = random.Random(self.seed)\n",
    "        num_batches = len(self)\n",
    "        for _ in range(num_batches):\n",
    "            selected_signers = rng.sample(self.signers, self.P)\n",
    "            batch: List[int] = []\n",
    "\n",
    "            for sid in selected_signers:\n",
    "                orig_label = f\"{sid}_orig\"\n",
    "                forg_label = f\"{sid}_forg\"\n",
    "\n",
    "                originals = self._indices_by_label.get(orig_label, [])\n",
    "                forgeries = self._indices_by_label.get(forg_label, [])\n",
    "\n",
    "                # Sample K originals (anchor + positives)\n",
    "                pos = rng.sample(originals, self.K) if len(originals) >= self.K else rng.choices(originals, k=self.K)\n",
    "\n",
    "                # Sample F intra-signer forgeries as hard negatives\n",
    "                neg_hard = rng.sample(forgeries, self.F) if len(forgeries) >= self.F else rng.choices(forgeries, k=self.F)\n",
    "\n",
    "                # Sample M inter-signer negatives (any label from other signers)\n",
    "                global_pool = [idx for idx in self._all_indices if idx not in self._indices_by_signer[sid]]\n",
    "                neg_global = rng.sample(global_pool, self.M) if len(global_pool) >= self.M else rng.choices(global_pool, k=self.M)\n",
    "\n",
    "                batch.extend(pos + neg_hard + neg_global)\n",
    "\n",
    "            yield batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7fc95957",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SignatureDataset(Dataset[Tuple[torch.Tensor, str]]):\n",
    "    def __init__(\n",
    "        self, \n",
    "        data_map: Dict[str, Dict[str, List[str]]],\n",
    "        transform: Optional[Callable[[Image.Image], torch.Tensor]] = None,\n",
    "    ) -> None:\n",
    "        self.data_map = data_map\n",
    "        self.transform = transform\n",
    "        self.signer_ids = sorted(list(data_map.keys()), key=int)\n",
    "        \n",
    "        # signer id, image type, index\n",
    "        self.all_image_references: List[Tuple[str, str, int]] = []\n",
    "        # self.labels: List[int] = []\n",
    "        \n",
    "        for signer_id in self.signer_ids:\n",
    "            for index, _ in enumerate(data_map[signer_id].get(\"original\", [])):\n",
    "                self.all_image_references.append((signer_id, \"original\", index))\n",
    "            \n",
    "            for index, _ in enumerate(data_map[signer_id].get(\"forged\", [])):\n",
    "                self.all_image_references.append((signer_id, \"forged\", index))\n",
    "        \n",
    "        \n",
    "        self.labels = [\n",
    "            f\"{signer_id}_{img_type[:4]}\"  # \"orig\" or \"forg\"\n",
    "            for signer_id, img_type, _ in self.all_image_references\n",
    "        ]\n",
    "        \n",
    "\n",
    "    def __len__(self)->int:\n",
    "        return len(self.all_image_references)\n",
    "    \n",
    "    def __getitem__(self, index: int) -> Tuple[torch.Tensor, str]:\n",
    "        signer_id, image_type, image_index = self.all_image_references[index]\n",
    "                \n",
    "        path: str = self.data_map[signer_id][image_type][image_index]\n",
    "        \n",
    "        image_pil: Image.Image = Image.open(path).convert(\"L\")\n",
    "            \n",
    "        if self.transform is not None:\n",
    "            image_tensor: torch.Tensor = self.transform(image_pil)\n",
    "        else:\n",
    "            image_array: npt.NDArray[np.uint8] = np.array(image_pil, dtype=np.uint8)\n",
    "            image_tensor: torch.Tensor = torch.from_numpy(image_array).unsqueeze(0).float() / 255.0 # type: ignore\n",
    "        \n",
    "        label = f\"{signer_id}_{image_type[:4]}\"\n",
    "        \n",
    "        # signer_label_tensor = torch.tensor(int(signer_id), dtype=torch.long)\n",
    "        \n",
    "        return image_tensor, label\n",
    "        # return image_tensor, signer_label_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c78fad52",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestSignatureDataset(Dataset[Tuple[torch.Tensor, str]]):\n",
    "    \"\"\"\n",
    "    Produces samples in the exact order expected by build_verification_pairs():\n",
    "        sorted signer IDs → originals → forgeries\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_map: Dict[str, Dict[str, List[str]]],\n",
    "        transform: Optional[Callable[[Image.Image], torch.Tensor]] = None,\n",
    "    ) -> None:\n",
    "        self.data_map = data_map\n",
    "        self.transform = transform\n",
    "\n",
    "        # Ensure deterministic ordering\n",
    "        self.signer_ids = sorted(list(data_map.keys()), key=int)\n",
    "\n",
    "        # Build ordered list matching evaluation logic\n",
    "        self.ordered_items: List[Tuple[str, str, str]] = []\n",
    "        # (signer_id, \"original\"/\"forged\", path)\n",
    "\n",
    "        for sid in self.signer_ids:\n",
    "            for path in data_map[sid].get(\"original\", []):\n",
    "                self.ordered_items.append((sid, \"original\", path))\n",
    "\n",
    "            for path in data_map[sid].get(\"forged\", []):\n",
    "                self.ordered_items.append((sid, \"forged\", path))\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.ordered_items)\n",
    "\n",
    "    def __getitem__(self, index: int) -> Tuple[torch.Tensor, str]:\n",
    "        signer_id, _img_type, path = self.ordered_items[index]\n",
    "\n",
    "        image_pil = Image.open(path).convert(\"L\")\n",
    "\n",
    "        if self.transform is not None:\n",
    "            image_tensor: torch.Tensor = self.transform(image_pil)\n",
    "        else:\n",
    "            image_array: npt.NDArray[np.uint8] = np.array(image_pil, dtype=np.uint8)\n",
    "            image_tensor: torch.Tensor = torch.from_numpy(image_array).unsqueeze(0).float() / 255.0 # pyright: ignore[reportUnknownMemberType]\n",
    "        \n",
    "        # IMPORTANT:\n",
    "        # evaluation code expects label to be a *tensor containing string IDs*\n",
    "        # but torch can't store strings → so evaluation uses batching with collate_fn default\n",
    "        # Each label is kept as a Python string.\n",
    "        return image_tensor, signer_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3be25f0",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8267645b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(\n",
    "        self, \n",
    "        model: nn.Module,\n",
    "        loss_function: nn.Module,\n",
    "        learning_config: Dict[str, str | int | float],\n",
    "        optimiser_config: Dict[str, str | float],\n",
    "        scheduler_config: SchedulerConfig,\n",
    "        save_checkpoints: bool = True\n",
    "    ) -> None:\n",
    "        \n",
    "        self.model = model\n",
    "        \n",
    "        # Training loop\n",
    "        self.epoch = int(learning_config[\"EPOCH\"])\n",
    "        self.batch_size = int(learning_config[\"BATCH_SIZE\"])\n",
    "        self.lr = float(learning_config[\"LEARNING_RATE\"])\n",
    "        self.early_stop = int(learning_config[\"EARLY_STOPPING_PATIENT\"])\n",
    "        self.checkpoint_path = Path(str(learning_config[\"CHECKPOINT_DIR\"]))\n",
    "        self.save_checkpoints = bool(save_checkpoints)\n",
    "        self.device = torch.device(str(learning_config[\"DEVICE\"]))\n",
    "        self.device_type = self.device.type\n",
    "        self.global_step = 0\n",
    "        \n",
    "        self.best_val_auc = float(\"inf\")\n",
    "        self.patience_counter = 0\n",
    "        \n",
    "        # Optimiser\n",
    "        self.optimiser = self._build_optimiser(optimiser_config)\n",
    "        \n",
    "        # Scheduler\n",
    "        self.scheduler = self._build_scheduler(scheduler_config)\n",
    "\n",
    "        # Loss function\n",
    "        self.loss_function = loss_function\n",
    "        \n",
    "        # Mixed precision\n",
    "        self.scaler = GradScaler()\n",
    "        \n",
    "        # Moving to GPU\n",
    "        self.model.to(self.device)\n",
    "        \n",
    "        # checkpointing\n",
    "        self.checkpoint_path.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Tensorboard\n",
    "        log_dir = learning_config[\"LOG_DIR\"]\n",
    "        self.writer = SummaryWriter(log_dir)\n",
    "        \n",
    "    def train_epoch(\n",
    "        self, dataloader: DataLoader[Tuple[torch.Tensor, str]]\n",
    "    ) -> float:\n",
    "        self.model.train()\n",
    "        running_loss: float = 0.0\n",
    "        num_batches: int = len(dataloader)\n",
    "        \n",
    "        for batch_index, (images, labels) in enumerate(dataloader):\n",
    "            images = images.to(self.device)\n",
    "            unique_labels = sorted(set(labels))\n",
    "            label_to_int = {label: i for i, label in enumerate(unique_labels)}\n",
    "            label_tensor = torch.tensor([label_to_int[label] for label in labels], dtype=torch.long, device=self.device)\n",
    "        \n",
    "            self.optimiser.zero_grad()\n",
    "            \n",
    "            with autocast(device_type=self.device_type):\n",
    "                outputs = self.model(images)\n",
    "                \n",
    "                # SCTLoss returns (loss, triplet_vals, triplet_idxs, hn_ratio, Pos_log, Neg_log)\n",
    "                loss, triplet_vals, _triplet_idxs, hn_ratio, pos, neg= self.loss_function(outputs, label_tensor)\n",
    "                \n",
    "                # Vanilla Triplet Loss returns (loss, stats)\n",
    "                # loss, stats = self.loss_function(outputs, label_tensor)\n",
    "            \n",
    "            # Gradient clipping is optional\n",
    "            \n",
    "            self.scaler.scale(loss).backward()  # pyright: ignore[reportUnknownMemberType]\n",
    "            self.scaler.step(self.optimiser)\n",
    "            self.scaler.update()\n",
    "            \n",
    "            # OneCycleLR steps for batch, not epoch\n",
    "            if isinstance(self.scheduler, lr_scheduler.OneCycleLR):\n",
    "                self.scheduler.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            self.global_step += 1\n",
    "            \n",
    "            if batch_index % 19 == 0:\n",
    "                # For both SCT and vanilla Triplet Loss\n",
    "                self.writer.add_scalar(f\"Train/BatchLoss\", loss.item(), self.global_step) # pyright: ignore[reportUnknownMemberType]\n",
    "                \n",
    "                # # SCT\n",
    "                self.writer.add_scalar(f\"Train/HN_Ratio\", hn_ratio.item(), self.global_step) # pyright: ignore[reportUnknownMemberType]\n",
    "                self.writer.add_scalar(f\"Train/PosMean\", pos.mean().item(), self.global_step) # pyright: ignore[reportUnknownMemberType]\n",
    "                self.writer.add_scalar(f\"Train/NegMean\", neg.mean().item(), self.global_step) # pyright: ignore[reportUnknownMemberType]\n",
    "                \n",
    "                self.writer.add_histogram(f\"Train/Pos\", triplet_vals[:,0], self.global_step) # pyright: ignore[reportUnknownMemberType]\n",
    "                self.writer.add_histogram(f\"Train/Neg\", triplet_vals[:,1], self.global_step) # pyright: ignore[reportUnknownMemberType]\n",
    "                \n",
    "                # Vanilla Triplet Loss\n",
    "                # self.writer.add_scalar(\"Train/HN_Ratio\", stats[\"hn_ratio\"], self.global_step) # pyright: ignore[reportUnknownMemberType]\n",
    "                # self.writer.add_scalar(\"Train/PosMean\", stats[\"pos\"].mean().item(), self.global_step) # pyright: ignore[reportUnknownMemberType]\n",
    "                # self.writer.add_scalar(\"Train/NegMean\", stats[\"neg\"].mean().item(), self.global_step) # pyright: ignore[reportUnknownMemberType]\n",
    "\n",
    "                # self.writer.add_histogram(\"Train/Pos\", stats[\"triplet_vals\"][:,0], self.global_step) # pyright: ignore[reportUnknownMemberType]\n",
    "                # self.writer.add_histogram(\"Train/Neg\", stats[\"triplet_vals\"][:,1], self.global_step) # pyright: ignore[reportUnknownMemberType]\n",
    "                \n",
    "                total_norm: float = 0.\n",
    "                for p in self.model.parameters():\n",
    "                    if p.grad is not None:\n",
    "                        total_norm += float(p.grad.data.norm(2).item()) # pyright: ignore[reportUnknownArgumentType, reportUnknownMemberType]\n",
    "                        \n",
    "                self.writer.add_scalar(\"Gradients/TotalNorm\", total_norm, self.global_step) # pyright: ignore[reportUnknownMemberType]\n",
    "        \n",
    "        return running_loss / num_batches\n",
    "        \n",
    "    def evaluate(\n",
    "        self,\n",
    "        dataloader: DataLoader[Tuple[torch.Tensor, str]] \n",
    "    ) -> Tuple[\n",
    "            Dict[str, float], \n",
    "            torch.Tensor, \n",
    "            List[str]\n",
    "    ]:\n",
    "        self.model.eval()\n",
    "        all_embeddings_list: List[torch.Tensor] = []\n",
    "        all_labels: List[str] = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels in dataloader:\n",
    "                images = images.to(self.device)\n",
    "                \n",
    "                with autocast(device_type=self.device_type):\n",
    "                    embeddings = self.model(images)\n",
    "                    all_embeddings_list.append(embeddings.cpu())\n",
    "                    all_labels.extend(labels)\n",
    "        \n",
    "        all_embeddings = torch.cat(all_embeddings_list, dim=0)\n",
    "        n = len(all_labels)\n",
    "        \n",
    "        similarity_matrix = F.cosine_similarity(\n",
    "            all_embeddings.unsqueeze(1),\n",
    "            all_embeddings.unsqueeze(0),\n",
    "            dim=2\n",
    "        )\n",
    "        \n",
    "        signer_ids = [label.split(\"_\")[0] for label in all_labels]\n",
    "        intra_mask = torch.zeros((n, n), dtype=torch.bool)\n",
    "        inter_mask = torch.zeros((n, n), dtype=torch.bool)\n",
    "        \n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                if i == j:\n",
    "                    continue\n",
    "                if signer_ids[i] == signer_ids[j]:\n",
    "                    intra_mask[i, j] = True\n",
    "                else:\n",
    "                    inter_mask[i, j] = True\n",
    "\n",
    "        intra_sims: torch.Tensor = similarity_matrix[intra_mask] \n",
    "        inter_sims: torch.Tensor = similarity_matrix[inter_mask]  \n",
    "\n",
    "        intra_sims_np = intra_sims.cpu().numpy() # type: ignore\n",
    "        inter_sims_np = inter_sims.cpu().numpy() # type: ignore\n",
    "\n",
    "        # Metrics\n",
    "        y_true = [1] * len(intra_sims_np) + [0] * len(inter_sims_np) # type: ignore\n",
    "        y_scores = list(intra_sims_np) + list(inter_sims_np) # type: ignore\n",
    "        auc = roc_auc_score(y_true, y_scores)\n",
    "\n",
    "        metrics: Dict[str, float | int] = {\n",
    "            \"AUC\": auc, # type: ignore\n",
    "            \"mean_intra_similarity\": float(intra_sims.mean()),\n",
    "            \"mean_inter_similarity\": float(inter_sims.mean()),\n",
    "            \"num_intra_pairs\": len(intra_sims),\n",
    "            \"num_inter_pairs\": len(inter_sims)\n",
    "        }\n",
    "\n",
    "        return metrics, all_embeddings, all_labels\n",
    "    \n",
    "    def fit(\n",
    "        self, \n",
    "        train_dataloader: DataLoader[Tuple[torch.Tensor, str]],\n",
    "        val_dataloader: DataLoader[Tuple[torch.Tensor, str]]\n",
    "    ) -> None: \n",
    "        for epoch in range(self.epoch):\n",
    "            train_loss = self.train_epoch(train_dataloader)\n",
    "            val_metrics, val_embedding, all_labels = self.evaluate(val_dataloader)\n",
    "            \n",
    "            self.writer.add_embedding( # pyright: ignore[reportUnknownMemberType]\n",
    "                mat = val_embedding,\n",
    "                metadata=all_labels,\n",
    "                global_step=self.global_step\n",
    "            )\n",
    "            \n",
    "            self.writer.add_scalar(\"Loss/train\", train_loss, epoch) # pyright: ignore[reportUnknownMemberType]\n",
    "            self.writer.add_scalar(\"AUC/val\", val_metrics[\"AUC\"], epoch) # pyright: ignore[reportUnknownMemberType]\n",
    "            # I should change this to include loss value from validation too\n",
    "            self.writer.add_scalar(\"Loss/1_minus_auc\", 1.0 - val_metrics[\"AUC\"], epoch) # pyright: ignore[reportUnknownMemberType] \n",
    "            self.writer.add_scalar(\"Learning rate\", self.optimiser.param_groups[0][\"lr\"], epoch) # pyright: ignore[reportUnknownMemberType]\n",
    "            \n",
    "            if self.scheduler is not None and not isinstance(self.scheduler, lr_scheduler.OneCycleLR):\n",
    "                self.scheduler.step()\n",
    "\n",
    "            print(f\"Epoch [{epoch + 1}/{self.epoch}]\"\n",
    "                  f\"| Train loss: {train_loss:.4f}\"\n",
    "                  f\"| AUC: {val_metrics[\"AUC\"]:.4f}\")\n",
    "        \n",
    "            val_auc_for_stop = 1.0 - val_metrics[\"AUC\"]\n",
    "            if val_auc_for_stop < self.best_val_auc:\n",
    "                self.best_val_auc = val_auc_for_stop\n",
    "                self.patience_counter = 0\n",
    "                if self.save_checkpoints:\n",
    "                    self._save_checkpoint(epoch, val_auc_for_stop, self.best_val_auc, self.patience_counter)\n",
    "            else:\n",
    "                self.patience_counter+=1\n",
    "                if self.patience_counter >= self.early_stop:\n",
    "                    print(\"Early stopping\")\n",
    "                    break\n",
    "        \n",
    "        self.writer.close()\n",
    "    \n",
    "    def load_checkpoint(\n",
    "        self, \n",
    "        path: str\n",
    "    ) -> None:\n",
    "        \n",
    "        self._has_path(path)\n",
    "        try:\n",
    "            checkpoint_model: ModelState = torch.load(path, map_location=self.device)\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Error loading checkpoint from {path}: {e}\")\n",
    "        \n",
    "        self.model.load_state_dict(checkpoint_model[\"model_state_dict\"])\n",
    "        self.optimiser.load_state_dict(checkpoint_model[\"optimiser_state_dict\"])\n",
    "        \n",
    "        if self.scheduler and checkpoint_model[\"scheduler_state_dict\"] is not None:\n",
    "            self.scheduler.load_state_dict(checkpoint_model[\"scheduler_state_dict\"])\n",
    "        \n",
    "        self.epoch = checkpoint_model[\"epoch\"]\n",
    "        self.best_val_auc = checkpoint_model[\"best_loss\"]\n",
    "        self.patience_counter = checkpoint_model[\"patience_counter\"]\n",
    "    \n",
    "    def _save_checkpoint(\n",
    "        self, \n",
    "        epoch: int, \n",
    "        auc: float, \n",
    "        best_auc: float, \n",
    "        patience_counter: int,\n",
    "    ) -> None:\n",
    "        model_state: ModelState = {\n",
    "            \"epoch\": epoch,\n",
    "            \"model_state_dict\": self.model.state_dict(),\n",
    "            \"optimiser_state_dict\": self.optimiser.state_dict(),\n",
    "            \"scheduler_state_dict\": self.scheduler.state_dict() if self.scheduler else None,\n",
    "            \"auc\": auc,\n",
    "            \"best_loss\": best_auc,\n",
    "            \"patience_counter\": patience_counter\n",
    "        }\n",
    "        \n",
    "        torch.save(\n",
    "            model_state, self.checkpoint_path / f\"{epoch+1}_auc_{auc:.4f}.pt\"\n",
    "        )\n",
    "    \n",
    "    def _has_path(self, path: str) -> None:\n",
    "        if not Path(path).exists():\n",
    "            raise FileNotFoundError(f\"File not found at {path}\")\n",
    "        print(f\"File is ok!\")\n",
    "                \n",
    "    def _build_optimiser(self, optimiser_config: Dict[str, str | float]) -> optim.Optimizer:\n",
    "        optimiser_name =  str(optimiser_config[\"optimiser\"])\n",
    "        optimiser_class = getattr(optim, optimiser_name)\n",
    "        \n",
    "        optimiser_params = {**optimiser_config}\n",
    "        optimiser_params.pop(\"optimiser\")\n",
    "        optimiser_params[\"lr\"] = self.lr\n",
    "        \n",
    "        return optimiser_class(self.model.parameters(), **optimiser_params)\n",
    "        \n",
    "    def _build_scheduler(\n",
    "        self, \n",
    "        scheduler_config: SchedulerConfig,\n",
    "        ) -> Optional[lr_scheduler.LRScheduler]:\n",
    "        schedulers: List[lr_scheduler.LRScheduler] = []\n",
    "         \n",
    "        for sched_cfg in scheduler_config.get(\"SCHEDULERS\", []):\n",
    "            name = sched_cfg[\"name\"]\n",
    "            params = sched_cfg.get(\"params\", {})\n",
    "            sched_class = getattr(lr_scheduler, name)\n",
    "            schedulers.append(sched_class(self.optimiser, **params))\n",
    "\n",
    "        if scheduler_config.get(\"SCHEDULER\") == \"SequentialLR\":\n",
    "            return lr_scheduler.SequentialLR(\n",
    "                self.optimiser,\n",
    "                schedulers=schedulers,\n",
    "                milestones=scheduler_config.get(\"MILESTONES\", [])\n",
    "            )\n",
    "        \n",
    "        return schedulers[0] if schedulers else None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853218a0",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e234a665",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(\n",
    "    pos_scores: List[float],\n",
    "    neg_scores: List[float]\n",
    ") -> Dict[str, Any]:\n",
    "    \n",
    "    metrics: Dict[str, Any] = {\n",
    "        \"AUC\": float(\"nan\"),\n",
    "        \"EER\": float(\"nan\"),\n",
    "        \"threshold\": float(\"nan\"),\n",
    "        \"fpr\": np.array([]),\n",
    "        \"tpr\": np.array([]),\n",
    "    }\n",
    "    \n",
    "    if len(pos_scores) == 0 or len(neg_scores) == 0:\n",
    "        return metrics\n",
    "    \n",
    "    y_true = [1] * len(pos_scores) + [0] * len(neg_scores)\n",
    "    y_score = pos_scores + neg_scores\n",
    "    \n",
    "    try:\n",
    "        auc = roc_auc_score(y_true, y_score)\n",
    "    except Exception:\n",
    "        metrics[\"AUC\"] = float(\"nan\")\n",
    "        return metrics\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_score) # pyright: ignore[reportUnknownVariableType]\n",
    "\n",
    "    fnr = 1 - tpr # pyright: ignore[reportUnknownVariableType]\n",
    "    abs_diffs = np.abs(fnr - fpr) # pyright: ignore[reportUnusedVariable, reportUnknownArgumentType]\n",
    "    eer_index = int(np.argmin(abs_diffs))\n",
    "    \n",
    "    eer = float((fnr[eer_index] + fpr[eer_index]) / 2.0)\n",
    "    threshold = float(thresholds[eer_index])\n",
    "\n",
    "    metrics.update({\n",
    "        \"AUC\": float(auc),\n",
    "        \"EER\": eer,\n",
    "        \"threshold\": threshold,\n",
    "        \"fpr\": fpr,\n",
    "        \"tpr\": tpr,\n",
    "        \"thresholds\":thresholds\n",
    "    })\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e140e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_scores(\n",
    "    embeddings: torch.Tensor,\n",
    "    pairs: List[Tuple[int, int]]\n",
    ") -> List[float]:\n",
    "    scores: List[float] = []\n",
    "    if len(pairs) == 0:\n",
    "        return scores\n",
    "    \n",
    "    for i, j in pairs:\n",
    "        if i < 0 or j < 0 or i >= embeddings.shape[0] or j >= embeddings.shape[0]:\n",
    "            continue\n",
    "        sim = F.cosine_similarity(\n",
    "            embeddings[i].unsqueeze(0),\n",
    "            embeddings[j].unsqueeze(0),\n",
    "        ).item()\n",
    "        scores.append(float(sim))\n",
    "    return scores    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9fcaebcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_verification_pairs(\n",
    "    embeddings: torch.Tensor,\n",
    "    test_map: Dict[str, Dict[str, List[str]]]\n",
    ") -> Tuple[List[Tuple[int, int]], List[Tuple[int, int]], List[Tuple[int, int]]]: \n",
    "    num_samples = embeddings.shape[0]\n",
    "    \n",
    "    ordered_paths: List[Tuple[str, str, str]] = []\n",
    "    # ordered_types = []\n",
    "    \n",
    "    for signer_id in sorted(test_map.keys(), key=int):\n",
    "        for path in test_map[signer_id].get(\"original\", []):\n",
    "            ordered_paths.append((signer_id, \"original\", path))\n",
    "    \n",
    "        for path in test_map[signer_id].get(\"forged\", []):\n",
    "            ordered_paths.append((signer_id, \"forged\", path))\n",
    "    \n",
    "    assert len(ordered_paths) == num_samples, \\\n",
    "        \"Embedding count does not match number of test images.\"\n",
    "        \n",
    "    # signer_to_indices = {}\n",
    "    orig_indices: Dict[str, List[int]] = {}\n",
    "    forg_indices: Dict[str, List[int]] = {}\n",
    "    \n",
    "    for index, (sid, t, _) in enumerate(ordered_paths):\n",
    "        # signer_to_indices.setdefault(sid, []).append(index)\n",
    "        if t == \"original\":\n",
    "            orig_indices.setdefault(sid, []).append(index)\n",
    "        else: forg_indices.setdefault(sid, []).append(index)\n",
    "    \n",
    "    pos_pairs: List[Tuple[int, int]] = []\n",
    "    for sid, indices in orig_indices.items():\n",
    "        if len(indices) >= 2:\n",
    "            for i, j in combinations(indices, 2):\n",
    "                pos_pairs.append((i, j))\n",
    "    \n",
    "    intra_neg_pairs: List[Tuple[int, int]] = []\n",
    "    for sid in orig_indices.keys():\n",
    "        o_idxs = orig_indices[sid]\n",
    "        f_idxs = forg_indices.get(sid, [])\n",
    "        for i in o_idxs:\n",
    "            for j in f_idxs:\n",
    "                intra_neg_pairs.append((i, j))\n",
    "    \n",
    "    inter_neg_pairs: List[Tuple[int, int]] = []\n",
    "    sids = list(orig_indices.keys())  # original-only ensures consistency\n",
    "\n",
    "    for sid_a, sid_b in combinations(sids, 2):\n",
    "        for i in orig_indices[sid_a]:\n",
    "            for j in orig_indices[sid_b]:\n",
    "                inter_neg_pairs.append((i, j))\n",
    "                \n",
    "    return pos_pairs, intra_neg_pairs, inter_neg_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a61b524b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_all(\n",
    "    model: nn.Module, \n",
    "    dataloader: DataLoader[Tuple[torch.Tensor, str]], \n",
    "    device: torch.device\n",
    ") -> torch.Tensor:\n",
    "    \n",
    "    model.eval()\n",
    "    embeddings_list: List[torch.Tensor] = []\n",
    "    # labels_list: List[str] = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, _signer_ids in dataloader:\n",
    "            images = images.to(device)\n",
    "            embedding = model(images)\n",
    "            embeddings_list.append(embedding.cpu())\n",
    "            # labels_list.append(signer_ids.cpu())\n",
    "            \n",
    "    all_embeddings = torch.cat(embeddings_list)\n",
    "    # labels = torch.cat(labels_list)\n",
    "    \n",
    "    return all_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "83d791f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_operating_point(fpr: Any, tpr: Any, thresholds: Any, chosen_threshold: Any):\n",
    "    # Find the index closest to your chosen threshold\n",
    "    idx = (np.abs(thresholds - chosen_threshold)).argmin()\n",
    "    return {\n",
    "        \"threshold\": thresholds[idx],\n",
    "        \"TPR\": tpr[idx],   # genuine acceptance rate\n",
    "        \"FPR\": fpr[idx],   # forgery acceptance rate\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "61a78242",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(pos_scores: List[float], neg_scores: List[float], threshold: float) -> float:\n",
    "    if len(pos_scores) == 0 and len(neg_scores) == 0:\n",
    "        return float(\"nan\")\n",
    "    \n",
    "    # Genuine pairs should be above threshold\n",
    "    pos_correct = sum([1 for s in pos_scores if s >= threshold])\n",
    "    # Forgery pairs should be below threshold\n",
    "    neg_correct = sum([1 for s in neg_scores if s < threshold])\n",
    "    \n",
    "    total = len(pos_scores) + len(neg_scores)\n",
    "    correct = pos_correct + neg_correct\n",
    "    \n",
    "    return correct / total if total > 0 else float(\"nan\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "accd9703",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(\n",
    "    model: nn.Module, \n",
    "    test_loader: DataLoader[Tuple[torch.Tensor, str]], \n",
    "    test_map:  Dict[str, Dict[str, List[str]]],\n",
    "    device: torch.device\n",
    ") -> Dict[str, Any]:\n",
    "    model.to(device)\n",
    "    \n",
    "    # Applying the model\n",
    "    embeddings = embed_all(model, test_loader, device)\n",
    "\n",
    "    # original, easy, and hard forgery  \n",
    "    pos_pairs, intra_pairs, inter_pairs = build_verification_pairs(embeddings, test_map)\n",
    "\n",
    "    # Intra and Inter\n",
    "    neg_pairs = intra_pairs + inter_pairs\n",
    "    \n",
    "    # Compute similarities\n",
    "    pos_scores = compute_scores(embeddings, pos_pairs)\n",
    "    neg_scores = compute_scores(embeddings, neg_pairs)\n",
    "\n",
    "    # Metrics\n",
    "    metrics = compute_metrics(pos_scores, neg_scores)\n",
    "    op_point = summarize_operating_point(\n",
    "        metrics[\"fpr\"], metrics[\"tpr\"], thresholds=metrics[\"thresholds\"], chosen_threshold=metrics[\"threshold\"]\n",
    "    )\n",
    "    accuracy = compute_accuracy(pos_scores, neg_scores, metrics[\"threshold\"])\n",
    "    metrics[\"accuracy\"] = accuracy\n",
    "\n",
    "    print(f\"At threshold {op_point['threshold']:.3f}:\")\n",
    "    print(f\"  TPR (genuine accepted) = {op_point['TPR']*100:.1f}%\")\n",
    "    print(f\"  FPR (forgeries accepted) = {op_point['FPR']*100:.1f}%\")\n",
    "\n",
    "    return {\n",
    "        # \"embeddings\": embeddings,\n",
    "        \"pos_scores\": sum(pos_scores)/len(pos_scores),\n",
    "        \"neg_scores\": sum(neg_scores)/len(neg_scores),\n",
    "        \"metrics\": metrics,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84818559",
   "metadata": {},
   "source": [
    "# Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "02bc2d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_signer_id(file_name: str) -> str:\n",
    "    match = re.search(r\"(?:original|forgeries|forgery|forged)_(\\d+)_\", file_name)\n",
    "    if match: return match.group(1) \n",
    "    return f\"UNKNOWN_SIGNER\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2685da9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_signature_images(\n",
    "    images_path: Path, \n",
    ") -> List[Tuple[str, str]]:\n",
    "    \n",
    "    signature_images: List[Tuple[str, str]] = []\n",
    "    if not images_path.is_dir():\n",
    "        print(f\"Warning: Directory not found! {images_path}\") \n",
    "        return []\n",
    "    for image_path in images_path.iterdir():\n",
    "        if image_path.is_file() and image_path.suffix.lower() in IMAGE_FORMATS:\n",
    "            signer_id = extract_signer_id(str(image_path))\n",
    "            if signer_id != \"UNKNOWN_SIGNER\":\n",
    "                signature_images.append((signer_id, str(image_path)))\n",
    "            else:\n",
    "                print(\n",
    "                    f\"Warning: Could not extract signer ID from file: {image_path.name}\"\n",
    "                )\n",
    "    return signature_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fe463a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_signature_map(\n",
    "    original_signatures: List[Tuple[str, str]],\n",
    "    forged_signatures: List[Tuple[str, str]],\n",
    ") -> Dict[str, Dict[str, List[str]]]:\n",
    "    \n",
    "    signature_dictionary: defaultdict[str, Dict[str, List[Any]]] = defaultdict(\n",
    "        lambda: {\n",
    "            \"original\": [], \n",
    "            \"forged\": []\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    for category, signatures in [(\"original\", original_signatures),\n",
    "                                 (\"forged\", forged_signatures)]:\n",
    "        for signer_id, image_path in signatures:\n",
    "            signature_dictionary[signer_id][category].append(image_path)\n",
    "            \n",
    "    return signature_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "92684e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_and_testing_split(\n",
    "    signature_dictionary: Dict[str, Dict[str, List[str]]],\n",
    "    test_ratio: float = 0.2,\n",
    "    val_ratio: float = 0.1,\n",
    "    random_state: int = 42,\n",
    ") -> Tuple[\n",
    "        Dict[str, Dict[str, List[str]]], \n",
    "        Dict[str, Dict[str, List[str]]],\n",
    "        Dict[str, Dict[str, List[str]]]\n",
    "    ]:\n",
    "    train_map: Dict[str, Dict[str, List[str]]] = {}\n",
    "    val_map: Dict[str, Dict[str, List[str]]] = {}\n",
    "    test_map: Dict[str, Dict[str, List[str]]] = {} \n",
    "    \n",
    "    signer_ids: List[str] = sorted(list(signature_dictionary.keys()), key=int)\n",
    "    \n",
    "    strat_labels: List[int] = []\n",
    "    for sid in signer_ids:\n",
    "        originals = len(signature_dictionary[sid].get(\"original\", []))\n",
    "        forgeries = len(signature_dictionary[sid].get(\"forged\", []))\n",
    "        strat_labels.append(0 if originals >= forgeries else 1)\n",
    "\n",
    "    train_val_ids, test_ids = train_test_split( # pyright: ignore[reportUnknownVariableType]\n",
    "        signer_ids,\n",
    "        test_size=test_ratio,\n",
    "        random_state=random_state,\n",
    "        stratify=strat_labels,\n",
    "    )\n",
    "\n",
    "    strat_labels_train_val = [\n",
    "        strat_labels[signer_ids.index(sid)] for sid in train_val_ids  # type: ignore\n",
    "    ]\n",
    "    val_size = val_ratio / (1 - test_ratio)\n",
    "    train_ids, val_ids = train_test_split( # pyright: ignore[reportUnknownVariableType]\n",
    "        train_val_ids, # pyright: ignore[reportUnknownArgumentType]\n",
    "        test_size=val_size,\n",
    "        random_state=random_state,\n",
    "        stratify=strat_labels_train_val,\n",
    "    )\n",
    "\n",
    "    train_map = {sid: signature_dictionary[sid] for sid in train_ids} # pyright: ignore[reportUnknownVariableType]\n",
    "    val_map = {sid: signature_dictionary[sid] for sid in val_ids} # pyright: ignore[reportUnknownVariableType]\n",
    "    test_map = {sid: signature_dictionary[sid] for sid in test_ids} # pyright: ignore[reportUnknownVariableType] \n",
    "\n",
    "    return train_map, val_map, test_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6672080c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_label_to_indices(dataset: SignatureDataset) -> dict[str, List[int]]:\n",
    "    label_to_indices: DefaultDict[str, List[int]] = defaultdict(list)\n",
    "    for index in range(len(dataset)):\n",
    "        _, label = dataset[index]\n",
    "        label_to_indices[label].append(index)\n",
    "    \n",
    "    return dict(label_to_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "082097a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_metrics(metrics: Dict[str, Any]) -> None:\n",
    "    print(\"=== Evaluation Metrics ===\")\n",
    "    print(f\"AUC       : {metrics['AUC']:.4f}\")\n",
    "    print(f\"EER       : {metrics['EER']:.4f}\")\n",
    "    print(f\"Threshold : {metrics['threshold']:.4f}\")\n",
    "    \n",
    "    # Summarize ROC curve\n",
    "    fpr = metrics['fpr']\n",
    "    tpr = metrics['tpr']\n",
    "    if len(fpr) > 0:\n",
    "        print(f\"ROC Points: {len(fpr)}\")\n",
    "        print(f\"FPR range : {fpr.min():.4f} → {fpr.max():.4f}\")\n",
    "        print(f\"TPR range : {tpr.min():.4f} → {tpr.max():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea12504",
   "metadata": {},
   "source": [
    "# Driver Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6407b466",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x19456bd63d0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_everything(42)\n",
    "g = torch.Generator()\n",
    "g.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "95d359c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "        transforms.Resize((384, 384)),\n",
    "        transforms.RandomAffine(\n",
    "            degrees=(-5, 5), \n",
    "            translate=(0.1, 0.1), \n",
    "            scale=(0.95, 1.05), \n",
    "            shear=(-5, 5)\n",
    "        ),\n",
    "\n",
    "        transforms.RandomResizedCrop(\n",
    "            (384, 384), \n",
    "            scale=(0.9, 1.05), \n",
    "            ratio=(0.95, 1.05), \n",
    "            antialias=True\n",
    "        ),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean=[0.5], std=[0.5]\n",
    "    )])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "        transforms.Resize((384, 384)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean=[0.5], std=[0.5]\n",
    "    )])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "435c19cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path: Path = Path(DATASET_PATH[\"CEDAR\"])\n",
    "original_signatures = retrieve_signature_images(dataset_path / \"original\")\n",
    "forged_signatures = retrieve_signature_images(dataset_path / \"forged\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fc35ba6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "signature_map = prepare_signature_map(original_signatures, forged_signatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6964cde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_map, val_map, test_map = training_and_testing_split(\n",
    "    signature_map, test_ratio=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "07f610d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SignatureDataset(train_map, train_transform)\n",
    "val_dataset = SignatureDataset(val_map, test_transform)\n",
    "\n",
    "test_dataset = TestSignatureDataset(test_map, test_transform)\n",
    "train_dataset_for_evaluation = TestSignatureDataset(train_map, test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dad4252e",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_indices = build_label_to_indices(train_dataset)\n",
    "train_sampler = PKSampler(label_to_indices, 8, 2, 2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5d133e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_sampler=train_sampler, \n",
    "    pin_memory=True, \n",
    "    worker_init_fn=seed_worker, \n",
    "    generator=g\n",
    ")\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset, \n",
    "    int(LEARNING_CONFIG[\"BATCH_SIZE\"]), \n",
    "    shuffle=False, \n",
    "    pin_memory=True, \n",
    "    worker_init_fn=seed_worker\n",
    ")\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    int(LEARNING_CONFIG[\"BATCH_SIZE\"]),\n",
    "    shuffle=False\n",
    ")\n",
    "train_dataloader_for_evaluation = DataLoader(\n",
    "    train_dataset_for_evaluation,\n",
    "    int(LEARNING_CONFIG[\"BATCH_SIZE\"]),\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ffd2a9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FeatureExtractionModel(\"efficientnet_v2_m\", 256, \"IMAGENET1K_V1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "91c2dce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_function = TripletLoss(0.5,\"batch_semi_hard\", use_diversity=False)\n",
    "loss_function = SCTLossWrapper(method=\"sct\", lam=1.0, margin=0.5, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2030c3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_trainer = Trainer(\n",
    "    model,\n",
    "    loss_function,\n",
    "    LEARNING_CONFIG,\n",
    "    OPTIMISER_PARAMS,\n",
    "    SCHEDULER_PARAMS,\n",
    "    True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7dccd1a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No easy triplets in the batch\n",
      "No easy triplets in the batch\n",
      "No easy triplets in the batch\n",
      "Epoch [1/50]| Train loss: 0.5100| AUC: 0.7898\n",
      "Epoch [2/50]| Train loss: 0.5064| AUC: 0.8192\n",
      "Epoch [3/50]| Train loss: 0.4437| AUC: 0.8976\n",
      "Epoch [4/50]| Train loss: 0.3711| AUC: 0.8450\n",
      "Epoch [5/50]| Train loss: 0.3813| AUC: 0.9017\n",
      "Epoch [6/50]| Train loss: 0.3646| AUC: 0.9009\n",
      "Epoch [7/50]| Train loss: 0.3303| AUC: 0.8938\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "Epoch [8/50]| Train loss: 0.2700| AUC: 0.8254\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "Epoch [9/50]| Train loss: 0.2155| AUC: 0.8724\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "Epoch [10/50]| Train loss: 0.1923| AUC: 0.9000\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "Epoch [11/50]| Train loss: 0.1662| AUC: 0.9135\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "Epoch [12/50]| Train loss: 0.1337| AUC: 0.9058\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "Epoch [13/50]| Train loss: 0.1125| AUC: 0.9293\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "Epoch [14/50]| Train loss: 0.0917| AUC: 0.9108\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "Epoch [15/50]| Train loss: 0.0804| AUC: 0.9308\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "Epoch [16/50]| Train loss: 0.0760| AUC: 0.9036\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "Epoch [17/50]| Train loss: 0.0652| AUC: 0.9112\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "Epoch [18/50]| Train loss: 0.0599| AUC: 0.9121\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "Epoch [19/50]| Train loss: 0.0580| AUC: 0.9195\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "Epoch [20/50]| Train loss: 0.0572| AUC: 0.9085\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "Epoch [21/50]| Train loss: 0.0502| AUC: 0.9011\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "Epoch [22/50]| Train loss: 0.0519| AUC: 0.9229\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "Epoch [23/50]| Train loss: 0.0463| AUC: 0.9266\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "Epoch [24/50]| Train loss: 0.0421| AUC: 0.9091\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "No hard triplets in the batch\n",
      "Epoch [25/50]| Train loss: 0.0411| AUC: 0.8949\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "model_trainer.fit(train_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "082c94d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File is ok!\n"
     ]
    }
   ],
   "source": [
    "model_trainer.load_checkpoint(\"checkpoint/exp_01_mod_sct/15_auc_0.0692.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ed4b9bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At threshold 0.631:\n",
      "  TPR (genuine accepted) = 90.6%\n",
      "  FPR (forgeries accepted) = 9.4%\n",
      "Accuracy: 90.6241%\n",
      "\n",
      "Positive and Negative Scores\n",
      "Positive Score: 0.8240\n",
      "Negative Score: 0.2337\n",
      "\n",
      "=== Evaluation Metrics ===\n",
      "AUC       : 0.9667\n",
      "EER       : 0.0938\n",
      "Threshold : 0.6311\n",
      "ROC Points: 2673\n",
      "FPR range : 0.0000 → 1.0000\n",
      "TPR range : 0.0000 → 1.0000\n"
     ]
    }
   ],
   "source": [
    "result = evaluate(model, test_dataloader, test_map, torch.device(\"cuda\"))\n",
    "print(f\"Accuracy: {(result[\"metrics\"][\"accuracy\"])*100:.4f}%\\n\")\n",
    "print(\"Positive and Negative Scores\")\n",
    "print(f\"Positive Score: {result[\"pos_scores\"]:.4f}\\n\"\n",
    "      f\"Negative Score: {result[\"neg_scores\"]:.4f}\\n\")\n",
    "pretty_metrics(result[\"metrics\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9bc7737f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At threshold 0.738:\n",
      "  TPR (genuine accepted) = 98.9%\n",
      "  FPR (forgeries accepted) = 1.1%\n",
      "Accuracy: 98.9266%\n",
      "\n",
      "Positive and Negative Scores\n",
      "Positive Score: 0.9692\n",
      "Negative Score: 0.0754\n",
      "\n",
      "=== Evaluation Metrics ===\n",
      "AUC       : 0.9995\n",
      "EER       : 0.0108\n",
      "Threshold : 0.7382\n",
      "ROC Points: 4506\n",
      "FPR range : 0.0000 → 1.0000\n",
      "TPR range : 0.0000 → 1.0000\n"
     ]
    }
   ],
   "source": [
    "result = evaluate(model, train_dataloader_for_evaluation, train_map, torch.device(\"cuda\"))\n",
    "print(f\"Accuracy: {(result[\"metrics\"][\"accuracy\"])*100:.4f}%\\n\")\n",
    "print(\"Positive and Negative Scores\")\n",
    "print(f\"Positive Score: {result[\"pos_scores\"]:.4f}\\n\"\n",
    "      f\"Negative Score: {result[\"neg_scores\"]:.4f}\\n\")\n",
    "pretty_metrics(result[\"metrics\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e646be27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_trainer._save_checkpoint(24, 0.1051, 0.0692, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127eb5ae",
   "metadata": {},
   "source": [
    "# Because I just wanted to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3577d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(\n",
    "    reference_feature_embeddings: torch.Tensor, input_feature_embeddings: torch.Tensor\n",
    ") -> Tuple[float, float, float, float, float]:\n",
    "    similarity = F.cosine_similarity(\n",
    "        reference_feature_embeddings, input_feature_embeddings\n",
    "    ).item()\n",
    "\n",
    "    distance = F.pairwise_distance(\n",
    "        reference_feature_embeddings, input_feature_embeddings\n",
    "    ).item()\n",
    "\n",
    "    normalised_distance = max(0, min(1, distance / 1.3))\n",
    "    distance_score = 1 - normalised_distance\n",
    "\n",
    "    # Greater emphasis is placed on the distance calculated.\n",
    "    confidence_score = 0.8 * similarity + 0.2 * distance_score\n",
    "\n",
    "    return similarity, confidence_score, normalised_distance, distance_score, distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4094d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_threshold(\n",
    "    similarity: float, \n",
    "    distance: float,\n",
    "    confidence_score: float,\n",
    "    result: Dict[str, bool | float | str]\n",
    ") -> None:\n",
    "    pass_thresholds = (\n",
    "        similarity >= 0.5 and \n",
    "        distance <= 1.07\n",
    "    )\n",
    "    \n",
    "    if pass_thresholds:\n",
    "        if confidence_score >= 0.9:\n",
    "            result['prediction_level'] = 'Very High Confidence'\n",
    "            result['is_genuine'] = True\n",
    "        elif confidence_score >= 0.8:\n",
    "            result['prediction_level'] = 'High Confidence'\n",
    "            result['is_genuine'] = True\n",
    "        elif confidence_score >= 0.7:\n",
    "            result['prediction_level'] = 'Medium Confidence'\n",
    "            result['is_genuine'] = True\n",
    "        elif confidence_score >= 0.6:\n",
    "            result['prediction_level'] = 'Low Confidence'\n",
    "        else:\n",
    "            result['prediction_level'] = \"Very Low Confidence\"\n",
    "    else:\n",
    "        result['prediction_level'] = 'Failed Threshold Check'\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478474a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_model(\n",
    "    reference_tensor: torch.Tensor,\n",
    "    forged_same_signer_tensor: torch.Tensor,\n",
    ") -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    \n",
    "    reference_feature_embeddings = torch.Tensor(model(reference_tensor))\n",
    "    forged_same_signer_feature_embeddings = torch.Tensor(model(\n",
    "        forged_same_signer_tensor\n",
    "    ))\n",
    "    return (\n",
    "        reference_feature_embeddings,\n",
    "        forged_same_signer_feature_embeddings,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4414476f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(55):  # signer IDs\n",
    "    for j in range(23):  # pick one original signature\n",
    "        reference_signature_image_path = Path(\n",
    "            f\"data/CEDAR/original/original_{i+1}_{j+1}.png\"\n",
    "        )\n",
    "        reference_image = Image.open(str(reference_signature_image_path)).convert(\"L\")\n",
    "        reference_tensor = test_transform(reference_image).unsqueeze(0).to(\"cuda\") # pyright: ignore[reportUnknownVariableType, reportAttributeAccessIssue, reportUnknownMemberType]\n",
    "\n",
    "        # Now compare this original against *all forgeries* of this signer\n",
    "        for k in range(23):  \n",
    "            forged_input_same_signer = Path(\n",
    "                f\"data/CEDAR/forged/forgeries_{i+1}_{k+1}.png\"\n",
    "            )\n",
    "            forged_same_signer = Image.open(str(forged_input_same_signer)).convert(\"L\")\n",
    "            forged_tensor = test_transform(forged_same_signer).unsqueeze(0).to(\"cuda\") # pyright: ignore[reportUnknownVariableType, reportAttributeAccessIssue, reportUnknownMemberType]\n",
    "\n",
    "            ref_emb, forged_emb = apply_model(reference_tensor, forged_tensor) # pyright: ignore[reportUnknownArgumentType]\n",
    "            similarity, confidence, norm_dist, dist_score, distance = calculate_metrics(ref_emb, forged_emb)\n",
    "\n",
    "            result: Dict[str, Any] = {\n",
    "                \"is_genuine\": False,\n",
    "                \"confidence_score\": confidence,\n",
    "                \"similarity_score\": similarity,\n",
    "                \"euclidean_distance\": norm_dist,\n",
    "                \"distance_score\": dist_score,\n",
    "                \"prediction_level\": \"unknown\",\n",
    "                \"passed_thresholds\": False,\n",
    "            }\n",
    "            apply_threshold(similarity, dist_score, confidence, result)\n",
    "            print(f\"Signer {i+1}, Original {j+1} vs Forgery {k+1} → {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e087817",
   "metadata": {},
   "source": [
    "# Dump"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09da98b0",
   "metadata": {},
   "source": [
    "## Scheduling\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b6097e",
   "metadata": {},
   "source": [
    "### Hardcoding Scheduling (Reference)\n",
    "\n",
    "```python\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, SequentialLR, LinearLR\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
    "\n",
    "warmup = LinearLR(optimizer, start_factor=0.1, total_iters=5)\n",
    "cosine = CosineAnnealingLR(optimizer, T_max=50)\n",
    "\n",
    "scheduler = SequentialLR(optimizer, schedulers=[warmup, cosine], milestones=[5])\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68b9c96",
   "metadata": {},
   "source": [
    "### More Flexible\n",
    "\n",
    "```python\n",
    "if \"WARMUP_SCHEDULER\" in scheduler_config:\n",
    "    warmup_name = str(scheduler_config[\"WARMUP_SCHEDULER\"])\n",
    "    warmup_class = getattr(lr_scheduler, warmup_name)\n",
    "    warmup_scheduler = warmup_class(\n",
    "        self.optimiser, \n",
    "        start_factor=scheduler_config[\"WARMUP_START_FACTOR\"],\n",
    "        total_iters=scheduler_config[\"WARMUP_EPOCHS\"]\n",
    "    )\n",
    "    schedulers.append(warmup_scheduler)\n",
    "\n",
    "if \"MAIN_SCHEDULER\" in scheduler_config:\n",
    "    main_name = str(scheduler_config[\"MAIN_SCHEDULER\"])\n",
    "    main_class = getattr(lr_scheduler, main_name)\n",
    "    main_scheduler = main_class(\n",
    "        self.optimiser,\n",
    "        T_max=scheduler_config[\"T_MAX\"],\n",
    "        eta_min=scheduler_config[\"eta_min\"]\n",
    "    )\n",
    "    schedulers.append(main_scheduler)\n",
    "\n",
    "if scheduler_config[\"SCHEDULER\"] == \"SequentialLR\":\n",
    "    scheduler_class = getattr(lr_scheduler, \"SequentialLR\")\n",
    "    scheduler = scheduler_class(\n",
    "        self.optimiser,\n",
    "        schedulers=schedulers,\n",
    "        milestones=scheduler_config[\"MILESTONES\"]\n",
    "    )\n",
    "    return scheduler\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7968dc2d",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93cdabb2",
   "metadata": {},
   "source": [
    "### Model Related\n",
    "```python \n",
    "\"EMBEDDING_DIM\": 256,\n",
    "        \n",
    "# Optional\n",
    "\"GRAD_CLIP\": 1.0,\n",
    "\"K_FOLD\": 5, \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a3097e",
   "metadata": {},
   "source": [
    "### Scheduling\n",
    "```python\n",
    "\"WARMUP_SCHEDULER\": \"LinearLR\",\n",
    "\"WARMUP_EPOCHS\": 2,\n",
    "\"WARMUP_START_FACTOR\": 0.1,\n",
    "\n",
    "\"MAIN_SCHEDULER\": \"CosineAnnealingLR\",\n",
    "\"T_MAX\": int(LEARNING_CONFIG[\"EPOCH\"]) - 2,\n",
    "\"eta_min\": 1e-6,\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def8a321",
   "metadata": {},
   "source": [
    "### EvalResult\n",
    "```python\n",
    "This needs changing\n",
    "@dataclass\n",
    "class EvalResults:\n",
    "    distances: npt.NDArray[np.float32]\n",
    "    labels: npt.NDArray[np.int64]\n",
    "    embeddings: Dict[str, npt.NDArray[np.float32]]\n",
    "    metrics: Dict[str, npt.NDArray[np.float32]]\n",
    "    curves: Dict[str, npt.NDArray[np.float32]] \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e55ab4",
   "metadata": {},
   "source": [
    "## Sampler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d91802",
   "metadata": {},
   "source": [
    "### PKSampler\n",
    "Still does not different forgeries in originals\n",
    "```python\n",
    "class PKSampler(Sampler[List[int]]):\n",
    "    def __init__(\n",
    "        self,\n",
    "        signer_to_indices: Dict[str, Dict[str, List[int]]], \n",
    "        P: int,          # signers per batch\n",
    "        K: int,          # originals per signer\n",
    "        F: int,          # forgeries per signer\n",
    "        M: int,          # inter-signer global negatives PER signer in batch\n",
    "        seed: int = 42\n",
    "    ):\n",
    "        \"\"\"\n",
    "        signer_to_indices:\n",
    "            {\n",
    "                signer_id: {\n",
    "                    \"original\": [idx,...],\n",
    "                    \"forged\":   [idx,...]\n",
    "                }\n",
    "            }\n",
    "        \"\"\"\n",
    "        self.P = P\n",
    "        self.K = K\n",
    "        self.F = F\n",
    "        self.M = M\n",
    "        \n",
    "        self.signer_to_indices = signer_to_indices\n",
    "        self.signers = list(signer_to_indices.keys())\n",
    "        self.seed = seed\n",
    "\n",
    "        # Precompute global negatives\n",
    "        self._all_indices = []\n",
    "        self._indices_by_signer = {}\n",
    "        for sid, groups in signer_to_indices.items():\n",
    "            all_for_sid = groups[\"original\"] + groups[\"forged\"]\n",
    "            self._indices_by_signer[sid] = set(all_for_sid)\n",
    "            self._all_indices.extend(all_for_sid)\n",
    "\n",
    "    def __len__(self):\n",
    "        return max(1, len(self.signers) // self.P * 10)\n",
    "\n",
    "    def __iter__(self):\n",
    "        rng = random.Random(self.seed)\n",
    "\n",
    "        while True:\n",
    "            selected_signers = rng.sample(self.signers, self.P)\n",
    "            batch = []\n",
    "\n",
    "            for sid in selected_signers:\n",
    "                originals = self.signer_to_indices[sid][\"original\"]\n",
    "                forgeries = self.signer_to_indices[sid][\"forged\"]\n",
    "\n",
    "                # Sample originals\n",
    "                pos = rng.sample(originals, self.K) if len(originals) >= self.K else rng.choices(originals, k=self.K)\n",
    "\n",
    "                # Sample forgeries\n",
    "                neg_hard = rng.sample(forgeries, self.F) if len(forgeries) >= self.F else rng.choices(forgeries, k=self.F)\n",
    "\n",
    "                # Sample inter-signer negatives\n",
    "                # All indices EXCEPT this signer\n",
    "                global_pool = [x for x in self._all_indices if x not in self._indices_by_signer[sid]]\n",
    "                neg_global = rng.sample(global_pool, self.M)\n",
    "\n",
    "                batch.extend(pos + neg_hard + neg_global)\n",
    "\n",
    "            yield batch\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32151d7",
   "metadata": {},
   "source": [
    "### ForgeryAwarePKSampler\n",
    "\n",
    "Still the same issue\n",
    "\n",
    "```python\n",
    "class ForgeryAwarePKSampler(Sampler[List[int]]):\n",
    "    def __init__(\n",
    "        self,\n",
    "        signer_to_indices: Dict[str, Dict[str, List[int]]],\n",
    "        P: int,\n",
    "        K: int,\n",
    "        seed: Optional[int] = 42\n",
    "    )\n",
    "        \"\"\"\n",
    "        signer_to_indices: {\n",
    "            signer_id: {\n",
    "                \"original\": [list of dataset indices],\n",
    "                \"forgery\": [list of dataset indices]\n",
    "            }\n",
    "        }\n",
    "        P: number of signers per batch\n",
    "        K: number of originals per signer\n",
    "        \"\"\"\n",
    "        self.P = P\n",
    "        self.K = K\n",
    "        self.signer_to_indices = signer_to_indices\n",
    "        self.signers = list(signer_to_indices.keys())\n",
    "        self.seed = seed\n",
    "\n",
    "    def __iter__(self):\n",
    "        rng = random.Random(self.seed)\n",
    "        while True:\n",
    "            selected_signers = rng.sample(self.signers, self.P)\n",
    "            batch = []\n",
    "\n",
    "            for signer in selected_signers:\n",
    "                originals = self.signer_to_indices[signer][\"original\"]\n",
    "                forgeries = self.signer_to_indices[signer][\"forged\"]\n",
    "\n",
    "                # Sample K originals (positives)\n",
    "                pos_samples = rng.sample(originals, self.K) if len(originals) >= self.K else rng.choices(originals, k=self.K)\n",
    "                # Sample K forgeries (negatives)\n",
    "                neg_samples = rng.sample(forgeries, self.K) if len(forgeries) >= self.K else rng.choices(forgeries, k=self.K)\n",
    "\n",
    "                batch.extend(pos_samples + neg_samples)\n",
    "\n",
    "            yield batch  # List[int] of indices\n",
    "\n",
    "    def __len__(self):\n",
    "        return max(1, len(self.signers) // self.P * 10)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf94633",
   "metadata": {},
   "source": [
    "### PKSampler\n",
    "This sampler does not differentiate forgeries and originals of the same signer\n",
    "\n",
    "```python\n",
    "class PKSampler(Sampler[List[int]]):\n",
    "    def __init__(\n",
    "        self, \n",
    "        labels: List[int], \n",
    "        P: int, \n",
    "        K: int,\n",
    "    ) -> None:\n",
    "        \n",
    "        self.labels = labels\n",
    "        # Classes per batch\n",
    "        self.P = P\n",
    "        # Samples per class\n",
    "        self.K = K\n",
    "        self.label_to_indices: Dict[int, List[int]] = {}\n",
    "        \n",
    "        for idx, label in enumerate(labels):\n",
    "            self.label_to_indices.setdefault(label, []).append(idx)\n",
    "        \n",
    "        self.labels_set = list(self.label_to_indices.keys())\n",
    "        \n",
    "\n",
    "    def __iter__(self) -> Iterator[List[int]]:\n",
    "        for _ in range(len(self)):\n",
    "            # Randomly select P classes from the available classes. \n",
    "            selected_labels = random.sample(self.labels_set, self.P)\n",
    "            batch: List[int] = []\n",
    "            for label in selected_labels:\n",
    "                indices = self.label_to_indices[label]\n",
    "                # Checks if the class has at least K samples\n",
    "                if len(indices) >= self.K:\n",
    "                    # Samples K indices without replacement\n",
    "                    batch.extend(random.sample(indices, self.K))\n",
    "                else:\n",
    "                    # Samples K indices with replacement\n",
    "                    batch.extend(random.choices(indices, k=self.K)) \n",
    "            yield batch\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        n = len(self.labels)\n",
    "        if n == 0:\n",
    "            return 0\n",
    "        return max(1, n // (self.P * self.K))\n",
    "    \n",
    "        # return len(self.labels) // (self.P * self.K)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075a9eb0",
   "metadata": {},
   "source": [
    "## Test Dataset\n",
    "\n",
    "These two datasets are not well made for evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ee3aae",
   "metadata": {},
   "source": [
    "```python\n",
    "class TestSignatureDataset(Dataset[Tuple[torch.Tensor, torch.Tensor, torch.Tensor, int]]):\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_map: Dict[str, Dict[str, List[str]]],\n",
    "        transform: Optional[transforms.Compose] = None,\n",
    "        mode: str = \"impostor\",\n",
    "    ):\n",
    "        self.data_map = data_map\n",
    "        self.transform = transform\n",
    "        self.mode = mode\n",
    "        \n",
    "        self.signer_ids = [\n",
    "            sid for sid, imgs in data_map.items()\n",
    "            if len(imgs.get(\"original\", [])) + len(imgs.get(\"forged\", [])) >= 2\n",
    "        ]\n",
    "        \n",
    "        self.anchor_candidates = [\n",
    "            (path, sid)\n",
    "            for sid in self.signer_ids\n",
    "            for t in (\"original\", \"forged\")\n",
    "            for path in data_map[sid].get(t, [])\n",
    "        ]\n",
    "        \n",
    "        self.signer_to_imgs = {\n",
    "            sid: data_map[sid].get(\"original\", []) + data_map[sid].get(\"forged\", [])\n",
    "            for sid in self.signer_ids\n",
    "        }\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.anchor_candidates)\n",
    "    \n",
    "    def _load(self, path:str) -> torch.Tensor:\n",
    "        img = Image.open(path).convert(\"L\")\n",
    "        return self.transform(img) if self.transform else transforms.ToTensor()(img) # pyright: ignore[reportUnknownVariableType, reportReturnType]\n",
    "    \n",
    "    def __getitem__(\n",
    "        self, \n",
    "        index: int\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, int]:\n",
    "        \n",
    "        anchor_path, anchor_id = self.anchor_candidates[index]\n",
    "        anchor_id_int = int(anchor_id)\n",
    "        \n",
    "        for _ in range(10):\n",
    "            positive_choices = [p for p in self.signer_to_imgs[anchor_id] if p != anchor_path]\n",
    "            if positive_choices:\n",
    "                break\n",
    "            index = random.randint(0, len(self) - 1)\n",
    "        else:\n",
    "            raise RuntimeError(\"Dataset too malformed to sample positives.\")\n",
    "    \n",
    "        # positive_choices = [p for p in self.signer_to_imgs[anchor_id] if p != anchor_path]\n",
    "        # if not positive_choices:\n",
    "        #     return self.__getitem__(random.randint(0, len(self) - 1))\n",
    "        positive_path = random.choice(positive_choices)\n",
    "        \n",
    "        if self.mode == \"impostor\":\n",
    "            negative_signer = random.choice([sid for sid in self.signer_ids if sid != anchor_id])\n",
    "            negative_choices = self.signer_to_imgs[negative_signer]\n",
    "            negative_path = random.choice(negative_choices)\n",
    "        elif self.mode == \"forgery\":\n",
    "            # for _ in range(10):\n",
    "            #     negative_choices = self.data_map[anchor_id].get(\"forged\", [])\n",
    "            #     if negative_choices:\n",
    "            #         break\n",
    "            #     index = random.randint(0, len(self) - 1)\n",
    "            # else:\n",
    "            #     raise RuntimeError(\"Dataset too malformed to sample negatives.\")\n",
    "            # negative_path = random.choice(negative_choices)\n",
    "            negative_choices = self.data_map[anchor_id].get(\"forged\", [])\n",
    "            if not negative_choices:\n",
    "                return self.__getitem__(random.randint(0, len(self) - 1))\n",
    "            negative_path = random.choice(negative_choices)\n",
    "        else:\n",
    "            raise ValueError(\"mode must be 'impostor' or 'forgery'\")\n",
    "        \n",
    "        return (\n",
    "            self._load(anchor_path),\n",
    "            self._load(positive_path),\n",
    "            self._load(negative_path),\n",
    "            anchor_id_int\n",
    "        )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb6f3c5",
   "metadata": {},
   "source": [
    "```python\n",
    "class TestSignatureDataset(Dataset[Tuple[torch.Tensor, torch.Tensor, torch.Tensor, int]]):\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_map: Dict[str, Dict[str, List[str]]],\n",
    "        transform: Optional[transforms.Compose] = None,\n",
    "    ):\n",
    "        self.data_map = data_map\n",
    "        self.transform = transform\n",
    "\n",
    "        self.signer_ids = [\n",
    "            sid for sid, imgs in data_map.items()\n",
    "            if len(imgs.get(\"original\", [])) + len(imgs.get(\"forged\", [])) >= 2\n",
    "        ]\n",
    "        \n",
    "        # self.signer_ids:List[str] = sorted(\n",
    "        #     [sid for sid, imgs in data_map.items()\n",
    "        #     if len(imgs.get(\"original\", [])) + len(imgs.get(\"forged\", [])) >= 2],\n",
    "        #     key=int\n",
    "        # )\n",
    "        \n",
    "        # if len(self.signer_ids) < 2:\n",
    "        #     raise ValueError(\"Need >= 2 signers with >= 2 images each to form valid triplets.\")\n",
    "        \n",
    "        self.anchor_candidates: List[Tuple[str, str]]= [\n",
    "            (path, sid)\n",
    "            for sid in self.signer_ids\n",
    "            for t in (\"original\", \"forged\")\n",
    "            for path in data_map[sid].get(t, [])\n",
    "        ]\n",
    "        \n",
    "        self.signer_to_imgs = {\n",
    "            sid: data_map[sid].get(\"original\", []) + data_map[sid].get(\"forged\", [])\n",
    "            for sid in self.signer_ids\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.anchor_candidates)\n",
    "    \n",
    "    def _load(self, path:str) -> torch.Tensor:\n",
    "        img = Image.open(path).convert(\"L\")\n",
    "        return torch.Tensor(self.transform(img) if self.transform else transforms.ToTensor()(img))\n",
    "\n",
    "    def __getitem__(  # type: ignore\n",
    "        self, \n",
    "        index: int\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, int]:\n",
    "        \n",
    "        anchor_path, anchor_id = self.anchor_candidates[index]\n",
    "        anchor_id_int = int(anchor_id)\n",
    "        \n",
    "        # all_paths = self.data_map[anchor_id].get(\"original\", []) + self.data_map[anchor_id].get(\"forged\", [])\n",
    "        positive_choices = [p for p in self.signer_to_imgs[anchor_id] if p != anchor_path]\n",
    "        if not positive_choices:\n",
    "            return self.__getitem__(random.randint(0, len(self) - 1))\n",
    "        positive_path = random.choice(positive_choices)\n",
    "\n",
    "\n",
    "        negative_choices = list(self.data_map[anchor_id].get(\"forged\", []))\n",
    "        \n",
    "        for other_id in self.signer_ids:\n",
    "            if other_id == anchor_id:\n",
    "                continue\n",
    "            for category in (\"original\", \"forged\"):\n",
    "                negative_choices.extend(self.data_map[other_id].get(category, []))\n",
    "        \n",
    "        if not negative_choices:\n",
    "            return self.__getitem__(random.randint(0, len(self) - 1))\n",
    "        \n",
    "        negative_path = random.choice(negative_choices)\n",
    "        \n",
    "        return (\n",
    "            self._load(anchor_path),\n",
    "            self._load(positive_path),\n",
    "            self._load(negative_path),\n",
    "            anchor_id_int\n",
    "        )\n",
    "        def load(path: str) -> torch.Tensor:\n",
    "            img: Image.Image = Image.open(path).convert(\"L\")\n",
    "            return self.transform(img) if self.transform else transforms.ToTensor()(img) # pyright: ignore[reportUnknownVariableType, reportReturnType]\n",
    "        \n",
    "        anchor, positive, negative = map(load, [anchor_path, positive_path, negative_path])\n",
    "        return anchor, positive, negative, anchor_id_int\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7beb5988",
   "metadata": {},
   "source": [
    "## Trainer\n",
    "```python\n",
    "class Trainer:\n",
    "    def __init__(\n",
    "        self, \n",
    "        model: nn.Module,\n",
    "        loss_function: nn.Module,\n",
    "        learning_config: Dict[str, str | int | float],\n",
    "        optimiser_config: Dict[str, str | float],\n",
    "        scheduler_config: SchedulerConfig,\n",
    "        save_checkpoints: bool = True\n",
    "    ) -> None:\n",
    "        \n",
    "        self.model = model\n",
    "        \n",
    "        # Training loop\n",
    "        self.epoch = int(learning_config[\"EPOCH\"])\n",
    "        self.batch_size = int(learning_config[\"BATCH_SIZE\"])\n",
    "        self.lr = float(learning_config[\"LEARNING_RATE\"])\n",
    "        self.early_stop = int(learning_config[\"EARLY_STOPPING_PATIENT\"])\n",
    "        self.checkpoint_path = Path(str(learning_config[\"CHECKPOINT_DIR\"]))\n",
    "        self.save_checkpoints = bool(save_checkpoints)\n",
    "        self.device = torch.device(str(learning_config[\"DEVICE\"]))\n",
    "        self.device_type = self.device.type\n",
    "        self.global_step = 0\n",
    "        \n",
    "        self.best_val_loss = float(\"inf\")\n",
    "        self.patience_counter = 0\n",
    "        \n",
    "        # Optimiser\n",
    "        self.optimiser = self._build_optimiser(optimiser_config)\n",
    "        \n",
    "        # Scheduler\n",
    "        self.scheduler = self._build_scheduler(scheduler_config)\n",
    "\n",
    "        # Loss function\n",
    "        self.loss_function = loss_function\n",
    "        \n",
    "        # Mixed precision\n",
    "        self.scaler = GradScaler()\n",
    "        \n",
    "        # Moving to GPU\n",
    "        self.model.to(self.device)\n",
    "        # self.loss_function.to(self.device)\n",
    "        \n",
    "        # checkpointing\n",
    "        self.checkpoint_path.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Tensorboard\n",
    "        log_dir = learning_config[\"LOG_DIR\"]\n",
    "        self.writer = SummaryWriter(log_dir)\n",
    "        \n",
    "    def train_epoch(\n",
    "        self, dataloader: DataLoader[Tuple[torch.Tensor, str]]\n",
    "    ) -> float:\n",
    "        self.model.train()\n",
    "        running_loss: float = 0.0\n",
    "        num_batches: int = len(dataloader)\n",
    "        \n",
    "        for batch_index, (images, label) in enumerate(dataloader):\n",
    "            images = images.to(self.device)\n",
    "            # label = label.to(self.device)\n",
    "        \n",
    "            self.optimiser.zero_grad()\n",
    "            \n",
    "            with autocast(device_type=self.device_type):\n",
    "                outputs = self.model(images)\n",
    "                # SCTLoss returns (loss, triplet_vals, triplet_idxs, hn_ratio, Pos_log, Neg_log)\n",
    "                # loss, triplet_vals, _triplet_idxs, hn_ratio, pos, neg= self.loss_function(outputs, label)\n",
    "                \n",
    "                # Vanilla Triplet Loss returns (loss, stats)\n",
    "                loss, stats = self.loss_function(outputs, label)\n",
    "            \n",
    "            # Gradient clipping is optional\n",
    "            \n",
    "            self.scaler.scale(loss).backward()  # pyright: ignore[reportUnknownMemberType]\n",
    "            self.scaler.step(self.optimiser)\n",
    "            self.scaler.update()\n",
    "            \n",
    "            if isinstance(self.scheduler, lr_scheduler.OneCycleLR):\n",
    "                self.scheduler.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            self.global_step += 1\n",
    "            print(\n",
    "                f\"Training batch {batch_index}/{ num_batches }, \"\n",
    "                f\"Loss: {loss.item():.4f}\"\n",
    "            )\n",
    "            # self._log_triplet_metrics(loss, triplet_vals, triplet_idxs, hn_ratio, \"train\")\n",
    "            \n",
    "            if batch_index % 50 == 0:\n",
    "                # For both SCT and vanilla Triplet Loss\n",
    "                self.writer.add_scalar(f\"Train/BatchLoss\", loss.item(), self.global_step) # pyright: ignore[reportUnknownMemberType]\n",
    "                \n",
    "                # # SCT\n",
    "                # self.writer.add_scalar(f\"Train/HN_Ratio\", hn_ratio.item(), self.global_step) # pyright: ignore[reportUnknownMemberType]\n",
    "                # self.writer.add_scalar(f\"Train/PosMean\", pos.mean().item(), self.global_step) # pyright: ignore[reportUnknownMemberType]\n",
    "                # self.writer.add_scalar(f\"Train/NegMean\", neg.mean().item(), self.global_step) # pyright: ignore[reportUnknownMemberType]\n",
    "                \n",
    "                # self.writer.add_histogram(f\"Train/Pos\", triplet_vals[:,0], self.global_step) # pyright: ignore[reportUnknownMemberType]\n",
    "                # self.writer.add_histogram(f\"Train/Neg\", triplet_vals[:,1], self.global_step) # pyright: ignore[reportUnknownMemberType]\n",
    "                \n",
    "                # Vanilla Triplet Loss\n",
    "                self.writer.add_scalar(\"Train/HN_Ratio\", stats[\"hn_ratio\"], self.global_step) # pyright: ignore[reportUnknownMemberType]\n",
    "                self.writer.add_scalar(\"Train/PosMean\", stats[\"pos\"].mean().item(), self.global_step) # pyright: ignore[reportUnknownMemberType]\n",
    "                self.writer.add_scalar(\"Train/NegMean\", stats[\"neg\"].mean().item(), self.global_step) # pyright: ignore[reportUnknownMemberType]\n",
    "\n",
    "                self.writer.add_histogram(\"Train/Pos\", stats[\"triplet_vals\"][:,0], self.global_step) # pyright: ignore[reportUnknownMemberType]\n",
    "                self.writer.add_histogram(\"Train/Neg\", stats[\"triplet_vals\"][:,1], self.global_step) # pyright: ignore[reportUnknownMemberType]\n",
    "                \n",
    "                total_norm: float = 0.\n",
    "                for p in self.model.parameters():\n",
    "                    if p.grad is not None:\n",
    "                        total_norm += float(p.grad.data.norm(2).item()) # pyright: ignore[reportUnknownArgumentType, reportUnknownMemberType]\n",
    "                        \n",
    "                self.writer.add_scalar(\"Gradients/TotalNorm\", total_norm, self.global_step) # pyright: ignore[reportUnknownMemberType]\n",
    "            \n",
    "        # This is for OneCyclicLR\n",
    "        # self.scheduler.step() # pyright: ignore[reportOptionalMemberAccess] \n",
    "        \n",
    "        return running_loss / num_batches\n",
    "        \n",
    "    def evaluate(\n",
    "        self,\n",
    "        dataloader: DataLoader[Tuple[torch.Tensor, str]] \n",
    "    ) -> Tuple[Dict[str, float], torch.Tensor, List[str]]:\n",
    "        self.model.eval()\n",
    "        all_embeddings_list: List[torch.Tensor] = []\n",
    "        all_labels: List[str] = []\n",
    "        # num_batches: int = len(dataloader)\n",
    "        # running_loss = 0.0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels in dataloader:\n",
    "                images = images.to(self.device)\n",
    "                # labels = labels.to(self.device)\n",
    "                \n",
    "                with autocast(device_type=self.device_type):\n",
    "                    embeddings = self.model(images)\n",
    "                    all_embeddings_list.append(embeddings.cpu())\n",
    "                    all_labels.extend(labels) \n",
    "                    \n",
    "        all_embeddings = torch.cat(all_embeddings_list, dim=0)\n",
    "        n = len(all_labels)\n",
    "        \n",
    "        sim_matrix = F.cosine_similarity(\n",
    "            all_embeddings.unsqueeze(1), \n",
    "            all_embeddings.unsqueeze(0), \n",
    "            dim=2\n",
    "        )\n",
    "        \n",
    "        signer_ids = [label.split(\"_\")[0] for label in all_labels]\n",
    "        intra_mask = torch.zeros((n, n), dtype=torch.bool)\n",
    "        inter_mask = torch.zeros((n, n), dtype=torch.bool)\n",
    "        \n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                if i == j:\n",
    "                    continue\n",
    "                if signer_ids[i] == signer_ids[j]:\n",
    "                    intra_mask[i, j] = True\n",
    "                else:\n",
    "                    inter_mask[i, j] = True\n",
    "\n",
    "        # Convert masked elements to numpy safely\n",
    "        intra_sims: torch.Tensor = sim_matrix[intra_mask] \n",
    "        inter_sims: torch.Tensor = sim_matrix[inter_mask]  \n",
    "\n",
    "        intra_sims_np: np.ndarray = intra_sims.cpu().numpy() # type: ignore\n",
    "        inter_sims_np: np.ndarray = inter_sims.cpu().numpy() # type: ignore\n",
    "\n",
    "        # Metrics\n",
    "        y_true = [1] * len(intra_sims_np) + [0] * len(inter_sims_np) # type: ignore\n",
    "        y_scores = list(intra_sims_np) + list(inter_sims_np) # type: ignore\n",
    "        auc = roc_auc_score(y_true, y_scores)\n",
    "\n",
    "        metrics: Dict[str, float | int] = {\n",
    "            \"AUC\": auc, # type: ignore\n",
    "            \"mean_intra_similarity\": float(intra_sims.mean()),\n",
    "            \"mean_inter_similarity\": float(inter_sims.mean()),\n",
    "            \"num_intra_pairs\": len(intra_sims),\n",
    "            \"num_inter_pairs\": len(inter_sims)\n",
    "        }\n",
    "\n",
    "        return metrics, all_embeddings, all_labels\n",
    "            \n",
    "        # val_embedding = torch.cat(all_embeddings, dim = 0)\n",
    "        # return running_loss / num_batches, val_embedding, all_labels\n",
    "    \n",
    "    def fit(\n",
    "        self, \n",
    "        train_dataloader: DataLoader[Tuple[torch.Tensor, str]],\n",
    "        val_dataloader: DataLoader[Tuple[torch.Tensor, str]]\n",
    "    ) -> None: \n",
    "        for epoch in range(self.epoch):\n",
    "            train_loss = self.train_epoch(train_dataloader)\n",
    "            val_metrics, val_embedding, all_labels = self.evaluate(val_dataloader)\n",
    "            \n",
    "            # if epoch % 5 == 0:\n",
    "            self.writer.add_embedding( # pyright: ignore[reportUnknownMemberType]\n",
    "                mat = val_embedding,\n",
    "                metadata=all_labels,\n",
    "                global_step=self.global_step\n",
    "            )\n",
    "            \n",
    "            self.writer.add_scalar(\"Loss/train\", train_loss, epoch) # pyright: ignore[reportUnknownMemberType]\n",
    "            self.writer.add_scalar(\"AUC/val\", val_metrics[\"AUC\"], epoch) # pyright: ignore[reportUnknownMemberType]\n",
    "            self.writer.add_scalar(\"Loss/val\", 1.0 - val_metrics[\"AUC\"], epoch) # pyright: ignore[reportUnknownMemberType]\n",
    "            self.writer.add_scalar(\"Learning rate\", self.optimiser.param_groups[0][\"lr\"], epoch) # pyright: ignore[reportUnknownMemberType]\n",
    "            \n",
    "            if self.scheduler is not None and not isinstance(self.scheduler, lr_scheduler.OneCycleLR):\n",
    "                self.scheduler.step()\n",
    "\n",
    "            print(f\"Epoch [{epoch+1}/{self.epoch}]\" \n",
    "                  f\"| Train loss: {train_loss:.4f}\" \n",
    "                  f\"| AUC: {val_metrics['AUC']:.4f}\")\n",
    "        \n",
    "            val_loss_for_stop = 1.0 - val_metrics[\"AUC\"]\n",
    "            if val_loss_for_stop < self.best_val_loss:\n",
    "                self.best_val_loss = val_loss_for_stop\n",
    "                self.patience_counter = 0\n",
    "                if self.save_checkpoints:\n",
    "                    self._save_checkpoint(epoch, val_loss_for_stop, self.best_val_loss, self.patience_counter)\n",
    "            else:\n",
    "                self.patience_counter+=1\n",
    "                if self.patience_counter >= self.early_stop:\n",
    "                    print(\"Early stopping\")\n",
    "                    break\n",
    "        \n",
    "        self.writer.close()\n",
    "    \n",
    "    def load_checkpoint(\n",
    "        self, \n",
    "        path: str\n",
    "    ) -> None:\n",
    "        \n",
    "        self._has_path(path)\n",
    "        try:\n",
    "            checkpoint_model: ModelState = torch.load(path, map_location=self.device)\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Error loading checkpoint from {path}: {e}\")\n",
    "        \n",
    "        self.model.load_state_dict(checkpoint_model[\"model_state_dict\"])\n",
    "        self.optimiser.load_state_dict(checkpoint_model[\"optimiser_state_dict\"])\n",
    "        \n",
    "        if self.scheduler and checkpoint_model[\"scheduler_state_dict\"] is not None:\n",
    "            self.scheduler.load_state_dict(checkpoint_model[\"scheduler_state_dict\"])\n",
    "        \n",
    "        self.epoch = checkpoint_model[\"epoch\"]\n",
    "        self.best_val_loss = checkpoint_model[\"best_loss\"]\n",
    "        self.patience_counter = checkpoint_model[\"patience_counter\"]\n",
    "    \n",
    "    def _save_checkpoint(\n",
    "        self, \n",
    "        epoch: int, \n",
    "        loss: float, \n",
    "        best_loss: float, \n",
    "        patience_counter: int,\n",
    "    ) -> None:\n",
    "        model_state: ModelState = {\n",
    "            \"epoch\": epoch,\n",
    "            \"model_state_dict\": self.model.state_dict(),\n",
    "            \"optimiser_state_dict\": self.optimiser.state_dict(),\n",
    "            \"scheduler_state_dict\": self.scheduler.state_dict() if self.scheduler else None,\n",
    "            \"loss\": loss,\n",
    "            \"best_loss\": best_loss,\n",
    "            \"patience_counter\": patience_counter\n",
    "        }\n",
    "        \n",
    "        torch.save(\n",
    "            model_state, self.checkpoint_path / f\"{epoch+1}_loss_{loss:.4f}.pt\"\n",
    "        )\n",
    "    \n",
    "    def _has_path(self, path: str) -> None:\n",
    "        if not Path(path).exists():\n",
    "            raise FileNotFoundError(f\"File not found at {path}\")\n",
    "        print(f\"File is ok!\")\n",
    "                \n",
    "    def _build_optimiser(self, optimiser_config: Dict[str, str | float]) -> optim.Optimizer:\n",
    "        optimiser_name =  str(optimiser_config[\"optimiser\"])\n",
    "        optimiser_class = getattr(optim, optimiser_name)\n",
    "        \n",
    "        optimiser_params = {**optimiser_config}\n",
    "        optimiser_params.pop(\"optimiser\")\n",
    "        optimiser_params[\"lr\"] = self.lr\n",
    "        \n",
    "        return optimiser_class(self.model.parameters(), **optimiser_params)\n",
    "        \n",
    "    def _build_scheduler(\n",
    "        self, \n",
    "        scheduler_config: SchedulerConfig,\n",
    "        ) -> Optional[lr_scheduler.LRScheduler]:\n",
    "        schedulers: List[lr_scheduler.LRScheduler] = []\n",
    "         \n",
    "        for sched_cfg in scheduler_config.get(\"SCHEDULERS\", []):\n",
    "            name = sched_cfg[\"name\"]\n",
    "            params = sched_cfg.get(\"params\", {})\n",
    "            sched_class = getattr(lr_scheduler, name)\n",
    "            schedulers.append(sched_class(self.optimiser, **params))\n",
    "\n",
    "        if scheduler_config.get(\"SCHEDULER\") == \"SequentialLR\":\n",
    "            return lr_scheduler.SequentialLR(\n",
    "                self.optimiser,\n",
    "                schedulers=schedulers,\n",
    "                milestones=scheduler_config.get(\"MILESTONES\", [])\n",
    "            )\n",
    "        \n",
    "        return schedulers[0] if schedulers else None\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67339d4",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afb950c",
   "metadata": {},
   "source": [
    "### Plot Confusion Matrix\n",
    "\n",
    "```python\n",
    "def plot_confusion_matrix(\n",
    "    all_labels_np: npt.NDArray[np.int64],\n",
    "    all_predictions_np: npt.NDArray[np.float32],\n",
    "    best_threshold: float,\n",
    ") -> None:\n",
    "\n",
    "    predictions = [1 if d <= best_threshold else 0 for d in all_predictions_np]\n",
    "    cm = confusion_matrix(all_labels_np, predictions) # type: ignore\n",
    "\n",
    "    plt.figure(figsize=(8, 6)) # type: ignore\n",
    "    sns.heatmap(cm, annot=True, fmt=\"g\", cmap=\"Blues\") # type: ignore\n",
    "    plt.title(\"Confusion Matrix\") # type: ignore\n",
    "    plt.ylabel(\"True Label\") # type: ignore\n",
    "    plt.xlabel(\"Predicted Label\") # type: ignore\n",
    "    plt.savefig(\"confusion_matrix.png\") # type: ignore\n",
    "    plt.show() # type: ignore\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc39a5c0",
   "metadata": {},
   "source": [
    "### Plot AUC ROC\n",
    "```python\n",
    "def plot_auc_roc(fpr: npt.NDArray[np.float32], tpr: npt.NDArray[np.float32], auc_roc: npt.NDArray[np.float32]) -> None:\n",
    "    plt.figure(figsize=(8, 6)) # type: ignore\n",
    "    plt.plot(fpr, tpr, color=\"orange\", label=f\"AUC = {auc_roc}\") # type: ignore\n",
    "    plt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\") # type: ignore\n",
    "    plt.xlabel(\"False Positive Rate\") # type: ignore\n",
    "    plt.ylabel(\"True Positive Rate\") # type: ignore\n",
    "    plt.title(\"ROC Curve\") # type: ignore\n",
    "    plt.legend(loc=\"lower right\") # type: ignore\n",
    "    plt.grid() # type: ignore\n",
    "    plt.show() # type: ignore\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc12c9ba",
   "metadata": {},
   "source": [
    "### Plot Embedding Distances\n",
    "```python\n",
    "def plot_embedding_distances(\n",
    "    anchors: npt.NDArray[np.float32],\n",
    "    positives: npt.NDArray[np.float32],\n",
    "    negatives: npt.NDArray[np.float32],\n",
    ") -> None:\n",
    "    \n",
    "    pca = PCA(n_components=2)\n",
    "    all_embeddings = np.concatenate([anchors, positives, negatives], axis=0)\n",
    "    embeddings_2d = pca.fit_transform(all_embeddings)  # type: ignore\n",
    "\n",
    "    n_samples = len(anchors)\n",
    "    anchors_2d = embeddings_2d[:n_samples] # type: ignore\n",
    "    positives_2d = embeddings_2d[n_samples : 2 * n_samples] # type: ignore\n",
    "    negatives_2d = embeddings_2d[2 * n_samples :] # type: ignore\n",
    "\n",
    "    plt.figure(figsize=(10, 8)) # type: ignore\n",
    "    plt.scatter(anchors_2d[:, 0], anchors_2d[:, 1], c=\"blue\", label=\"Anchors\", alpha=0.6)  # type: ignore\n",
    "    plt.scatter(positives_2d[:, 0], positives_2d[:, 1], c=\"green\", label=\"Positives\", alpha=0.6)  # type: ignore\n",
    "    plt.scatter(negatives_2d[:, 0], negatives_2d[:, 1], c=\"red\", label=\"Negatives\", alpha=0.6)  # type: ignore\n",
    "\n",
    "    for i in range(len(anchors_2d)):  # type: ignore\n",
    "        plt.plot(  # type: ignore\n",
    "            [anchors_2d[i, 0], positives_2d[i, 0]],\n",
    "            [anchors_2d[i, 1], positives_2d[i, 1]],\n",
    "            \"g-\",\n",
    "            alpha=0.1,\n",
    "        )\n",
    "\n",
    "    for i in range(len(anchors_2d)):  # type: ignore\n",
    "        plt.plot(  # type: ignore\n",
    "            [anchors_2d[i, 0], negatives_2d[i, 0]],\n",
    "            [anchors_2d[i, 1], negatives_2d[i, 1]],\n",
    "            \"r-\",\n",
    "            alpha=0.1,\n",
    "        )\n",
    "\n",
    "    plt.title(\"2D Visualization of Embedding Distances\")  # type: ignore\n",
    "    plt.xlabel(\"First Principal Component\")  # type: ignore\n",
    "    plt.ylabel(\"Second Principal Component\")  # type: ignore\n",
    "    plt.legend()  # type: ignore\n",
    "    plt.grid(True)  # type: ignore\n",
    "    plt.savefig(\"embedding_distance.png\")  # type: ignore\n",
    "    plt.show()  # type: ignore\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc2f1f6",
   "metadata": {},
   "source": [
    "### Plot 3D Embeddings Interactive\n",
    "```python\n",
    "def plot_3d_embeddings_interactive(\n",
    "    anchors: npt.NDArray[np.float32],\n",
    "    positives: npt.NDArray[np.float32],\n",
    "    negatives: npt.NDArray[np.float32],\n",
    ") -> None:\n",
    "    pca = PCA(n_components=3)\n",
    "    all_embeddings = np.concatenate([anchors, positives, negatives])\n",
    "    embeddings_3d = pca.fit_transform(all_embeddings)  # type: ignore\n",
    "\n",
    "    n_samples = len(anchors)\n",
    "    anchors_3d = embeddings_3d[:n_samples]  # type: ignore\n",
    "    positives_3d = embeddings_3d[n_samples : 2 * n_samples]  # type: ignore\n",
    "    negatives_3d = embeddings_3d[2 * n_samples :]  # type: ignore\n",
    "\n",
    "    fig = go.Figure()\n",
    "\n",
    "    fig.add_trace(  # type: ignore\n",
    "        go.Scatter3d(\n",
    "            x=anchors_3d[:, 0],\n",
    "            y=anchors_3d[:, 1],\n",
    "            z=anchors_3d[:, 2],\n",
    "            mode=\"markers\",\n",
    "            name=\"Anchors\",\n",
    "            marker=dict(size=5, color=\"blue\", opacity=0.6),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fig.add_trace(  # type: ignore\n",
    "        go.Scatter3d(\n",
    "            x=positives_3d[:, 0],\n",
    "            y=positives_3d[:, 1],\n",
    "            z=positives_3d[:, 2],\n",
    "            mode=\"markers\",\n",
    "            name=\"Positives\",\n",
    "            marker=dict(size=5, color=\"green\", opacity=0.6),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fig.add_trace(  # type: ignore\n",
    "        go.Scatter3d(\n",
    "            x=negatives_3d[:, 0],\n",
    "            y=negatives_3d[:, 1],\n",
    "            z=negatives_3d[:, 2],\n",
    "            mode=\"markers\",\n",
    "            name=\"Negatives\",\n",
    "            marker=dict(size=5, color=\"red\", opacity=0.6),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fig.update_layout(  # type: ignore\n",
    "        title=\"Interactive 3D Visualization of Embedding Distances\",\n",
    "        scene=dict(\n",
    "            xaxis_title=\"First Principal Component\",\n",
    "            yaxis_title=\"Second Principal Component\",\n",
    "            zaxis_title=\"Third Principal Component\",\n",
    "        ),\n",
    "        width=800,\n",
    "        height=800,\n",
    "        margin=dict(l=0, r=0, b=0, t=30),\n",
    "    )\n",
    "\n",
    "    fig.update_layout(  # type: ignore\n",
    "        title=\"Interactive 3D Visualization of Embedding Distances\",\n",
    "        scene=dict(\n",
    "            xaxis_title=\"First Principal Component\",\n",
    "            yaxis_title=\"Second Principal Component\",\n",
    "            zaxis_title=\"Third Principal Component\",\n",
    "            camera=dict(eye=dict(x=1.25, y=1.25, z=1.25)),\n",
    "        ),\n",
    "        width=800,\n",
    "        height=800,\n",
    "        margin=dict(l=0, r=0, b=0, t=30),\n",
    "    )\n",
    "\n",
    "    fig.show()  # type: ignore\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe964d13",
   "metadata": {},
   "source": [
    "### Metrices\n",
    "```python\n",
    "def compute_distance_eval(\n",
    "    anchor: torch.Tensor, \n",
    "    positive: torch.Tensor, \n",
    "    negative: torch.Tensor, \n",
    "    margin: float,\n",
    ") -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "    positive_dist = F.pairwise_distance(anchor, positive)\n",
    "    negative_dist = F.pairwise_distance(anchor, negative)\n",
    "    loss = torch.mean(torch.relu(positive_dist - negative_dist + margin))\n",
    "    return positive_dist, negative_dist, loss\n",
    "\n",
    "def calculate_eer_eer_threshold(\n",
    "    thresholds: npt.NDArray[np.float32],\n",
    "    fpr: npt.NDArray[np.float32],\n",
    "    fnr: npt.NDArray[np.float32],\n",
    ") -> Tuple[float, float]:\n",
    "    absolute_difference = np.abs(fpr - fnr)\n",
    "    index = np.argmin(absolute_difference)\n",
    "    eer = (fpr[index] + fnr[index]) / 2.0\n",
    "    eer_threshold = thresholds[index]\n",
    "    \n",
    "    return eer, eer_threshold\n",
    "\n",
    "def calculate_auc(\n",
    "    all_labels_np: npt.NDArray[np.int64], \n",
    "    all_distances_np: npt.NDArray[np.float32]\n",
    ") -> Tuple[\n",
    "    npt.NDArray[np.float32],\n",
    "    npt.NDArray[np.float32],\n",
    "    npt.NDArray[np.float32],\n",
    "    npt.NDArray[np.float32],\n",
    "    float,\n",
    "    npt.NDArray[np.float32],\n",
    "]:    \n",
    "    scores = -all_distances_np\n",
    "    fpr, tpr, thresholds = roc_curve(all_labels_np, scores) # pyright: ignore[reportUnknownVariableType]\n",
    "    roc_auc = float(auc(fpr, tpr)) # pyright: ignore[reportUnknownArgumentType]\n",
    "\n",
    "    fnr = 1 - tpr  # pyright: ignore[reportUnknownVariableType]\n",
    "\n",
    "    return fpr, tpr, fnr, thresholds, roc_auc, scores # pyright: ignore[reportUnknownVariableType]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ea779e",
   "metadata": {},
   "source": [
    "### Evaluation Function\n",
    "```python\n",
    "def evaluate_model(\n",
    "    model: nn.Module,\n",
    "    test_loader: DataLoader[Tuple[torch.Tensor, torch.Tensor, torch.Tensor, int]],\n",
    "    margin: float = 0.5,\n",
    ") -> EvalResults:\n",
    "    model.eval()\n",
    "    all_labels: List[float] = []\n",
    "    all_distances: List[float] = []\n",
    "    embeddings_list: defaultdict[\n",
    "        str, \n",
    "        List[\n",
    "            npt.NDArray[\n",
    "                np.float32\n",
    "            ]\n",
    "        ]\n",
    "    ] = defaultdict(list)\n",
    "    \n",
    "    total_loss: float = 0.0\n",
    "    num_batches: int = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for anchor, positive, negative, _anchor_id in test_loader:\n",
    "            anchor = anchor.to(LEARNING_CONFIG[\"DEVICE\"])\n",
    "            positive = positive.to(LEARNING_CONFIG[\"DEVICE\"])\n",
    "            negative = negative.to(LEARNING_CONFIG[\"DEVICE\"])\n",
    "             \n",
    "            anchor_embedding = model(anchor)\n",
    "            positive_embedding = model(positive)\n",
    "            negative_embedding = model(negative)\n",
    "            \n",
    "            positive_dist, negative_dist, loss = compute_distance_eval(anchor_embedding, positive_embedding, negative_embedding, margin)\n",
    "            total_loss += loss.item()\n",
    "            num_batches += 1\n",
    "            \n",
    "            for k, v in zip((\"anchor\", \"positive\", \"negative\"), (anchor_embedding, positive_embedding, negative_embedding)):\n",
    "                embeddings_list[k].append(v.cpu().numpy())\n",
    "            \n",
    "            all_distances.extend(positive_dist.cpu().tolist()); all_labels.extend([1]*len(positive_dist)) # pyright: ignore[reportUnknownArgumentType, reportUnknownMemberType]\n",
    "            all_distances.extend(negative_dist.cpu().tolist()); all_labels.extend([0]*len(negative_dist)) # pyright: ignore[reportUnknownArgumentType, reportUnknownMemberType]\n",
    "\n",
    "    final_embeddings: Dict[str, npt.NDArray[np.float32]] = {k: np.concatenate(v, axis=0) for k,v in embeddings_list.items()}\n",
    "    all_distances_np = np.array(all_distances, np.float32).reshape(-1)\n",
    "    all_labels_np = np.array(all_labels, np.int64).reshape(-1)\n",
    "    \n",
    "    fpr, tpr, fnr, thresholds, roc_auc, scores = calculate_auc(all_labels_np, all_distances_np)\n",
    "    eer, eer_threshold = calculate_eer_eer_threshold(thresholds, fpr, fnr)\n",
    "\n",
    "    preds = (scores >= eer_threshold).astype(int)\n",
    "\n",
    "    metrics: Dict[str, Any] = {\n",
    "        \"avg_triplet_loss\": total_loss/num_batches,\n",
    "        \"avg_pos_dist\": float(all_distances_np[all_labels_np==1].mean()),\n",
    "        \"avg_neg_dist\": float(all_distances_np[all_labels_np==0].mean()),\n",
    "        \"auc_roc\": float(roc_auc),\n",
    "        \"eer\": float(eer),\n",
    "        \"eer_threshold\": float(eer_threshold),\n",
    "        \"accuracy\": accuracy_score(all_labels_np, preds),\n",
    "        \"precision\": precision_score(all_labels_np, preds, pos_label=1),\n",
    "        \"recall\": recall_score(all_labels_np, preds, pos_label=1),\n",
    "    }\n",
    "\n",
    "    curves = {\"fpr\": fpr, \"tpr\": tpr, \"fnr\": fnr}\n",
    "    return EvalResults(all_distances_np, all_labels_np, final_embeddings, metrics, curves)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd35b22",
   "metadata": {},
   "source": [
    "## Sanity checks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1664e55b",
   "metadata": {},
   "source": [
    "### Batch indices\n",
    "```python\n",
    "batch_iter = iter(train_sampler)\n",
    "batch_indices = next(batch_iter)\n",
    "\n",
    "print(\"Batch indices:\", batch_indices)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6830ff6d",
   "metadata": {},
   "source": [
    "### Batch Labels\n",
    "```python\n",
    "# Map indices back to labels\n",
    "batch_labels = [train_dataset[i][1] for i in batch_indices]\n",
    "print(\"Batch labels:\", batch_labels)\n",
    "\n",
    "# Optionally, map to signer IDs and type\n",
    "batch_info = [train_dataset.all_image_references[i] for i in batch_indices]\n",
    "print(\"Batch info (signer_id, type, idx):\", batch_info)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759dc4d9",
   "metadata": {},
   "source": [
    "### Signer counts\n",
    "```python\n",
    "from collections import Counter\n",
    "signers = [train_dataset.all_image_references[i][0] for i in batch_indices]\n",
    "print(\"Signer counts in batch:\", Counter(signers))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e8b3b0",
   "metadata": {},
   "source": [
    "### Batch Summary\n",
    "\n",
    "```python\n",
    "from collections import defaultdict\n",
    "\n",
    "def print_batch_summary(dataset, batch_indices):\n",
    "    summary = defaultdict(list)\n",
    "    for idx in batch_indices:\n",
    "        signer, img_type, img_idx = dataset.all_image_references[idx]\n",
    "        summary[signer].append(img_type)\n",
    "    for signer, types in summary.items():\n",
    "        print(f\"Signer {signer}: {types}\")\n",
    "\n",
    "print_batch_summary(train_dataset, batch_indices)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13dbb32",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
